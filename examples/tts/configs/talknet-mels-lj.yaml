model: "TalkNet Mels Predictor (LJSpeech)"
sample_rate: &sample_rate 22050
n_mels: &n_mels 80
pad16: &pad16 false
labels: [
  # Space
    ' ',
  # string.ascii_lowercase
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
  # Punctuation
    ',', '.', '!', '?', ';', ':', '-', '/',
    '"', "'", '(', ')', '[', ']', '{', '}',
]

TalkNetDataLayer_train:
    sample_rate: *sample_rate
    normalize_transcripts: true
    trim_silence: false
    drop_last: true
    shuffle: true
    sampler_type: 'default'  # 'super-smart' makes sense for distributed training.
    # Possible values: shake_[un]biased|p, false
    bd_aug: false  # I believe model should still learn something when we shake durs a bit.

TalkNetDataLayer_eval:
    sample_rate: *sample_rate
    normalize_transcripts: true
    trim_silence: false
    drop_last: false  # Mind the BN.
    shuffle: false
    # Eval/Test are too small for distributed evaluation. Also, we can't collect python objects using torch dist.
    sampler_type: 'all'
    bd_aug: false

AudioToMelSpectrogramPreprocessor:  # Full good-TTS config.
    sample_rate: *sample_rate
    window_size: null  # Because "n_window_size" below is set.
    window_stride: null  # Because "n_window_size" below is set.
    n_window_size: 1024
    n_window_stride: 256
    window: 'hann'
    normalize: null  # Seems like it's bad for TTS.
    n_fft: 1024
    preemph: null
    features: *n_mels  # 80 works good for TTS.
    lowfreq: 0
    highfreq: 8000
    log: true
    log_zero_guard_type: 'clamp'  # 'clamp' just seems more reasonable.
    log_zero_guard_value: 1e-05
    dither: 0.0
    pad_to: 1  # 16 would be better choice, but we pad manually in encoder/loss classes.
    frame_splicing: 1
    stft_conv: true
    pad_value: -11.52
    mag_power: 1.0  # People use 1.0 for TTS for some reason.

LenSampler:
    max_len: 1100  # Max LJSpeech dur is 10.10sec, so it's never happen.

TalkNet:
    d_char: 256
    pad16: *pad16
    poly_span: true  # Gives a little boost, sounds a little bit better.

# QuartzNet15x5 without 2x First Stride and Jasper's kernel sizes
dropout: &dropout 0.0  # Having dropout more than 0.1 doesn't make sense for LJSpeech.
separable: &separable true  # Non-separable one greatly increase number of weights.
JasperEncoder:
    activation: "relu"
    conv_mask: false  # Mind the MaskedConv1d implementation: it's too slow for training and inference.

    # (Number of Layers) x (Number of Repeats) x (Number of Filters) x (Kernel Sizes)
    jasper:
        # First 3x3 Conv: 1 x 3 x 256 x 3
        -   filters: 256
            repeat: 3  # Was 1 in Original QuartzNet15x5.
            kernel: [3]  # 5 and 7 works a bit worse.
            stride: [1]  # Was 2 in Original QuartzNet15x5.
            dilation: [1]
            dropout: *dropout
            residual: true  # Non-residual works a bit worse.
            separable: *separable

        # Block 1: 3 x 5 x 256 x [5, 7, 9]
        -   filters: 256
            repeat: 5
            kernel: [5]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 256
            repeat: 5
            kernel: [7]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 256
            repeat: 5
            kernel: [9]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        # Block 2: 3 x 5 x 256 x [13, 15, 17]
        -   filters: 256
            repeat: 5
            kernel: [13]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 256
            repeat: 5
            kernel: [15]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 256
            repeat: 5
            kernel: [17]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        # Block 3: 3 x 5 x 512 x [21, 23, 25] (Last Block)
        -   filters: 512
            repeat: 5
            kernel: [21]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 512
            repeat: 5
            kernel: [23]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        -   filters: 512
            repeat: 5
            kernel: [25]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true
            separable: *separable

        # Last 1x1 Conv
        -   filters: 1024
            repeat: 1
            kernel: [1]
            stride: [1]
            dilation: [1]
            dropout: *dropout
            residual: true  # Non-residual works a bit worse.

TalkNetMelsLoss:
    reduction: 'all'
    pad16: *pad16
