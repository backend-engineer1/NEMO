name: MixerTTS
sample_rate: 22050

train_dataset: ???
validation_datasets: ???
sup_data_path: ???
sup_data_types: [ "duration_prior", "pitch", "lm_tokens" ]

whitelist_path: "nemo_text_processing/text_normalization/en/data/whitelist_lj_speech.tsv"

# LJSpeech stats (per frame), train
pitch_mean: 212.35873413085938
pitch_std: 68.52806091308594

# default values from librosa.pyin
pitch_fmin: 65.40639132514966
pitch_fmax: 2093.004522404789

# default values for sample_rate=22050
n_mels: 80
n_window_size: 1024
n_window_stride: 256
n_fft: 1024
lowfreq: 0
highfreq: 8000
window: "hann"

pitch_loss_scale: 0.1
durs_loss_scale: 0.1
mel_loss_scale: 1.0

cond_on_lm_embeddings: True
lm_model: "albert"

model:
  # aligner
  bin_loss_start_ratio: 0.2
  bin_loss_warmup_epochs: 100

  symbols_embedding_dim: 384
  n_mel_channels: ${n_mels}

  pitch_loss_scale: ${pitch_loss_scale}
  durs_loss_scale: ${durs_loss_scale}
  mel_loss_scale: ${mel_loss_scale}

  cond_on_lm_embeddings: ${cond_on_lm_embeddings}

  pitch_mean: ${pitch_mean}
  pitch_std: ${pitch_std}

  train_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.MixerTTSDataset"
      manifest_filepath: ${train_dataset}
      sample_rate: ${sample_rate}
      sup_data_path: ${sup_data_path}
      sup_data_types: ${sup_data_types}
      n_fft: ${n_fft}
      win_length: ${n_window_size}
      hop_length: ${n_window_stride}
      window: ${window}
      n_mels: ${n_mels}
      lowfreq: ${lowfreq}
      highfreq: ${highfreq}
      max_duration: null
      min_duration: 0.1
      ignore_file: null
      trim: False
      pitch_fmin: ${pitch_fmin}
      pitch_fmax: ${pitch_fmax}

      lm_model: ${lm_model}

      text_normalizer:
        _target_: "nemo_text_processing.text_normalization.normalize.Normalizer"
        lang: "en"
        input_case: "cased"
        whitelist: ${whitelist_path}

      text_normalizer_call_args:
        verbose: False
        punct_pre_process: True
        punct_post_process: True

      text_tokenizer:
        _target_: "nemo.collections.tts.torch.tts_tokenizers.EnglishCharsTokenizer"
        punct: True
        apostrophe: True
        add_blank_at: null
        pad_with_space: True

    dataloader_params:
      drop_last: false
      shuffle: true
      batch_size: 64
      num_workers: 4
      pin_memory: false

  validation_ds:
    dataset:
      _target_: "nemo.collections.tts.torch.data.MixerTTSDataset"
      manifest_filepath: ${validation_datasets}
      sample_rate: ${sample_rate}
      sup_data_path: ${sup_data_path}
      sup_data_types: ${sup_data_types}
      n_fft: ${n_fft}
      win_length: ${n_window_size}
      hop_length: ${n_window_stride}
      window: ${window}
      n_mels: ${n_mels}
      lowfreq: ${lowfreq}
      highfreq: ${highfreq}
      max_duration: null
      min_duration: 0.1
      ignore_file: null
      trim: False
      pitch_fmin: ${pitch_fmin}
      pitch_fmax: ${pitch_fmax}

      lm_model: ${lm_model}

      text_normalizer:
        _target_: "nemo_text_processing.text_normalization.normalize.Normalizer"
        lang: "en"
        input_case: "cased"
        whitelist: ${whitelist_path}

      text_normalizer_call_args:
        verbose: False
        punct_pre_process: True
        punct_post_process: True

      text_tokenizer:
        _target_: "nemo.collections.tts.torch.tts_tokenizers.EnglishCharsTokenizer"
        punct: True
        apostrophe: True
        add_blank_at: null
        pad_with_space: True

    dataloader_params:
      drop_last: false
      shuffle: false
      batch_size: 64
      num_workers: 1
      pin_memory: false

  preprocessor:
    _target_: "nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor"
    dither: 0.0
    features: ${model.n_mel_channels}
    frame_splicing: 1
    highfreq: ${highfreq}
    log: true
    log_zero_guard_type: clamp
    log_zero_guard_value: 1e-05
    lowfreq: 0
    mag_power: 1.0
    n_fft: ${n_fft}
    n_window_size: ${n_window_size}
    window_size: false
    n_window_stride: ${n_window_stride}
    window_stride: false
    normalize: null
    pad_to: 1
    pad_value: -11.52
    preemph: null
    sample_rate: ${sample_rate}
    stft_conv: false
    window: hann

  alignment_module:
    _target_: nemo.collections.tts.modules.aligner.AlignmentEncoder
    n_text_channels: ${model.symbols_embedding_dim}

  self_attention_module:
    _target_: nemo.collections.tts.modules.mixer_tts.SelfAttentionModule
    n_text_channels: ${model.symbols_embedding_dim}
    n_lm_tokens_channels: 100 # dummy value, real value is set in model constructor

  encoder:
    _target_: nemo.collections.tts.modules.mixer_tts.MixerTTSModule
    num_tokens: 100 # dummy value, real value is set in model constructor
    padding_idx: 100 # dummy value, real value is set in model constructor
    feature_dim: 384
    kernel_sizes: [11, 13, 15, 17, 19, 21]
    num_layers: 6
    expansion_factor: 4
    dropout: 0.15

  decoder:
    _target_: nemo.collections.tts.modules.mixer_tts.MixerTTSModule
    num_tokens: -1
    feature_dim: 384
    kernel_sizes: [15, 17, 19, 21, 23, 25, 27, 29, 31]
    num_layers: 9
    expansion_factor: 4
    dropout: 0.15

  duration_predictor:
    _target_: nemo.collections.tts.modules.fastpitch.TemporalPredictor
    input_size: ${model.symbols_embedding_dim}
    kernel_size: 3
    filter_size: 256
    dropout: 0.15
    n_layers: 2

  pitch_predictor:
    _target_: nemo.collections.tts.modules.fastpitch.TemporalPredictor
    input_size: ${model.symbols_embedding_dim}
    kernel_size: 3
    filter_size: 256
    dropout: 0.15
    n_layers: 2

  pitch_emb:
    _target_: torch.nn.Conv1d
    in_channels: 1
    out_channels: ${model.symbols_embedding_dim}
    kernel_size: 3
    padding: 1

  optim:
    name: lamb
    lr: 1e-1
    betas: [0.9, 0.98]
    weight_decay: 1e-6

    sched:
      name: NoamAnnealing
      warmup_steps: 1000
      last_epoch: -1
      d_model: 1  # Disable scaling based on model dim

trainer:
  gpus: 1
  precision: 32
  max_epochs: 1000
  num_nodes: 1
  accelerator: ddp
  accumulate_grad_batches: 1
  checkpoint_callback: False
  logger: False
  gradient_clip_val: 1000.0
  flush_logs_every_n_steps: 1000
  log_every_n_steps: 200
  check_val_every_n_epoch: 1

exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: True
  create_checkpoint_callback: True
  checkpoint_callback_params:
    monitor: "val_mel_loss"
    mode: "min"