name: &name "MatchboxNet-3x1x64-v2"

model:
  sample_rate: 16000
  timesteps: 128
  repeat: 1
  dropout: 0.0
  kernel_size_factor: 1.0

  labels_full: ['visual', 'wow', 'learn', 'backward', 'dog', 'two', 'left', 'happy', 'nine', 'go', 'up', 'bed', 'stop',
           'one', 'zero', 'tree', 'seven', 'on', 'four', 'bird', 'right', 'eight', 'no', 'six', 'forward', 'house',
           'marvin', 'sheila', 'five', 'off', 'three', 'down', 'cat', 'follow', 'yes']

  labels_subset: ["yes", "no", "up", "down", "left", "right", "on", "off", "stop", "go", "unknown", "silence"]

  labels: ${model.labels_full}

  train_ds:
    manifest_filepath: ???
    sample_rate: ${model.sample_rate}
    labels: ${model.labels}
    batch_size: 128
    shuffle: True
    augmentor:
      shift:
        prob: 1.0
        min_shift_ms: -5.0
        max_shift_ms: 5.0
      white_noise:
        prob: 1.0
        min_level: -90
        max_level: -46

  validation_ds:
    manifest_filepath: ???
    sample_rate: ${model.sample_rate}
    labels: ${model.labels}
    batch_size: 128
    shuffle: False
    val_loss_idx: 0

  test_ds:
    manifest_filepath: null
    sample_rate: ${model.sample_rate}
    labels: ${model.labels}
    batch_size: 128
    shuffle: False
    test_loss_idx: 0

  preprocessor:
    cls: nemo.collections.asr.modules.AudioToMFCCPreprocessor
    params:
      window_size: 0.025
      window_stride: 0.01
      window: "hann"
      n_mels: &n_mels 64
      n_mfcc: *n_mels
      n_fft: 512

  spec_augment:
    cls: nemo.collections.asr.modules.SpectrogramAugmentation
    params:
      freq_masks: 2
      time_masks: 2
      freq_width: 15
      time_width: 25
      rect_masks: 5
      rect_time: 25
      rect_freq: 15

  crop_or_pad_augment:
    cls: nemo.collections.asr.modules.CropOrPadSpectrogramAugmentation
    params:
      audio_length: ${model.timesteps}

  encoder:
    cls: nemo.collections.asr.modules.ConvASREncoder
    params:
      feat_in: *n_mels
      activation: relu
      conv_mask: true

      jasper:
        - filters: 128
          repeat: 1
          kernel: [11]
          stride: [1]
          dilation: [1]
          dropout: ${model.dropout}
          residual: false
          separable: true
          kernel_size_factor: ${model.kernel_size_factor}

        - filters: 64
          repeat: ${model.repeat}
          kernel: [13]
          stride: [1]
          dilation: [1]
          dropout: ${model.dropout}
          residual: true
          separable: true
          kernel_size_factor: ${model.kernel_size_factor}

        - filters: 64
          repeat: ${model.repeat}
          kernel: [15]
          stride: [1]
          dilation: [1]
          dropout: ${model.dropout}
          residual: true
          separable: true
          kernel_size_factor: ${model.kernel_size_factor}

        - filters: 64
          repeat: ${model.repeat}
          kernel: [17]
          stride: [1]
          dilation: [1]
          dropout: ${model.dropout}
          residual: true
          separable: true
          kernel_size_factor: ${model.kernel_size_factor}

        - filters: 128
          repeat: 1
          kernel: [29]
          stride: [1]
          dilation: [2]
          dropout: ${model.dropout}
          residual: false
          separable: true
          kernel_size_factor: ${model.kernel_size_factor}

        - filters: &enc_final_filters 128
          repeat: 1
          kernel: [1]
          stride: [1]
          dilation: [1]
          dropout: ${model.dropout}
          residual: false

  decoder:
    cls: nemo.collections.asr.modules.ConvASRDecoderClassification
    params:
      feat_in: *enc_final_filters
      num_classes: 35
      return_logits: true
      pooling_type: 'avg'

  optim:
    name: novograd
    # cls: nemo.core.optim.optimizers.Novograd
    lr: 0.05
    # optimizer arguments
    betas: [0.95, 0.5]
    weight_decay: 0.001

    # scheduler setup
    sched:
      name: PolynomialHoldDecayAnnealing

      # Scheduler params
      power: 2.0
      warmup_ratio: 0.05
      hold_ratio: 0.45
      min_lr: 0.001
      last_epoch: -1

trainer:
  gpus: 0 # number of gpus
  max_epochs: 200
  max_steps: null # computed at runtime if not set
  num_nodes: 1
  distributed_backend: ddp
  accumulate_grad_batches: 1
  checkpoint_callback: False  # Provided by exp_manager
  logger: False  # Provided by exp_manager
  row_log_interval: 1  # Interval of logging.
  val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations

exp_manager:
  exp_dir: null
  name: *name
  create_tensorboard_logger: True
  create_checkpoint_callback: True
  create_wandb_logger: False
  wandb_logger_kwargs:
    name: null
    project: null

hydra:
  run:
    dir: .
  job_logging:
    root:
      handlers: null
