{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed changes\n",
    "\n",
    "* Drop (empty) multi-backend promise\n",
    "* Make all Models and Modules Pytorch-compatible out-of-the box\n",
    "* Provide training/fine-tuning examples using Pytorch Lightning\n",
    "* Neural Types are now optional and can do more when used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NeMo/Jarvis fine-tuning example\n",
    "\n",
    "Every Jarvis service will have a corresponding script (or more if several models are used) to fine-tune its models on the user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 - get model and pretrained weights from NVIDIA NGC cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asr_model = nemo_asr.models.ASRConvCTCModel2.from_cloud(name=\"QuartzNet15x5-En\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 - get model and pretrained weights from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asr_model = nemo_asr.models.ASRConvCTCModel2.restore_from(\"my_asr.nemo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3 - instantiate model from config (no pre-trained weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asr_model = nemo_asr.models.ASRConvCTCModel2.from_config(\"quartznet.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4 - instantiate model using constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-06-15 22:54:19 features:154] PADDING: 16\n",
      "[NeMo I 2020-06-15 22:54:19 features:162] STFT using conv\n",
      "[NeMo I 2020-06-15 22:54:19 helpers:66] Instantiated a new Neural Module of type AudioToMelSpectrogramPreprocessor2\n",
      "[NeMo I 2020-06-15 22:54:19 helpers:66] Instantiated a new Neural Module of type ConvASREncoder\n",
      "[NeMo I 2020-06-15 22:54:19 helpers:66] Instantiated a new Neural Module of type ConvASRDecoder\n"
     ]
    }
   ],
   "source": [
    "from ruamel.yaml import YAML\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open('/Users/okuchaiev/repos/NeMo/examples/asr/configs/jasper_an4-2.yaml') as f:\n",
    "    model_config = yaml.load(f)\n",
    "asr_model = nemo_asr.models.ASRConvCTCModel2(\n",
    "    preprocessor_params=model_config['AudioToMelSpectrogramPreprocessor'],\n",
    "    encoder_params=model_config['JasperEncoder'],\n",
    "    decoder_params=model_config['JasperDecoder'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-06-15 22:54:19 collections:158] Dataset loaded with 897 files totalling 1.39 hours\n",
      "[NeMo I 2020-06-15 22:54:19 collections:159] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2020-06-15 22:54:19 helpers:66] Instantiated a new Neural Module of type AudioToTextDataLayer2\n",
      "[NeMo I 2020-06-15 22:54:19 collections:158] Dataset loaded with 130 files totalling 0.20 hours\n",
      "[NeMo I 2020-06-15 22:54:19 collections:159] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2020-06-15 22:54:19 helpers:66] Instantiated a new Neural Module of type AudioToTextDataLayer2\n"
     ]
    }
   ],
   "source": [
    "# Setup where your training data is\n",
    "asr_model.setup_training_data(model_config['AudioToTextDataLayer'])\n",
    "asr_model.setup_validation_data(model_config['AudioToTextDataLayer_eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Pytorch Lightning Trainer object instead of NeuralModuleFactory\n",
    "# trainer = pl.Trainer(val_check_interval=5, amp_level='O1', precision=16, gpus=2, max_epochs=50, distributed_backend='ddp')\n",
    "trainer = pl.Trainer(val_check_interval=5, max_epochs=1)\n",
    "trainer.fit(asr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for deployment with Jarvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: Implement Me\n"
     ]
    }
   ],
   "source": [
    "asr_model.save_to('qn.nemo', optimize_for_deployment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
