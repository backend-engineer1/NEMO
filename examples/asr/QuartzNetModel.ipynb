{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeMo Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-20 14:43:03 audio_preprocessing:56] Could not import torchaudio. Some features might not work.\n",
      "[NeMo W 2020-05-20 14:43:03 audio_preprocessing:61] Unable to import APEX. Mixed precision and distributed training will not work.\n"
     ]
    }
   ],
   "source": [
    "# Import NeMo and ASR collection\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "nf = nemo.core.NeuralModuleFactory(placement=nemo.core.DeviceType.CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *NeMoModel* is a kind of NeuralModule which contains other neural modules inside it.\n",
    "NeMoModel can have other NeuralModules inside and their mode, and topology of connections can\n",
    "depend on the mode (training, inference, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want an ASR model to serve with Jarvis. What do I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-20 14:43:03 quartznet:150] THIS METHOD IS NOT DONE YET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuartzNet15x5-En-BASE\n",
      "QuartzNet15x5-Zh-BASE\n",
      "Jasper10x5-En-BASE\n",
      "ContextNet21x5-En-BASE\n"
     ]
    }
   ],
   "source": [
    "# Check what's available on NGC \n",
    "for checkpoint in nemo.collections.asr.models.QuartzNet.list_pretrained_models():\n",
    "    print(checkpoint.pretrained_model_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-20 14:43:04 quartznet:183] THIS METHOD IS NOT YET FINISHED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-20 14:43:04 helpers:157] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperEncoder-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-20 14:43:04 helpers:157] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-20 14:43:04 helpers:157] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-20 14:43:04 helpers:157] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/qn.yaml. Re-using\n",
      "[NeMo I 2020-05-20 14:43:04 quartznet:198] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2020-05-20 14:43:04 neural_modules:341] Loading configuration of a new Neural Module from the `/Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/qn.yaml` file\n",
      "[NeMo I 2020-05-20 14:43:05 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-20 14:43:05 features:152] STFT using conv\n",
      "[NeMo I 2020-05-20 14:43:05 neural_modules:441] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor0` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-20 14:43:05 neural_modules:441] Instantiated a new Neural Module named `jasperencoder0` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-20 14:43:05 neural_modules:441] Instantiated a new Neural Module named `jasperdecoderforctc0` of type `JasperDecoderForCTC`\n",
      "[NeMo I 2020-05-20 14:43:05 neural_modules:441] Instantiated a new Neural Module named `quartznet0` of type `QuartzNet`\n",
      "[NeMo I 2020-05-20 14:43:05 quartznet:200] Model instantiated with pre-trained weights\n"
     ]
    }
   ],
   "source": [
    "# Download the one I want from NGC\n",
    "pre_trained_qn_model = nemo_asr.models.QuartzNet.from_pretrained(model_info=\"QuartzNet15x5-En-BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nemo.collections.asr.models.quartznet.QuartzNet"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pre_trained_qn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:43:38 neural_modules:232] Configuration of module `quartznet0` (QuartzNet) exported to .PYS964LHI7ILTPT8/.nemo_tmp/QuartzNet.yaml\n",
      "[NeMo I 2020-05-15 14:43:38 neural_graph:480] Configuration of graph `neuralgraph1` (NeuralGraph) exported to .PYS964LHI7ILTPT8/.nemo_tmp/QuartzNet_eval_graph.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-15 14:43:38 nemo_model:135] Did not convert AudioToMelSpectrogramPreprocessor to .onnx\n",
      "[NeMo W 2020-05-15 14:43:38 jasper:134] Turned off 12 masked convolutions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AudioToMelSpectrogramPreprocessor' object has no attribute 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-15 14:43:39 deprecated:68] Function ``local_parameters`` is deprecated. It is going to be removed in the 0.11 version.\n",
      "/Users/okuchaiev/opt/anaconda3/envs/py37/lib/python3.7/site-packages/torch/onnx/utils.py:915: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input audio_signal\n",
      "  'Automatically generated names will be applied to each dynamic axes of input {}'.format(key))\n",
      "/Users/okuchaiev/opt/anaconda3/envs/py37/lib/python3.7/site-packages/torch/onnx/utils.py:915: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input outputs\n",
      "  'Automatically generated names will be applied to each dynamic axes of input {}'.format(key))\n",
      "/Users/okuchaiev/opt/anaconda3/envs/py37/lib/python3.7/site-packages/torch/onnx/utils.py:915: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input encoder_output\n",
      "  'Automatically generated names will be applied to each dynamic axes of input {}'.format(key))\n",
      "/Users/okuchaiev/opt/anaconda3/envs/py37/lib/python3.7/site-packages/torch/onnx/utils.py:915: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input output\n",
      "  'Automatically generated names will be applied to each dynamic axes of input {}'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:43:44 nemo_model:143] Exported model QuartzNet to asr.nemo\n"
     ]
    }
   ],
   "source": [
    "# Export it as \".nemo\" file\n",
    "pre_trained_qn_model.export(\"asr.nemo\", optimize_for_deployment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: asr.nemo: No such file or directory\n",
      "x .nemo_tmp/\n",
      "x .nemo_tmp/JasperDecoderForCTC.onnx\n",
      "x .nemo_tmp/JasperEncoder.onnx\n",
      "x .nemo_tmp/QuartzNet.yaml\n",
      "x .nemo_tmp/QuartzNet_eval_graph.yaml\n"
     ]
    }
   ],
   "source": [
    "# \".nemo\" file is just a file with Modules in .onnx format and evaluation graph structure\n",
    "! mv asr.nemo asr.tar.gz\n",
    "! tar -xvf asr.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModel instantiation - method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because NeMoModel is a NeuralModule, regular constructor-based initialization applies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, load the config from YAML file\n",
    "from ruamel.yaml import YAML\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(\"configs/jasper_an4.yaml\") as file:\n",
    "    model_definition = yaml.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:52:28 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-15 14:52:28 features:152] STFT using conv\n",
      "[NeMo I 2020-05-15 14:52:28 neural_modules:442] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor1` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-15 14:52:29 neural_modules:442] Instantiated a new Neural Module named `jasperencoder1` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-15 14:52:29 neural_modules:442] Instantiated a new Neural Module named `jasperdecoderforctc1` of type `JasperDecoderForCTC`\n",
      "5771293\n",
      "{'input_signal': <nemo.core.neural_types.neural_type.NeuralType object at 0x142194390>, 'length': <nemo.core.neural_types.neural_type.NeuralType object at 0x142184650>}\n"
     ]
    }
   ],
   "source": [
    "qn_model = nemo.collections.asr.models.QuartzNet(\n",
    "            preprocessor_params=model_definition['AudioToMelSpectrogramPreprocessor'],\n",
    "            encoder_params=model_definition['JasperEncoder'],\n",
    "            decoder_params=model_definition['JasperDecoderForCTC'],\n",
    "        )\n",
    "print(qn_model.num_weights)\n",
    "print(qn_model.input_ports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because NeMoModel is a NeuralModule, regular config import/export work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:52:42 neural_modules:232] Configuration of module `quartznet1` (QuartzNet) exported to qn.yaml\n",
      "[NeMo I 2020-05-15 14:52:42 neural_modules:342] Loading configuration of a new Neural Module from the `qn.yaml` file\n",
      "[NeMo I 2020-05-15 14:52:42 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-15 14:52:42 features:152] STFT using conv\n",
      "[NeMo I 2020-05-15 14:52:42 neural_modules:442] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor2` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-15 14:52:42 neural_modules:442] Instantiated a new Neural Module named `jasperencoder2` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-15 14:52:42 neural_modules:442] Instantiated a new Neural Module named `jasperdecoderforctc2` of type `JasperDecoderForCTC`\n",
      "[NeMo I 2020-05-15 14:52:42 neural_modules:442] Instantiated a new Neural Module named `quartznet2` of type `QuartzNet`\n",
      "5771293\n",
      "5771293\n"
     ]
    }
   ],
   "source": [
    "qn_model.export_to_config(\"qn.yaml\")\n",
    "qn_model2 = nemo.collections.asr.models.QuartzNet.import_from_config(config_file=\"qn.yaml\")\n",
    "print(qn_model2.num_weights)\n",
    "print(qn_model.num_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModel instantiation - method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-15 14:52:53 quartznet:151] THIS METHOD IS NOT DONE YET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuartzNet15x5-En-BASE\n",
      "QuartzNet15x5-Zh-BASE\n",
      "Jasper10x5-En-BASE\n",
      "ContextNet21x5-En-BASE\n"
     ]
    }
   ],
   "source": [
    "# List all available models from NGC\n",
    "for checkpoint in nemo.collections.asr.models.QuartzNet.list_pretrained_models():\n",
    "    print(checkpoint.pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-15 14:52:59 quartznet:184] THIS METHOD IS NOT YET FINISHED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:52:59 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperEncoder-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-15 14:52:59 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-15 14:52:59 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-05-15 14:52:59 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/qn.yaml. Re-using\n",
      "[NeMo I 2020-05-15 14:52:59 quartznet:199] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2020-05-15 14:52:59 neural_modules:342] Loading configuration of a new Neural Module from the `/Users/okuchaiev/.nemo_files/NEMO_0.10.2b0/QuartzNet15x5-En-BASE/qn.yaml` file\n",
      "[NeMo I 2020-05-15 14:52:59 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-15 14:52:59 features:152] STFT using conv\n",
      "[NeMo I 2020-05-15 14:52:59 neural_modules:442] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor3` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-15 14:52:59 neural_modules:442] Instantiated a new Neural Module named `jasperencoder3` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-15 14:52:59 neural_modules:442] Instantiated a new Neural Module named `jasperdecoderforctc3` of type `JasperDecoderForCTC`\n",
      "[NeMo I 2020-05-15 14:52:59 neural_modules:442] Instantiated a new Neural Module named `quartznet3` of type `QuartzNet`\n",
      "[NeMo I 2020-05-15 14:52:59 quartznet:201] Model instantiated with pre-trained weights\n"
     ]
    }
   ],
   "source": [
    "# Automagically go to NGC and instantiate a model and weights\n",
    "pre_trained_qn_model = nemo_asr.models.QuartzNet.from_pretrained(model_info=\"QuartzNet15x5-En-BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to \".nemo\" format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to \".nemo\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:53:57 neural_modules:232] Configuration of module `quartznet3` (QuartzNet) exported to .64G9SZNAIUY6YTJF/.nemo_tmp/QuartzNet.yaml\n",
      "[NeMo I 2020-05-15 14:53:57 neural_graph:480] Configuration of graph `neuralgraph6` (NeuralGraph) exported to .64G9SZNAIUY6YTJF/.nemo_tmp/QuartzNet_train_graph.yaml\n",
      "[NeMo I 2020-05-15 14:53:57 neural_graph:480] Configuration of graph `neuralgraph7` (NeuralGraph) exported to .64G9SZNAIUY6YTJF/.nemo_tmp/QuartzNet_eval_graph.yaml\n",
      "[NeMo I 2020-05-15 14:53:58 nemo_model:143] Exported model QuartzNet to quartznet.nemo\n"
     ]
    }
   ],
   "source": [
    "pre_trained_qn_model.export('quartznet.nemo', optimize_for_deployment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-05-15 14:54:02 quartznet:184] THIS METHOD IS NOT YET FINISHED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:54:02 neural_modules:342] Loading configuration of a new Neural Module from the `UGJB1452F2HA799B/.nemo_tmp/QuartzNet.yaml` file\n",
      "[NeMo I 2020-05-15 14:54:02 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-15 14:54:02 features:152] STFT using conv\n",
      "[NeMo I 2020-05-15 14:54:02 neural_modules:442] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor0` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-15 14:54:02 neural_modules:442] Instantiated a new Neural Module named `jasperencoder0` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-15 14:54:02 neural_modules:442] Instantiated a new Neural Module named `jasperdecoderforctc0` of type `JasperDecoderForCTC`\n",
      "[NeMo I 2020-05-15 14:54:02 neural_modules:442] Instantiated a new Neural Module named `quartznet0` of type `QuartzNet`\n"
     ]
    }
   ],
   "source": [
    "new_instance = nemo_asr.models.QuartzNet.from_pretrained(model_info='quartznet.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x .nemo_tmp/\n",
      "x .nemo_tmp/JasperDecoderForCTC.pt\n",
      "x .nemo_tmp/JasperEncoder.pt\n",
      "x .nemo_tmp/QuartzNet.yaml\n",
      "x .nemo_tmp/QuartzNet_eval_graph.yaml\n",
      "x .nemo_tmp/QuartzNet_train_graph.yaml\n"
     ]
    }
   ],
   "source": [
    "# \".nemo\" file is just a file with Modules in .onnx format and evaluation graph structure\n",
    "! mv quartznet.nemo quartznet.tar.gz\n",
    "! tar -xvf quartznet.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nemo.core.DeploymentFormat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModels can be used just as any other Neural Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 14:58:38 collections:154] Dataset loaded with 897 files totalling 1.39 hours\n",
      "[NeMo I 2020-05-15 14:58:38 collections:155] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2020-05-15 14:58:38 collections:154] Dataset loaded with 130 files totalling 0.20 hours\n",
      "[NeMo I 2020-05-15 14:58:38 collections:155] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "train_manifest = \"/Users/okuchaiev/Data/an4_dataset/an4_train.json\"\n",
    "val_manifest = \"/Users/okuchaiev/Data/an4_dataset/an4_val.json\"\n",
    "labels = model_definition['labels']\n",
    "data_layer = nemo_asr.AudioToTextDataLayer(manifest_filepath=train_manifest, labels=labels, batch_size=16)\n",
    "data_layerE = nemo_asr.AudioToTextDataLayer(manifest_filepath=val_manifest, labels=labels, batch_size=16)\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(labels))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal, audio_signal_len, transcript, transcript_len = data_layer()\n",
    "log_probs, encoded_len = pre_trained_qn_model(input_signal=audio_signal, length=audio_signal_len)\n",
    "predictions = greedy_decoder(log_probs=log_probs)\n",
    "loss = ctc_loss(log_probs=log_probs, targets=transcript,\n",
    "                input_length=encoded_len, target_length=transcript_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TRAINING \n",
    "tensors_to_evaluate=[predictions, transcript, transcript_len]\n",
    "from functools import partial\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=[loss]+tensors_to_evaluate,\n",
    "    print_func=partial(monitor_asr_train_progress, labels=labels))\n",
    "nf.train(tensors_to_optimize=[loss],\n",
    "                callbacks=[train_callback],\n",
    "                optimizer=\"novograd\",\n",
    "                optimization_params={\"num_epochs\": 30, \"lr\": 1e-2,\n",
    "                                    \"weight_decay\": 1e-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pre_trained_qn_model(audio_file='myaudio.wav')\n",
    "pre_trained_qn_model.transcribe_from_microphone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
