{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeMo Models and JarvisModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okuchaiev/repos/NeMo/nemo/collections/asr/audio_preprocessing.py:48: UserWarning: Could not import torchaudio. Some features might not work.\n",
      "  warnings.warn('Could not import torchaudio. Some features might not work.')\n",
      "/Users/okuchaiev/repos/NeMo/nemo/collections/asr/audio_preprocessing.py:52: UserWarning: Unable to import APEX. Mixed precision and distributed training will not work.\n",
      "  warnings.warn(\"Unable to import APEX. Mixed precision and distributed training will not work.\")\n"
     ]
    }
   ],
   "source": [
    "# Import NeMo and ASR collection\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "nf = nemo.core.NeuralModuleFactory(placement=nemo.core.DeviceType.CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *NeMoModel* is a kind of NeuralModule which contains other neural modules inside it.\n",
    "NeMoModel can have other NeuralModules inside and their mode, and topology of connections can\n",
    "depend on the mode (training, inference, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModel instantiation - method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because NeMoModel is a NeuralModule, regular constructor-based initialization applies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, load the config from YAML file\n",
    "from ruamel.yaml import YAML\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(\"configs/jasper_an4.yaml\") as file:\n",
    "    model_definition = yaml.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-15 16:27:59 features:144] PADDING: 16\n",
      "[NeMo I 2020-04-15 16:27:59 features:152] STFT using conv\n",
      "5771293\n",
      "{'input_signal': <nemo.core.neural_types.neural_type.NeuralType object at 0x13a7bb850>, 'length': <nemo.core.neural_types.neural_type.NeuralType object at 0x13a7bb8d0>}\n"
     ]
    }
   ],
   "source": [
    "qn_model = nemo.collections.asr.models.QuartzNet(\n",
    "            preprocessor_params=model_definition['AudioToMelSpectrogramPreprocessor'],\n",
    "            encoder_params=model_definition['JasperEncoder'],\n",
    "            decoder_params=model_definition['JasperDecoderForCTC'],\n",
    "        )\n",
    "print(qn_model.num_weights)\n",
    "print(qn_model.input_ports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because NeMoModel is a NeuralModule, regular config import/export work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-15 16:28:02 neural_modules:273] Configuration of module 5efb29d4-aefd-45fd-bf51-98bb7fff04eb (QuartzNet) exported to qn.yaml\n",
      "[NeMo I 2020-04-15 16:28:03 features:144] PADDING: 16\n",
      "[NeMo I 2020-04-15 16:28:03 features:152] STFT using conv\n",
      "[NeMo I 2020-04-15 16:28:03 neural_modules:374] Instantiated a new Neural Module of type `QuartzNet` using configuration loaded from the `qn.yaml` file\n",
      "5771293\n"
     ]
    }
   ],
   "source": [
    "qn_model.export_to_config(\"qn.yaml\")\n",
    "qn_model2 = nemo.collections.asr.models.QuartzNet.import_from_config(config_file=\"qn.yaml\")\n",
    "print(qn_model2.num_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModel instantiation - method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-04-15 16:28:06 quartznet:121] THIS METHOD IS NOT DONE YET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuartzNet15x5-En-BASE\n",
      "QuartzNet15x5-Zh-BASE\n"
     ]
    }
   ],
   "source": [
    "# List all available models from NGC\n",
    "for checkpoint in nemo.collections.asr.models.QuartzNet.list_pretrained_models():\n",
    "    print(checkpoint.pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-04-15 16:28:07 quartznet:144] THIS METHOD IS NOT DONE YET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-15 16:28:07 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.11.0b0/QuartzNet15x5-En-BASE/JasperEncoder-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-04-15 16:28:07 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.11.0b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-04-15 16:28:07 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.11.0b0/QuartzNet15x5-En-BASE/JasperDecoderForCTC-STEP-243800.pt. Re-using\n",
      "[NeMo I 2020-04-15 16:28:07 helpers:155] Found existing object /Users/okuchaiev/.nemo_files/NEMO_0.11.0b0/QuartzNet15x5-En-BASE/qn.yaml. Re-using\n",
      "[NeMo I 2020-04-15 16:28:07 quartznet:159] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2020-04-15 16:28:07 features:144] PADDING: 16\n",
      "[NeMo I 2020-04-15 16:28:07 features:152] STFT using conv\n",
      "[NeMo I 2020-04-15 16:28:07 neural_modules:374] Instantiated a new Neural Module of type `QuartzNet` using configuration loaded from the `/Users/okuchaiev/.nemo_files/NEMO_0.11.0b0/QuartzNet15x5-En-BASE/qn.yaml` file\n",
      "[NeMo I 2020-04-15 16:28:07 quartznet:161] Model instantiated with pre-trained weights\n"
     ]
    }
   ],
   "source": [
    "# Automagically go to NGC and instantiate a model and weights\n",
    "pre_trained_qn_model = nemo_asr.models.QuartzNet.from_pretrained(model_info=\"QuartzNet15x5-En-BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to \".nemo\" format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to \".nemo\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-15 16:28:11 neural_modules:273] Configuration of module 68d18a78-dac8-4c49-a099-129082ae3749 (QuartzNet) exported to .FBY2ZJCV6GKM1YGN/.nemo_tmp/QuartzNet.yaml\n",
      "[NeMo I 2020-04-15 16:28:11 neural_modules:781] Exported model QuartzNet to aaaa.nemo\n"
     ]
    }
   ],
   "source": [
    "pre_trained_qn_model.export('aaaa.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-04-15 16:28:14 quartznet:144] THIS METHOD IS NOT DONE YET\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-15 16:28:14 features:144] PADDING: 16\n",
      "[NeMo I 2020-04-15 16:28:14 features:152] STFT using conv\n",
      "[NeMo I 2020-04-15 16:28:14 neural_modules:374] Instantiated a new Neural Module of type `QuartzNet` using configuration loaded from the `306E7MGSGK3Q8JMP/.nemo_tmp/QuartzNet.yaml` file\n"
     ]
    }
   ],
   "source": [
    "new_instance = nemo_asr.models.QuartzNet.from_pretrained(model_info='aaaa.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\".nemo\" file is an arxiv which contains the following:\n",
    "\n",
    "* weights per module\n",
    "* hyperparameters (e.g. constructor arguments) for all modules\n",
    "* topology (e.g. NeuralGraph) description for inference and for trainig modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this instantiates model from disk instead of NGC:\n",
    "pre_trained_qn_model = nemo_asr.models.QuartzNet.from_pretrained(model_info=\"quartznet.nemo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeMoModels can be used just as any other Neural Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_manifest = \"/Users/okuchaiev/Data/an4_dataset/an4_train.json\"\n",
    "val_manifest = \"/Users/okuchaiev/Data/an4_dataset/an4_val.json\"\n",
    "labels = model_definition['labels']\n",
    "data_layer = nemo_asr.AudioToTextDataLayer(manifest_filepath=train_manifest, labels=labels, batch_size=16)\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(labels))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal, audio_signal_len, transcript, transcript_len = data_layer()\n",
    "log_probs, encoded_len = pre_trained_qn_model(audio_signal=audio_signal, a_sig_length=audio_signal_len)\n",
    "predictions = greedy_decoder(log_probs=log_probs)\n",
    "loss = ctc_loss(log_probs=log_probs, targets=transcript,\n",
    "                input_length=encoded_len, target_length=transcript_len)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "audio_signal, audio_signal_len, transcript, transcript_len = data_layerE()\n",
    "log_probs, encoded_len = pre_trained_qn_model(audio_signal=audio_signal, a_sig_length=audio_signal_len)\n",
    "predictions = greedy_decoder(log_probs=log_probs)\n",
    "lossE = ctc_loss(log_probs=log_probs, targets=transcript,\n",
    "                input_length=encoded_len, target_length=transcript_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TRAINING \n",
    "tensors_to_evaluate=[predictions, transcript, transcript_len]\n",
    "from functools import partial\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=[loss]+tensors_to_evaluate,\n",
    "    print_func=partial(monitor_asr_train_progress, labels=labels))\n",
    "nf.train(tensors_to_optimize=[loss],\n",
    "                callbacks=[train_callback],\n",
    "                optimizer=\"novograd\",\n",
    "                optimization_params={\"num_epochs\": 30, \"lr\": 1e-2,\n",
    "                                    \"weight_decay\": 1e-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_qn_model.transcribe('myaudio.wav')\n",
    "pre_trained_qn_model.transcribe_from_microphone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
