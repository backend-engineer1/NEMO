{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Copyright (c) 2020 NVIDIA. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "from functools import partial\n",
    "from os.path import expanduser\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress\n",
    "from nemo.core import NeuralGraph, OperationMode, DeviceType\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.app_state import AppState\n",
    "\n",
    "# Create Neural(Module)Factory, use CPU.\n",
    "nf = nemo.core.NeuralModuleFactory(placement=DeviceType.CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial II: The advanced functionality\n",
    "\n",
    "In this first part of the Neural Graphs (NGs) tutorial we will focus on a more complex example: training of an End-to-End Convolutional Neural Acoustic Model called JASPER. We will build a \"model graph\" and show how we can nest it into another graphs, how we can freeze/unfreeze modules, use graph configuration and save/load graph checkpoints.\n",
    "\n",
    "#### This part covers the following:\n",
    " * how to nest one graph into another\n",
    " * how to serialize and deserialize a graph \n",
    " * how to export and import configuration to/from YAML files\n",
    " * how to save and load graph checkpoints\n",
    " * how to freeze/unfreeze modules in a graph\n",
    "\n",
    "In order to learn more about graph nesting and input/output binding please refer to the first part of the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to \"manifests\" and model configuration files.\n",
    "train_manifest = \"~/TestData/an4_dataset/an4_train.json\"\n",
    "val_manifest = \"~/TestData/an4_dataset/an4_val.json\"\n",
    "model_config_file = \"~/workspace/nemo/examples/asr/configs/jasper_an4.yaml\"\n",
    "\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(expanduser(model_config_file)) as f:\n",
    "    config = yaml.load(f)\n",
    "# Get vocabulary.\n",
    "vocab = config['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural modules using the Neural Module deserialization feature.\n",
    "data_layer = nemo_asr.AudioToTextDataLayer.deserialize(\n",
    "    config[\"AudioToTextDataLayer_train\"], overwrite_params={\"manifest_filepath\": train_manifest, \"batch_size\": 16},\n",
    ")\n",
    "\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor.deserialize(config[\"AudioToMelSpectrogramPreprocessor\"])\n",
    "\n",
    "jasper_encoder = nemo_asr.JasperEncoder.deserialize(config[\"JasperEncoder\"])\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC.deserialize(\n",
    "    config[\"JasperDecoderForCTC\"], overwrite_params={\"num_classes\": len(vocab)}\n",
    ")\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(vocab))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Jasper \"model\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.both, name=\"jasper\") as Jasper:\n",
    "    # Copy one input port definitions - using \"user\" port names.\n",
    "    Jasper.inputs[\"input\"] = data_preprocessor.input_ports[\"input_signal\"]\n",
    "    # Bind selected inputs - bind other using the default port name.\n",
    "    i_processed_signal, i_processed_signal_len = data_preprocessor(input_signal=Jasper.inputs[\"input\"], length=Jasper)\n",
    "    i_encoded, i_encoded_len = jasper_encoder(audio_signal=i_processed_signal, length=i_processed_signal_len)\n",
    "    i_log_probs = jasper_decoder(encoder_output=i_encoded)\n",
    "    # Bind selected outputs - using \"user\" port names.\n",
    "    Jasper.outputs[\"log_probs\"] = i_log_probs\n",
    "    Jasper.outputs[\"encoded_len\"] = i_encoded_len\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(Jasper.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize graph\n",
    "serialized_jasper = Jasper.serialize()\n",
    "logging.info(\"Serialized JasperNet:\\n {}\".format(serialized_jasper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize decoder.\n",
    "logging.info(\"Serialized Jasper Decoder:\\n {}\".format(jasper_decoder.serialize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also export the serialized configuration to a file.\n",
    "Jasper.export_to_config(\"my_jasper.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the lists of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete everything - aside of jasper encoder, just as a test to show that reusing work! ;)\n",
    "del Jasper\n",
    "del data_preprocessor\n",
    "del jasper_encoder #\n",
    "del jasper_decoder\n",
    "\n",
    "# In \"pure\" python - that will remove ALL existing references (bot registries are Dicts with weak references!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize graph - create a copy of the JASPER \"model\".\n",
    "# Please note that the modules exist, so we must enable the graph to \"reuse\" them.\n",
    "# (Commenting out reuse_existing_modules will raise a KeyError.)\n",
    "jasper_copy = NeuralGraph.deserialize(serialized_jasper, reuse_existing_modules=True)\n",
    "serialized_jasper_copy = jasper_copy.serialize()\n",
    "assert serialized_jasper == serialized_jasper_copy # THE SAME! Please note name of the graph is not exported.\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(jasper_copy.summary())\n",
    "\n",
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativelly, import a copy of the JASPER \"model\" from config.\n",
    "jasper_copy = NeuralGraph.import_from_config(\"my_jasper.yml\", reuse_existing_modules=True, name=\"jasper_copy2\")\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(jasper_copy.summary())\n",
    "\n",
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"training\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.training) as training_graph:\n",
    "    # Create the \"implicit\" training graph.\n",
    "    o_audio_signal, o_audio_signal_len, o_transcript, o_transcript_len = data_layer()\n",
    "    # Use Jasper module as any other neural module.\n",
    "    o_log_probs, o_encoded_len = jasper_copy(input=o_audio_signal, length=o_audio_signal_len)\n",
    "    o_predictions = greedy_decoder(log_probs=o_log_probs)\n",
    "    o_loss = ctc_loss(\n",
    "        log_probs=o_log_probs, targets=o_transcript, input_length=o_encoded_len, target_length=o_transcript_len\n",
    "    )\n",
    "    # Set graph output.\n",
    "    training_graph.outputs[\"o_loss\"] = o_loss\n",
    "    # training_graph.outputs[\"o_predictions\"] = o_predictions # DOESN'T WORK!\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training callback.\n",
    "tensors_to_evaluate = [o_loss, o_predictions, o_transcript, o_transcript_len]\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=tensors_to_evaluate, print_func=partial(monitor_asr_train_progress, labels=vocab), step_freq=1\n",
    ")\n",
    "\n",
    "# Train the graph.\n",
    "nf.train(\n",
    "    # tensors_to_optimize=[o_loss, o_predictions], # DOESN'T WORK!\n",
    "    # tensors_to_optimize=[o_loss],\n",
    "    training_graph=training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[train_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, I can save the graph checkpoint!\n",
    "jasper_copy.save_to(\"my_jasper.chkpt\")#, module_names=[\"jasperencoder0\"])\n",
    "# Please note only \"trainable\" modules will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case saving the whole graph should result in the same checkpoint...\n",
    "training_graph.export_to_config(\"my_whole_graph.yml\")\n",
    "training_graph.save_to(\"my_whole_graph.chkpt\")\n",
    "\n",
    "# BUT !! class GreedyCTCDecoder(TrainableNM) !! so:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Greedy decoder has actually 0! trainable parameters, and, moreover this is its :\n",
    "    def forward(self, log_probs):\n",
    "        with torch.no_grad(): # !!!!\n",
    "            argmx = log_probs.argmax(dim=-1, keepdim=False)\n",
    "            return argmx\n",
    "\n",
    "# BTW. This also triggers a question of using no_grad()\n",
    "# in (NonTrainable) modules that are NOT TERMINAL NODES of the graph \n",
    "# (requires_grad = False VS torch.no_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, I can load everything and continue training.\n",
    "new_training_graph = NeuralGraph.import_from_config(\"my_whole_graph.yml\", reuse_existing_modules=True)\n",
    "\n",
    "# Let's restore only the encoder\n",
    "new_training_graph.restore_from(\"my_whole_graph.chkpt\", module_names=[\"jasperencoder0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or maybe not...\n",
    "# Let's restore only the encoder\n",
    "new_training_graph.restore_from(\"my_whole_graph.chkpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogically - create a loss callback.\n",
    "loss_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=[new_training_graph.output_tensors[\"o_loss\"]],\n",
    "    print_func=lambda x: logging.info(f'Train Loss: {str(x[0].item())}'), step_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And  what will happen if we will freeze our graph?\n",
    "training_graph.freeze() #we can also freeze a subset, using \"module_names=[]\"\"\n",
    "# Let us finetune only the decoder.\n",
    "training_graph.unfreeze(module_names=[\"jasperdecoderforctc0\"])\n",
    "\n",
    "# Ok, let us see what the graph looks like now.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And continue training...\n",
    "nf.reset_trainer() # I do not understand why do I have to \"reset the trainer\" when calling train() function again :]\n",
    "nf.train(\n",
    "    training_graph=new_training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[loss_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")\n",
    "\n",
    "# This will throw an error as all trainable modules are frozen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Graph plans and extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Long-term goal: \"training with graphs\" (since November 2019;])\n",
    "\n",
    "### training with training/evaluation graphs\n",
    " * train(training_graph=graph1, evaluation_graph=graph2 [OPTIONAL], ...)\n",
    "\n",
    "### Expanded: training with callbacks \n",
    " * train(training_graph=graph1, training_callbacks=callbacks1 [OPTIONAL], evaluation_graph=graph2 [OPTIONAL], evaluation_callbacks=callbacks2 [OPTIONAL], ...)\n",
    "\n",
    "### Inference/evaluation\n",
    " * infer(evaluation_graph=graph2, ...)\n",
    "\n",
    "### Expanded: inference with callbacks \n",
    " * infer(evaluation_graph=graph2, evaluation_callbacks=callbacks2 [OPTIONAL], ...)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \"Other main\" graph actions\n",
    "\n",
    " * inputs/outputs binding [DONE]\n",
    " * graph nesting [DONE]\n",
    " * import_from_config()/export_to_config() [DONE]\n",
    " * serialize()/deserialize() [DONE]\n",
    " * save_to()/restore_from() [DONE]\n",
    " \n",
    " \n",
    "## 3. \"Partial\" graph actions\n",
    "### (will be used in the \"main actions\", but also could be called by the user directly)\n",
    "\n",
    " * freeze()/unfreeze() [DONE]\n",
    " * is_valid()\n",
    " * to(device)\n",
    " * graph nesting \"with duplication\" (@duplicate)\n",
    " * get_batch() -> batch\n",
    " * forward(batch) # Evelina's \"infer with user input\" (Complete Dialog Pipeline)\n",
    " * backward() (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo-env",
   "language": "python",
   "name": "nemo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
