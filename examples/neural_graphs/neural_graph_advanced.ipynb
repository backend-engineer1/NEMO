{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkornuta/workspace/nemo/nemo/collections/asr/audio_preprocessing.py:57: UserWarning: Could not import torchaudio. Some features might not work.\n",
      "  warnings.warn('Could not import torchaudio. Some features might not work.')\n",
      "/Users/tkornuta/workspace/nemo/nemo/collections/asr/audio_preprocessing.py:61: UserWarning: Unable to import APEX. Mixed precision and distributed training will not work.\n",
      "  warnings.warn(\"Unable to import APEX. Mixed precision and distributed training will not work.\")\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Copyright (c) 2020 NVIDIA. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "from functools import partial\n",
    "from os.path import expanduser, join, abspath, dirname, exists\n",
    "import tarfile\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress\n",
    "from nemo.core import NeuralGraph, OperationMode, DeviceType\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.app_state import AppState\n",
    "\n",
    "# Create Neural(Module)Factory, use CPU.\n",
    "nf = nemo.core.NeuralModuleFactory(placement=DeviceType.CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial II: The advanced functionality\n",
    "\n",
    "In this first part of the Neural Graphs (NGs) tutorial we will focus on a more complex example: training of an End-to-End Convolutional Neural Acoustic Model called JASPER. We will build a \"model graph\" and show how we can nest it into another graphs, how we can freeze/unfreeze modules, use graph configuration and save/load graph checkpoints.\n",
    "\n",
    "#### This part covers the following:\n",
    " * how to nest one graph into another\n",
    " * how to serialize and deserialize a graph\n",
    " * how to export and import configuration to/from YAML files\n",
    " * how to save and load graph checkpoints\n",
    " * how to freeze/unfreeze modules in a graph\n",
    "\n",
    "In order to learn more about graph nesting and input/output binding please refer to the first part of the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-2-a64db28628d1>:3] Looking up for test ASR data\n",
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-2-a64db28628d1>:10] ASR data found in: /Users/tkornuta/workspace/nemo/tests/data/asr\n"
     ]
    }
   ],
   "source": [
    "# Prepare the samples for training JASPER - we will use the data from NeMo tests.\n",
    "data_folder = abspath(\"../../tests/data/\")\n",
    "logging.info(\"Looking up for test ASR data\")\n",
    "if not exists(join(data_folder, \"asr\")):\n",
    "    logging.info(\"Extracting ASR data to: {0}\".format(join(data_folder, \"asr\")))\n",
    "    tar = tarfile.open(join(data_folder, \"asr.tar.gz\"), \"r:gz\")\n",
    "    tar.extractall(path=data_folder)\n",
    "    tar.close()\n",
    "else:\n",
    "    logging.info(\"ASR data found in: {0}\".format(join(data_folder, \"asr\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to model configuration, manifest and sample files.\n",
    "model_config_file = abspath(\"../asr/configs/jasper_an4.yaml\")\n",
    "manifest_path = join(data_folder, 'asr/tarred_an4/tarred_audio_manifest.json')\n",
    "tarpath = join(data_folder, 'asr/tarred_an4/audio_0.tar')\n",
    "\n",
    "# Open the model config file and get vocabulary.\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(expanduser(model_config_file)) as f:\n",
    "    config = yaml.load(f)\n",
    "# Get labels (vocabulary).\n",
    "vocab = config['labels']\n",
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 collections:154] Dataset loaded with 65 files totalling 0.05 hours\n",
      "[NeMo I 2020-05-18 15:36:22 collections:155] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2020-05-18 15:36:22 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-18 15:36:22 features:152] STFT using conv\n",
      "[NeMo I 2020-05-18 15:36:22 neural_modules:441] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor0` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-18 15:36:22 neural_modules:441] Instantiated a new Neural Module named `jasperencoder0` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-18 15:36:22 neural_modules:441] Instantiated a new Neural Module named `jasperdecoderforctc0` of type `JasperDecoderForCTC`\n"
     ]
    }
   ],
   "source": [
    "# Instantiate DataLayer that can load the tarred samples.\n",
    "data_layer = nemo_asr.TarredAudioToTextDataLayer(\n",
    "    audio_tar_filepaths=tarpath, manifest_filepath=manifest_path, labels=vocab, batch_size=16)\n",
    "\n",
    "# Create rest of the modules using the Neural Module deserialization feature.\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor.deserialize(config[\"AudioToMelSpectrogramPreprocessor\"])\n",
    "\n",
    "jasper_encoder = nemo_asr.JasperEncoder.deserialize(config[\"JasperEncoder\"])\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC.deserialize(\n",
    "    config[\"JasperDecoderForCTC\"], overwrite_params={\"num_classes\": vocab_len}\n",
    ")\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=vocab_len)\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-5-ba7109a0a06a>:14] \n",
      "    =================================================================================================================\n",
      "    The `jasper` Neural Graph [OperationMode.both] [NOT COMPLETE]:\n",
      "     * Modules (3):\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "     * Steps (3):\n",
      "        0. audiotomelspectrogrampreprocessor0\n",
      "        1. jasperencoder0\n",
      "        2. jasperdecoderforctc0\n",
      "     * Connections (3):\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "     * Graph Inputs (2):\n",
      "        * input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "     * Graph Outputs (2, manual):\n",
      "        * 2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the Jasper \"model\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.both, name=\"jasper\") as Jasper:\n",
    "    # Copy one input port definitions - using \"user\" port names.\n",
    "    Jasper.inputs[\"input\"] = data_preprocessor.input_ports[\"input_signal\"]\n",
    "    # Bind selected inputs - bind other using the default port name.\n",
    "    i_processed_signal, i_processed_signal_len = data_preprocessor(input_signal=Jasper.inputs[\"input\"], length=Jasper)\n",
    "    i_encoded, i_encoded_len = jasper_encoder(audio_signal=i_processed_signal, length=i_processed_signal_len)\n",
    "    i_log_probs = jasper_decoder(encoder_output=i_encoded)\n",
    "    # Bind selected outputs - using \"user\" port names.\n",
    "    Jasper.outputs[\"log_probs\"] = i_log_probs\n",
    "    Jasper.outputs[\"encoded_len\"] = i_encoded_len\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(Jasper.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-6-a7ab0364999d>:3] Serialized JasperNet:\n",
      "     {'header': {'nemo_core_version': '0.10.2b0', 'full_spec': 'nemo.core.neural_graph.NeuralGraph', 'operation_mode': 'both'}, 'modules': {'audiotomelspectrogrampreprocessor0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.audio_preprocessing.AudioToMelSpectrogramPreprocessor'}, 'init_params': {'sample_rate': 16000, 'window_size': 0.02, 'window_stride': 0.01, 'n_window_size': 320, 'n_window_stride': 160, 'window': 'hann', 'normalize': 'per_feature', 'n_fft': 512, 'preemph': 0.97, 'features': 64, 'lowfreq': 0, 'highfreq': None, 'log': True, 'log_zero_guard_type': 'add', 'log_zero_guard_value': 5.960464477539063e-08, 'dither': 1e-05, 'pad_to': 16, 'frame_splicing': 1, 'stft_conv': True, 'pad_value': 0, 'mag_power': 2.0}}, 'jasperencoder0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperEncoder'}, 'init_params': {'jasper': [{'filters': 128, 'repeat': 1, 'kernel': [11], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [13], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [15], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [17], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [19], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [21], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False}, {'filters': 1024, 'repeat': 1, 'kernel': [1], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False}], 'activation': 'relu', 'feat_in': 64, 'normalization_mode': 'batch', 'residual_mode': 'add', 'norm_groups': -1, 'conv_mask': True, 'frame_splicing': 1, 'init_mode': 'xavier_uniform'}}, 'jasperdecoderforctc0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperDecoderForCTC'}, 'init_params': {'feat_in': 1024, 'num_classes': 28, 'init_mode': 'xavier_uniform'}}}, 'steps': {0: 'audiotomelspectrogrampreprocessor0', 1: 'jasperencoder0', 2: 'jasperdecoderforctc0'}, 'connections': ['0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType', '0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType', '1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation'], 'inputs': ['input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal', 'length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType'], 'outputs': {'mappings': ['2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType', '1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType'], 'type': 'manual'}}\n"
     ]
    }
   ],
   "source": [
    "# Serialize the whole graph.\n",
    "serialized_jasper = Jasper.serialize()\n",
    "logging.info(\"Serialized JasperNet:\\n {}\".format(serialized_jasper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-7-ad20a66ca46f>:2] Serialized Jasper Decoder:\n",
      "     {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperDecoderForCTC'}, 'init_params': {'feat_in': 1024, 'num_classes': 28, 'init_mode': 'xavier_uniform'}}\n"
     ]
    }
   ],
   "source": [
    "# You can also serialize a single NeuralModule, e.g. a decoder.\n",
    "logging.info(\"Serialized Jasper Decoder:\\n {}\".format(jasper_decoder.serialize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 neural_graph:480] Configuration of graph `jasper` (NeuralGraph) exported to 'my_jasper.yml'\n"
     ]
    }
   ],
   "source": [
    "# We can also export the serialized configuration to a file.\n",
    "Jasper.export_to_config(\"my_jasper.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-9-2c61c243edb7>:2] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * jasper (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-9-2c61c243edb7>:3] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * tarredaudiototextdatalayer0 (TarredAudioToTextDataLayer)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display the lists of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 neural_graph:674] Instantiated a new Neural Graph named `neuralgraph0` with mode `OperationMode.both`\n"
     ]
    }
   ],
   "source": [
    "# Deserialize graph - create a copy of the JASPER \"model\".\n",
    "# Please note that the modules exist, so we must enable the graph to \"reuse\" them.\n",
    "# (Commenting out reuse_existing_modules will raise a KeyError.)\n",
    "jasper_copy = NeuralGraph.deserialize(serialized_jasper, reuse_existing_modules=True)\n",
    "serialized_jasper_copy = jasper_copy.serialize()\n",
    "assert serialized_jasper == serialized_jasper_copy # THE SAME! Please note name of the graph is not exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 neural_graph:601] Loading configuration of a new Neural Graph from the `my_jasper.yml` file\n",
      "[NeMo I 2020-05-18 15:36:22 neural_graph:674] Instantiated a new Neural Graph named `jasper_copy` with mode `OperationMode.both`\n",
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-11-24a1dbd84e21>:5] \n",
      "    =================================================================================================================\n",
      "    The `jasper_copy` Neural Graph [OperationMode.both] [NOT COMPLETE]:\n",
      "     * Modules (3):\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "     * Steps (3):\n",
      "        0. audiotomelspectrogrampreprocessor0\n",
      "        1. jasperencoder0\n",
      "        2. jasperdecoderforctc0\n",
      "     * Connections (3):\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "     * Graph Inputs (2):\n",
      "        * input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "     * Graph Outputs (2, manual):\n",
      "        * 2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-11-24a1dbd84e21>:8] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * jasper (3) [OperationMode.both]\n",
      "     * jasper_copy (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-11-24a1dbd84e21>:9] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * tarredaudiototextdatalayer0 (TarredAudioToTextDataLayer)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Alternativelly, import a copy of the JASPER \"model\" from config.\n",
    "jasper_copy = NeuralGraph.import_from_config(\"my_jasper.yml\", reuse_existing_modules=True, name=\"jasper_copy\")\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(jasper_copy.summary())\n",
    "\n",
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 <ipython-input-12-0a2d620d8e6e>:16] \n",
      "    =================================================================================================================\n",
      "    The `neuralgraph0` Neural Graph [OperationMode.training] [COMPLETE]:\n",
      "     * Modules (6):\n",
      "        * `tarredaudiototextdatalayer0` (TarredAudioToTextDataLayer)\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "        * `greedyctcdecoder0` (GreedyCTCDecoder)\n",
      "        * `ctclossnm0` (CTCLossNM)\n",
      "     * Steps (6):\n",
      "        0. tarredaudiototextdatalayer0\n",
      "        1. audiotomelspectrogrampreprocessor0\n",
      "        2. jasperencoder0\n",
      "        3. jasperdecoderforctc0\n",
      "        4. greedyctcdecoder0\n",
      "        5. ctclossnm0\n",
      "     * Connections (10):\n",
      "        * 0.tarredaudiototextdatalayer0.audio_signal->1.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * 0.tarredaudiototextdatalayer0.a_sig_length->1.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 0.tarredaudiototextdatalayer0.transcripts->5.ctclossnm0.targets | axes: (batch, time);  elements_type: LabelsType\n",
      "        * 0.tarredaudiototextdatalayer0.transcript_length->5.ctclossnm0.target_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_signal->2.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_length->2.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 2.jasperencoder0.outputs->3.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "        * 2.jasperencoder0.encoded_lengths->5.ctclossnm0.input_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 3.jasperdecoderforctc0.output->4.greedyctcdecoder0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 3.jasperdecoderforctc0.output->5.ctclossnm0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "     * Graph Inputs (0):\n",
      "     * Graph Outputs (1, manual):\n",
      "        * 5.ctclossnm0.loss->o_loss | axes: None;  elements_type: LossType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the \"training\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.training) as training_graph:\n",
    "    # Create the \"implicit\" training graph.\n",
    "    o_audio_signal, o_audio_signal_len, o_transcript, o_transcript_len = data_layer()\n",
    "    # Use Jasper module as any other neural module.\n",
    "    o_log_probs, o_encoded_len = jasper_copy(input=o_audio_signal, length=o_audio_signal_len)\n",
    "    o_predictions = greedy_decoder(log_probs=o_log_probs)\n",
    "    o_loss = ctc_loss(\n",
    "        log_probs=o_log_probs, targets=o_transcript, input_length=o_encoded_len, target_length=o_transcript_len\n",
    "    )\n",
    "    # Set the graph output.\n",
    "    training_graph.outputs[\"o_loss\"] = o_loss\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:22 callbacks:187] Starting .....\n",
      "[NeMo I 2020-05-18 15:36:22 callbacks:199] Starting epoch 0\n",
      "[NeMo I 2020-05-18 15:36:28 callbacks:224] Step: 0\n",
      "[NeMo I 2020-05-18 15:36:28 helpers:72] Loss: 605.7487182617188\n",
      "[NeMo I 2020-05-18 15:36:28 helpers:73] training_batch_WER:  700.00%\n",
      "[NeMo I 2020-05-18 15:36:28 helpers:74] Prediction: mlcdjmgcg gp pgdlmem tl e ' 'p depepm m pcp p pgfmpmpcgp'cpgipjgpj\n",
      "[NeMo I 2020-05-18 15:36:28 helpers:75] Reference: yes\n",
      "[NeMo I 2020-05-18 15:36:28 callbacks:239] Step time: 5.990310907363892 seconds\n",
      "[NeMo I 2020-05-18 15:36:28 callbacks:207] Finished epoch 0 in 0:00:06.018388\n",
      "[NeMo I 2020-05-18 15:36:28 callbacks:199] Starting epoch 1\n",
      "[NeMo I 2020-05-18 15:36:34 callbacks:224] Step: 1\n",
      "[NeMo I 2020-05-18 15:36:34 helpers:72] Loss: 495.0736389160156\n",
      "[NeMo I 2020-05-18 15:36:34 helpers:73] training_batch_WER:  797.65%\n",
      "[NeMo I 2020-05-18 15:36:34 helpers:74] Prediction: mcdjmgcjlgp pgjlmem tl e ' 'p dep pm m p p p pgmpmpcgp'cxgipjgpj\n",
      "[NeMo I 2020-05-18 15:36:34 helpers:75] Reference: yes\n",
      "[NeMo I 2020-05-18 15:36:34 callbacks:239] Step time: 5.781011343002319 seconds\n",
      "[NeMo I 2020-05-18 15:36:34 callbacks:207] Finished epoch 1 in 0:00:05.805836\n",
      "[NeMo I 2020-05-18 15:36:34 callbacks:199] Starting epoch 2\n",
      "[NeMo I 2020-05-18 15:36:40 callbacks:224] Step: 2\n",
      "[NeMo I 2020-05-18 15:36:40 helpers:72] Loss: 329.9770812988281\n",
      "[NeMo I 2020-05-18 15:36:40 helpers:73] training_batch_WER:  455.29%\n",
      "[NeMo I 2020-05-18 15:36:40 helpers:74] Prediction: mdcdjmegcgp gdlmemem el e e ' de  p p cgm mpcgp cgpjpgpj\n",
      "[NeMo I 2020-05-18 15:36:40 helpers:75] Reference: yes\n",
      "[NeMo I 2020-05-18 15:36:40 callbacks:239] Step time: 5.747957944869995 seconds\n",
      "[NeMo I 2020-05-18 15:36:40 callbacks:207] Finished epoch 2 in 0:00:05.772102\n",
      "[NeMo I 2020-05-18 15:36:40 callbacks:199] Starting epoch 3\n",
      "[NeMo I 2020-05-18 15:36:46 callbacks:224] Step: 3\n",
      "[NeMo I 2020-05-18 15:36:46 helpers:72] Loss: 197.56671142578125\n",
      "[NeMo I 2020-05-18 15:36:46 helpers:73] training_batch_WER:  176.47%\n",
      "[NeMo I 2020-05-18 15:36:46 helpers:74] Prediction: mdcdjmgjgm e l mem e e  e'e e   p sm cgp g gipdpgpj\n",
      "[NeMo I 2020-05-18 15:36:46 helpers:75] Reference: yes\n",
      "[NeMo I 2020-05-18 15:36:46 callbacks:239] Step time: 5.749670743942261 seconds\n",
      "[NeMo I 2020-05-18 15:36:46 callbacks:207] Finished epoch 3 in 0:00:05.773491\n",
      "[NeMo I 2020-05-18 15:36:46 callbacks:199] Starting epoch 4\n",
      "[NeMo I 2020-05-18 15:36:51 callbacks:224] Step: 4\n",
      "[NeMo I 2020-05-18 15:36:51 helpers:72] Loss: 130.45704650878906\n",
      "[NeMo I 2020-05-18 15:36:51 helpers:73] training_batch_WER:  117.65%\n",
      "[NeMo I 2020-05-18 15:36:51 helpers:74] Prediction: mdpgmg e e e  e e    sm c  gipdpgpj\n",
      "[NeMo I 2020-05-18 15:36:51 helpers:75] Reference: yes\n",
      "[NeMo I 2020-05-18 15:36:51 callbacks:239] Step time: 5.649251699447632 seconds\n",
      "[NeMo I 2020-05-18 15:36:51 callbacks:207] Finished epoch 4 in 0:00:05.678685\n",
      "[NeMo I 2020-05-18 15:36:51 callbacks:195] Done in 0:00:29.055673\n"
     ]
    }
   ],
   "source": [
    "# Create training callback.\n",
    "tensors_to_evaluate = [o_loss, o_predictions, o_transcript, o_transcript_len]\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=tensors_to_evaluate, print_func=partial(monitor_asr_train_progress, labels=vocab), step_freq=1\n",
    ")\n",
    "\n",
    "# Train the graph.\n",
    "nf.train(\n",
    "    training_graph=training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[train_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:51 neural_graph:1011] Saved  the 'jasper_copy' graph to a checkpoint `my_jasper.chkpt`:\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params saved \n",
      "      * Module 'jasperdecoderforctc0' (JasperDecoderForCTC) params saved \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Finally, I can save the graph checkpoint!\n",
    "# Note that optionally you can indicate the names of the modules to be saved.\n",
    "jasper_copy.save_to(\"my_jasper.chkpt\")#, module_names=[\"jasperencoder0\"])\n",
    "# Please note only \"trainable\" modules will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:51 neural_graph:480] Configuration of graph `neuralgraph0` (NeuralGraph) exported to 'my_whole_graph.yml'\n",
      "[NeMo I 2020-05-18 15:36:51 neural_graph:1011] Saved  the 'neuralgraph0' graph to a checkpoint `my_whole_graph.chkpt`:\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params saved \n",
      "      * Module 'jasperdecoderforctc0' (JasperDecoderForCTC) params saved \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# In this case saving the whole graph should result in the same checkpoint...\n",
    "training_graph.export_to_config(\"my_whole_graph.yml\")\n",
    "training_graph.save_to(\"my_whole_graph.chkpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:51 neural_graph:601] Loading configuration of a new Neural Graph from the `my_whole_graph.yml` file\n",
      "[NeMo I 2020-05-18 15:36:51 neural_graph:674] Instantiated a new Neural Graph named `neuralgraph1` with mode `OperationMode.training`\n",
      "[NeMo I 2020-05-18 15:36:51 neural_graph:1052] Loading modules constituting the 'neuralgraph0' graph from the `my_whole_graph.chkpt` checkpoint :\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params loaded\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Finally, I can load everything and continue training.\n",
    "new_training_graph = NeuralGraph.import_from_config(\"my_whole_graph.yml\", reuse_existing_modules=True)\n",
    "\n",
    "# Let's restore only the encoder\n",
    "new_training_graph.restore_from(\"my_whole_graph.chkpt\", module_names=[\"jasperencoder0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogically - create a loss callback.\n",
    "loss_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=[new_training_graph.output_tensors[\"o_loss\"]],\n",
    "    print_func=lambda x: logging.info(f'Train Loss: {str(x[0].item())}'), step_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:51 <ipython-input-18-7b917cb48826>:7] \n",
      "    =================================================================================================================\n",
      "    The `neuralgraph0` Neural Graph [OperationMode.training] [COMPLETE]:\n",
      "     * Modules (6):\n",
      "        * `tarredaudiototextdatalayer0` (TarredAudioToTextDataLayer)\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder) [FROZEN]\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "        * `greedyctcdecoder0` (GreedyCTCDecoder)\n",
      "        * `ctclossnm0` (CTCLossNM)\n",
      "     * Steps (6):\n",
      "        0. tarredaudiototextdatalayer0\n",
      "        1. audiotomelspectrogrampreprocessor0\n",
      "        2. jasperencoder0\n",
      "        3. jasperdecoderforctc0\n",
      "        4. greedyctcdecoder0\n",
      "        5. ctclossnm0\n",
      "     * Connections (10):\n",
      "        * 0.tarredaudiototextdatalayer0.audio_signal->1.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * 0.tarredaudiototextdatalayer0.a_sig_length->1.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 0.tarredaudiototextdatalayer0.transcripts->5.ctclossnm0.targets | axes: (batch, time);  elements_type: LabelsType\n",
      "        * 0.tarredaudiototextdatalayer0.transcript_length->5.ctclossnm0.target_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_signal->2.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_length->2.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 2.jasperencoder0.outputs->3.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "        * 2.jasperencoder0.encoded_lengths->5.ctclossnm0.input_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 3.jasperdecoderforctc0.output->4.greedyctcdecoder0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 3.jasperdecoderforctc0.output->5.ctclossnm0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "     * Graph Inputs (0):\n",
      "     * Graph Outputs (1, manual):\n",
      "        * 5.ctclossnm0.loss->o_loss | axes: None;  elements_type: LossType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# So let us freeze the whole graph...\n",
    "training_graph.freeze() #we can also freeze a subset, using \"module_names=[]\"\"\n",
    "# ... and finetune only the decoder.\n",
    "training_graph.unfreeze(module_names=[\"jasperdecoderforctc0\"])\n",
    "\n",
    "# Ok, let us see what the graph looks like now.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-18 15:36:51 callbacks:187] Starting .....\n",
      "[NeMo I 2020-05-18 15:36:51 callbacks:199] Starting epoch 0\n",
      "[NeMo I 2020-05-18 15:36:54 callbacks:224] Step: 0\n",
      "[NeMo I 2020-05-18 15:36:54 <ipython-input-17-fe5652d86be1>:4] Train Loss: 98.85807800292969\n",
      "[NeMo I 2020-05-18 15:36:54 callbacks:239] Step time: 2.189332962036133 seconds\n",
      "[NeMo I 2020-05-18 15:36:54 callbacks:207] Finished epoch 0 in 0:00:02.208335\n",
      "[NeMo I 2020-05-18 15:36:54 callbacks:199] Starting epoch 1\n",
      "[NeMo I 2020-05-18 15:36:56 callbacks:224] Step: 1\n",
      "[NeMo I 2020-05-18 15:36:56 <ipython-input-17-fe5652d86be1>:4] Train Loss: 96.85870361328125\n",
      "[NeMo I 2020-05-18 15:36:56 callbacks:239] Step time: 2.239922285079956 seconds\n",
      "[NeMo I 2020-05-18 15:36:56 callbacks:207] Finished epoch 1 in 0:00:02.273441\n",
      "[NeMo I 2020-05-18 15:36:56 callbacks:199] Starting epoch 2\n",
      "[NeMo I 2020-05-18 15:36:58 callbacks:224] Step: 2\n",
      "[NeMo I 2020-05-18 15:36:58 <ipython-input-17-fe5652d86be1>:4] Train Loss: 93.3438720703125\n",
      "[NeMo I 2020-05-18 15:36:58 callbacks:239] Step time: 2.199843168258667 seconds\n",
      "[NeMo I 2020-05-18 15:36:58 callbacks:207] Finished epoch 2 in 0:00:02.228470\n",
      "[NeMo I 2020-05-18 15:36:58 callbacks:199] Starting epoch 3\n",
      "[NeMo I 2020-05-18 15:37:00 callbacks:224] Step: 3\n",
      "[NeMo I 2020-05-18 15:37:00 <ipython-input-17-fe5652d86be1>:4] Train Loss: 88.83654022216797\n",
      "[NeMo I 2020-05-18 15:37:00 callbacks:239] Step time: 2.0680630207061768 seconds\n",
      "[NeMo I 2020-05-18 15:37:00 callbacks:207] Finished epoch 3 in 0:00:02.098568\n",
      "[NeMo I 2020-05-18 15:37:00 callbacks:199] Starting epoch 4\n",
      "[NeMo I 2020-05-18 15:37:03 callbacks:224] Step: 4\n",
      "[NeMo I 2020-05-18 15:37:03 <ipython-input-17-fe5652d86be1>:4] Train Loss: 84.05590057373047\n",
      "[NeMo I 2020-05-18 15:37:03 callbacks:239] Step time: 2.2276837825775146 seconds\n",
      "[NeMo I 2020-05-18 15:37:03 callbacks:207] Finished epoch 4 in 0:00:02.255908\n",
      "[NeMo I 2020-05-18 15:37:03 callbacks:195] Done in 0:00:11.072573\n"
     ]
    }
   ],
   "source": [
    "# And continue training...\n",
    "nf.reset_trainer()\n",
    "nf.train(\n",
    "    training_graph=new_training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[loss_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")\n",
    "# Please note that this will throw an error if you will freeze all the trainable modules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo-env",
   "language": "python",
   "name": "nemo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
