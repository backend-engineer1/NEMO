{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkornuta/workspace/nemo/nemo/collections/asr/audio_preprocessing.py:57: UserWarning: Could not import torchaudio. Some features might not work.\n",
      "  warnings.warn('Could not import torchaudio. Some features might not work.')\n",
      "/Users/tkornuta/workspace/nemo/nemo/collections/asr/audio_preprocessing.py:61: UserWarning: Unable to import APEX. Mixed precision and distributed training will not work.\n",
      "  warnings.warn(\"Unable to import APEX. Mixed precision and distributed training will not work.\")\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Copyright (c) 2020 NVIDIA. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================\n",
    "from functools import partial\n",
    "from os.path import expanduser\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress\n",
    "from nemo.core import NeuralGraph, OperationMode, DeviceType\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.app_state import AppState\n",
    "\n",
    "# Create Neural(Module)Factory, use CPU.\n",
    "nf = nemo.core.NeuralModuleFactory(placement=DeviceType.CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial II: The advanced functionality\n",
    "\n",
    "In this first part of the Neural Graphs (NGs) tutorial we will focus on a more complex example: training of an End-to-End Convolutional Neural Acoustic Model called JASPER. We will build a \"model graph\" and show how we can nest it into another graphs, how we can freeze/unfreeze modules, use graph configuration and save/load graph checkpoints.\n",
    "\n",
    "#### This part covers the following:\n",
    " * how to nest one graph into another\n",
    " * how to serialize and deserialize a graph \n",
    " * how to export and import configuration to/from YAML files\n",
    " * how to save and load graph checkpoints\n",
    " * how to freeze/unfreeze modules in a graph\n",
    "\n",
    "In order to learn more about graph nesting and input/output binding please refer to the first part of the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to \"manifests\" and model configuration files.\n",
    "train_manifest = \"~/TestData/an4_dataset/an4_train.json\"\n",
    "val_manifest = \"~/TestData/an4_dataset/an4_val.json\"\n",
    "model_config_file = \"~/workspace/nemo/examples/asr/configs/jasper_an4.yaml\"\n",
    "\n",
    "yaml = YAML(typ=\"safe\")\n",
    "with open(expanduser(model_config_file)) as f:\n",
    "    config = yaml.load(f)\n",
    "# Get vocabulary.\n",
    "vocab = config['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 collections:154] Dataset loaded with 897 files totalling 1.39 hours\n",
      "[NeMo I 2020-05-15 11:48:33 collections:155] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2020-05-15 11:48:33 neural_modules:437] Instantiated a new Neural Module named `audiototextdatalayer0` of type `AudioToTextDataLayer`\n",
      "[NeMo I 2020-05-15 11:48:33 features:144] PADDING: 16\n",
      "[NeMo I 2020-05-15 11:48:33 features:152] STFT using conv\n",
      "[NeMo I 2020-05-15 11:48:33 neural_modules:437] Instantiated a new Neural Module named `audiotomelspectrogrampreprocessor0` of type `AudioToMelSpectrogramPreprocessor`\n",
      "[NeMo I 2020-05-15 11:48:33 neural_modules:437] Instantiated a new Neural Module named `jasperencoder0` of type `JasperEncoder`\n",
      "[NeMo I 2020-05-15 11:48:33 neural_modules:437] Instantiated a new Neural Module named `jasperdecoderforctc0` of type `JasperDecoderForCTC`\n"
     ]
    }
   ],
   "source": [
    "# Create neural modules using the Neural Module deserialization feature.\n",
    "data_layer = nemo_asr.AudioToTextDataLayer.deserialize(\n",
    "    config[\"AudioToTextDataLayer_train\"], overwrite_params={\"manifest_filepath\": train_manifest, \"batch_size\": 16},\n",
    ")\n",
    "\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor.deserialize(config[\"AudioToMelSpectrogramPreprocessor\"])\n",
    "\n",
    "jasper_encoder = nemo_asr.JasperEncoder.deserialize(config[\"JasperEncoder\"])\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC.deserialize(\n",
    "    config[\"JasperDecoderForCTC\"], overwrite_params={\"num_classes\": len(vocab)}\n",
    ")\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(vocab))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-4-ba7109a0a06a>:14] \n",
      "    =================================================================================================================\n",
      "    The `jasper` Neural Graph [OperationMode.both]:\n",
      "     * Modules (3):\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "     * Steps (3):\n",
      "        0. audiotomelspectrogrampreprocessor0\n",
      "        1. jasperencoder0\n",
      "        2. jasperdecoderforctc0\n",
      "     * Connections (3):\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "     * Graph Inputs (2):\n",
      "        * input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "     * Graph Outputs (2, manual):\n",
      "        * 2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the Jasper \"model\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.both, name=\"jasper\") as Jasper:\n",
    "    # Copy one input port definitions - using \"user\" port names.\n",
    "    Jasper.inputs[\"input\"] = data_preprocessor.input_ports[\"input_signal\"]\n",
    "    # Bind selected inputs - bind other using the default port name.\n",
    "    i_processed_signal, i_processed_signal_len = data_preprocessor(input_signal=Jasper.inputs[\"input\"], length=Jasper)\n",
    "    i_encoded, i_encoded_len = jasper_encoder(audio_signal=i_processed_signal, length=i_processed_signal_len)\n",
    "    i_log_probs = jasper_decoder(encoder_output=i_encoded)\n",
    "    # Bind selected outputs - using \"user\" port names.\n",
    "    Jasper.outputs[\"log_probs\"] = i_log_probs\n",
    "    Jasper.outputs[\"encoded_len\"] = i_encoded_len\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(Jasper.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-5-1b0206c7cbe6>:3] Serialized JasperNet:\n",
      "     {'header': {'nemo_core_version': '0.10.2b0', 'full_spec': 'nemo.core.neural_graph.NeuralGraph', 'operation_mode': 'both'}, 'modules': {'audiotomelspectrogrampreprocessor0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.audio_preprocessing.AudioToMelSpectrogramPreprocessor'}, 'init_params': {'sample_rate': 16000, 'window_size': 0.02, 'window_stride': 0.01, 'n_window_size': 320, 'n_window_stride': 160, 'window': 'hann', 'normalize': 'per_feature', 'n_fft': 512, 'preemph': 0.97, 'features': 64, 'lowfreq': 0, 'highfreq': None, 'log': True, 'log_zero_guard_type': 'add', 'log_zero_guard_value': 5.960464477539063e-08, 'dither': 1e-05, 'pad_to': 16, 'frame_splicing': 1, 'stft_conv': True, 'pad_value': 0, 'mag_power': 2.0}}, 'jasperencoder0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperEncoder'}, 'init_params': {'jasper': [{'filters': 128, 'repeat': 1, 'kernel': [11], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [13], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [15], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [17], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [19], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True}, {'filters': 256, 'repeat': 1, 'kernel': [21], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False}, {'filters': 1024, 'repeat': 1, 'kernel': [1], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False}], 'activation': 'relu', 'feat_in': 64, 'normalization_mode': 'batch', 'residual_mode': 'add', 'norm_groups': -1, 'conv_mask': True, 'frame_splicing': 1, 'init_mode': 'xavier_uniform'}}, 'jasperdecoderforctc0': {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperDecoderForCTC'}, 'init_params': {'feat_in': 1024, 'num_classes': 28, 'init_mode': 'xavier_uniform'}}}, 'steps': {0: 'audiotomelspectrogrampreprocessor0', 1: 'jasperencoder0', 2: 'jasperdecoderforctc0'}, 'connections': ['0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType', '0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType', '1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation'], 'inputs': ['input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal', 'length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType'], 'outputs': {'mappings': ['2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType', '1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType'], 'type': 'manual'}}\n"
     ]
    }
   ],
   "source": [
    "# Serialize graph\n",
    "serialized_jasper = Jasper.serialize()\n",
    "logging.info(\"Serialized JasperNet:\\n {}\".format(serialized_jasper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-6-b0ca699f7a0d>:2] Serialized Jasper Decoder:\n",
      "     {'header': {'nemo_core_version': '0.10.2b0', 'collection_type': 'asr', 'collection_version': None, 'full_spec': 'nemo.collections.asr.jasper.JasperDecoderForCTC'}, 'init_params': {'feat_in': 1024, 'num_classes': 28, 'init_mode': 'xavier_uniform'}}\n"
     ]
    }
   ],
   "source": [
    "# Serialize decoder.\n",
    "logging.info(\"Serialized Jasper Decoder:\\n {}\".format(jasper_decoder.serialize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 neural_graph:480] Configuration of graph `jasper` (NeuralGraph) exported to 'my_jasper.yml'\n"
     ]
    }
   ],
   "source": [
    "# We can also export the serialized configuration to a file.\n",
    "Jasper.export_to_config(\"my_jasper.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-8-2c61c243edb7>:2] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * jasper (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-8-2c61c243edb7>:3] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "     * audiototextdatalayer0 (AudioToTextDataLayer)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display the lists of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete everything - aside of jasper encoder, just as a test to show that reusing work! ;)\n",
    "del Jasper\n",
    "del data_preprocessor\n",
    "del jasper_encoder #\n",
    "del jasper_decoder\n",
    "\n",
    "# In \"pure\" python - that will remove ALL existing references (bot registries are Dicts with weak references!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-10-09741a5af73d>:2] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * jasper (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:33 <ipython-input-10-09741a5af73d>:3] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "     * audiototextdatalayer0 (AudioToTextDataLayer)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:48 neural_graph:674] Instantiated a new Neural Graph named `neuralgraph1` with mode `OperationMode.both`\n",
      "[NeMo I 2020-05-15 11:48:48 <ipython-input-12-79f4663a0e1e>:8] \n",
      "    =================================================================================================================\n",
      "    The `neuralgraph1` Neural Graph [OperationMode.both]:\n",
      "     * Modules (3):\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "     * Steps (3):\n",
      "        0. audiotomelspectrogrampreprocessor0\n",
      "        1. jasperencoder0\n",
      "        2. jasperdecoderforctc0\n",
      "     * Connections (3):\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "     * Graph Inputs (2):\n",
      "        * input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "     * Graph Outputs (2, manual):\n",
      "        * 2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:48 <ipython-input-12-79f4663a0e1e>:11] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * neuralgraph0 (0) [OperationMode.both]\n",
      "     * neuralgraph1 (3) [OperationMode.both]\n",
      "     * jasper (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:48 <ipython-input-12-79f4663a0e1e>:12] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "     * audiototextdatalayer0 (AudioToTextDataLayer)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Deserialize graph - create a copy of the JASPER \"model\".\n",
    "# PLease note that the modules exist, so we must enable the graph to \"reuse\" them.\n",
    "jasper_copy = NeuralGraph.deserialize(serialized_jasper)#, reuse_existing_modules=True)\n",
    "serialized_jasper_copy = jasper_copy.serialize()\n",
    "assert serialized_jasper == serialized_jasper_copy # THE SAME! Please note name of the graph is not exported.\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(jasper_copy.summary())\n",
    "\n",
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:53 neural_graph:601] Loading configuration of a new Neural Graph from the `my_jasper.yml` file\n",
      "[NeMo I 2020-05-15 11:48:53 neural_graph:674] Instantiated a new Neural Graph named `jasper_copy2` with mode `OperationMode.both`\n",
      "[NeMo I 2020-05-15 11:48:53 <ipython-input-13-57035402f623>:5] \n",
      "    =================================================================================================================\n",
      "    The `jasper_copy2` Neural Graph [OperationMode.both]:\n",
      "     * Modules (3):\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "     * Steps (3):\n",
      "        0. audiotomelspectrogrampreprocessor0\n",
      "        1. jasperencoder0\n",
      "        2. jasperdecoderforctc0\n",
      "     * Connections (3):\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_signal->1.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 0.audiotomelspectrogrampreprocessor0.processed_length->1.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.jasperencoder0.outputs->2.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "     * Graph Inputs (2):\n",
      "        * input->0.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * length->0.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "     * Graph Outputs (2, manual):\n",
      "        * 2.jasperdecoderforctc0.output->log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 1.jasperencoder0.encoded_lengths->encoded_len | axes: (batch,);  elements_type: LengthsType\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:53 <ipython-input-13-57035402f623>:8] \n",
      "    =================================================================================================================\n",
      "    Registry of graphs:\n",
      "     * neuralgraph0 (0) [OperationMode.both]\n",
      "     * jasper (3) [OperationMode.both]\n",
      "     * jasper_copy2 (3) [OperationMode.both]\n",
      "    =================================================================================================================\n",
      "[NeMo I 2020-05-15 11:48:53 <ipython-input-13-57035402f623>:9] \n",
      "    =================================================================================================================\n",
      "    Registry of modules:\n",
      "     * ctclossnm0 (CTCLossNM)\n",
      "     * jasperdecoderforctc0 (JasperDecoderForCTC)\n",
      "     * audiotomelspectrogrampreprocessor0 (AudioToMelSpectrogramPreprocessor)\n",
      "     * audiototextdatalayer0 (AudioToTextDataLayer)\n",
      "     * jasperencoder0 (JasperEncoder)\n",
      "     * greedyctcdecoder0 (GreedyCTCDecoder)\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Alternativelly, import a copy of the JASPER \"model\" from config.\n",
    "jasper_copy = NeuralGraph.import_from_config(\"my_jasper.yml\", reuse_existing_modules=True, name=\"jasper_copy2\")\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(jasper_copy.summary())\n",
    "\n",
    "# Display list of graph and modules\n",
    "logging.info(AppState().graphs.summary())\n",
    "logging.info(AppState().modules.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:56 <ipython-input-14-0a2d620d8e6e>:16] \n",
      "    =================================================================================================================\n",
      "    The `neuralgraph1` Neural Graph [OperationMode.training]:\n",
      "     * Modules (6):\n",
      "        * `audiototextdatalayer0` (AudioToTextDataLayer)\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder)\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC)\n",
      "        * `greedyctcdecoder0` (GreedyCTCDecoder)\n",
      "        * `ctclossnm0` (CTCLossNM)\n",
      "     * Steps (6):\n",
      "        0. audiototextdatalayer0\n",
      "        1. audiotomelspectrogrampreprocessor0\n",
      "        2. jasperencoder0\n",
      "        3. jasperdecoderforctc0\n",
      "        4. greedyctcdecoder0\n",
      "        5. ctclossnm0\n",
      "     * Connections (10):\n",
      "        * 0.audiototextdatalayer0.audio_signal->1.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * 0.audiototextdatalayer0.a_sig_length->1.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 0.audiototextdatalayer0.transcripts->5.ctclossnm0.targets | axes: (batch, time);  elements_type: LabelsType\n",
      "        * 0.audiototextdatalayer0.transcript_length->5.ctclossnm0.target_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_signal->2.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_length->2.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 2.jasperencoder0.outputs->3.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "        * 2.jasperencoder0.encoded_lengths->5.ctclossnm0.input_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 3.jasperdecoderforctc0.output->4.greedyctcdecoder0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 3.jasperdecoderforctc0.output->5.ctclossnm0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "     * Graph Inputs (0):\n",
      "     * Graph Outputs (1, manual):\n",
      "        * 5.ctclossnm0.loss->o_loss | axes: None;  elements_type: LossType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the \"training\" graph.\n",
    "with NeuralGraph(operation_mode=OperationMode.training) as training_graph:\n",
    "    # Create the \"implicit\" training graph.\n",
    "    o_audio_signal, o_audio_signal_len, o_transcript, o_transcript_len = data_layer()\n",
    "    # Use Jasper module as any other neural module.\n",
    "    o_log_probs, o_encoded_len = jasper_copy(input=o_audio_signal, length=o_audio_signal_len)\n",
    "    o_predictions = greedy_decoder(log_probs=o_log_probs)\n",
    "    o_loss = ctc_loss(\n",
    "        log_probs=o_log_probs, targets=o_transcript, input_length=o_encoded_len, target_length=o_transcript_len\n",
    "    )\n",
    "    # Set graph output.\n",
    "    training_graph.outputs[\"o_loss\"] = o_loss\n",
    "    # training_graph.outputs[\"o_predictions\"] = o_predictions # DOESN'T WORK!\n",
    "\n",
    "# Print the summary.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:48:59 callbacks:187] Starting .....\n",
      "[NeMo I 2020-05-15 11:48:59 callbacks:199] Starting epoch 0\n",
      "[NeMo I 2020-05-15 11:49:02 callbacks:224] Step: 0\n",
      "[NeMo I 2020-05-15 11:49:02 helpers:72] Loss: 696.0162353515625\n",
      "[NeMo I 2020-05-15 11:49:02 helpers:73] training_batch_WER:  484.00%\n",
      "[NeMo I 2020-05-15 11:49:02 helpers:74] Prediction:  y zxce amekzkaf'aeapaparpapaaazc' a'ypacp  sa raep ay nzyh pjypmpna'appo aepacyb c a ge'e p p pn\n",
      "[NeMo I 2020-05-15 11:49:02 helpers:75] Reference: j u l i e\n",
      "[NeMo I 2020-05-15 11:49:02 callbacks:239] Step time: 3.7683730125427246 seconds\n",
      "[NeMo I 2020-05-15 11:49:07 callbacks:224] Step: 1\n",
      "[NeMo I 2020-05-15 11:49:07 helpers:72] Loss: 655.5051879882812\n",
      "[NeMo I 2020-05-15 11:49:07 helpers:73] training_batch_WER:  568.27%\n",
      "[NeMo I 2020-05-15 11:49:07 helpers:74] Prediction: x lz ysy m p e y l pl pe pe z myayl lp eayapazqay p ae namamzamz pa s parpa'pyaepaapaeycaxcapwaza zapxapapwazap'rzagaped cpcd znancpzp zn a gse aoac sbgapaparnlcypya eae a pn p ly sy zpepn\n",
      "[NeMo I 2020-05-15 11:49:07 helpers:75] Reference: y w a a m two\n",
      "[NeMo I 2020-05-15 11:49:07 callbacks:239] Step time: 4.716326951980591 seconds\n",
      "[NeMo I 2020-05-15 11:49:11 callbacks:224] Step: 2\n",
      "[NeMo I 2020-05-15 11:49:11 helpers:72] Loss: 486.7196044921875\n",
      "[NeMo I 2020-05-15 11:49:11 helpers:73] training_batch_WER:  677.27%\n",
      "[NeMo I 2020-05-15 11:49:11 helpers:74] Prediction:  ela cna'epv  c ' s d a a zanaz napapapaza apapa pa ' a 'aez a na aezy a a qxa z pacaa planzamhnz ze aralmazppazpa a alal pep p e  p s y ep a babl pan na e la m a y e pn\n",
      "[NeMo I 2020-05-15 11:49:11 helpers:75] Reference: b a i q w eight\n",
      "[NeMo I 2020-05-15 11:49:11 callbacks:239] Step time: 4.256508111953735 seconds\n",
      "[NeMo I 2020-05-15 11:49:16 callbacks:224] Step: 3\n",
      "[NeMo I 2020-05-15 11:49:16 helpers:72] Loss: 436.18768310546875\n",
      "[NeMo I 2020-05-15 11:49:16 helpers:73] training_batch_WER:  523.30%\n",
      "[NeMo I 2020-05-15 11:49:16 helpers:74] Prediction:  zyazna a a iam a  a nanaeaa z e l a ln a za p aseaazam na zn na laaz  aea el a  l a p p p pn\n",
      "[NeMo I 2020-05-15 11:49:16 helpers:75] Reference: enter seven two one six\n",
      "[NeMo I 2020-05-15 11:49:16 callbacks:239] Step time: 4.2603819370269775 seconds\n",
      "[NeMo I 2020-05-15 11:49:20 callbacks:224] Step: 4\n",
      "[NeMo I 2020-05-15 11:49:20 helpers:72] Loss: 270.54290771484375\n",
      "[NeMo I 2020-05-15 11:49:20 helpers:73] training_batch_WER:  284.69%\n",
      "[NeMo I 2020-05-15 11:49:20 helpers:74] Prediction: sp aaeaan a a ala ea aa e ae a e e '  a e p\n",
      "[NeMo I 2020-05-15 11:49:20 helpers:75] Reference: two six eight four six five eight\n",
      "[NeMo I 2020-05-15 11:49:20 callbacks:239] Step time: 3.912882089614868 seconds\n",
      "[NeMo I 2020-05-15 11:49:20 callbacks:207] Finished epoch 0 in 0:00:21.105558\n",
      "[NeMo I 2020-05-15 11:49:20 callbacks:195] Done in 0:00:21.107171\n"
     ]
    }
   ],
   "source": [
    "# Create training callback.\n",
    "tensors_to_evaluate = [o_loss, o_predictions, o_transcript, o_transcript_len]\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=tensors_to_evaluate, print_func=partial(monitor_asr_train_progress, labels=vocab), step_freq=1\n",
    ")\n",
    "\n",
    "# Train the graph.\n",
    "nf.train(\n",
    "    # tensors_to_optimize=[o_loss, o_predictions], # DOESN'T WORK!\n",
    "    # tensors_to_optimize=[o_loss],\n",
    "    training_graph=training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[train_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:20 neural_graph:1007] Saved  the 'jasper_copy2' graph to a checkpoint `my_jasper.chkpt`:\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params saved \n",
      "      * Module 'jasperdecoderforctc0' (JasperDecoderForCTC) params saved \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Finally, I can save the graph checkpoint!\n",
    "jasper_copy.save_to(\"my_jasper.chkpt\")#, module_names=[\"jasperencoder0\"])\n",
    "# Please note only \"trainable\" modules will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:20 neural_graph:480] Configuration of graph `neuralgraph1` (NeuralGraph) exported to 'my_whole_graph.yml'\n",
      "[NeMo I 2020-05-15 11:49:20 neural_graph:1007] Saved  the 'neuralgraph1' graph to a checkpoint `my_whole_graph.chkpt`:\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params saved \n",
      "      * Module 'jasperdecoderforctc0' (JasperDecoderForCTC) params saved \n",
      "      * Module 'greedyctcdecoder0' (GreedyCTCDecoder) params saved \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# In this case saving the whole graph should result in the same checkpoint...\n",
    "training_graph.export_to_config(\"my_whole_graph.yml\")\n",
    "training_graph.save_to(\"my_whole_graph.chkpt\")\n",
    "\n",
    "# BUT !! class GreedyCTCDecoder(TrainableNM) !! so:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Greedy decoder has actually 0! trainable parameters, and, moreover this is its :\n",
    "    def forward(self, log_probs):\n",
    "        with torch.no_grad(): # !!!!\n",
    "            argmx = log_probs.argmax(dim=-1, keepdim=False)\n",
    "            return argmx\n",
    "\n",
    "# BTW. This also triggers a question of using no_grad()\n",
    "# in (NonTrainable) modules that are NOT TERMINAL NODES of the graph \n",
    "# (requires_grad = False VS torch.no_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:20 neural_graph:601] Loading configuration of a new Neural Graph from the `my_whole_graph.yml` file\n",
      "[NeMo I 2020-05-15 11:49:20 neural_graph:674] Instantiated a new Neural Graph named `neuralgraph2` with mode `OperationMode.training`\n",
      "[NeMo I 2020-05-15 11:49:20 neural_graph:1048] Loading modules constituting the 'neuralgraph1' graph from the `my_whole_graph.chkpt` checkpoint :\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params loaded\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Finally, I can load everything and continue training.\n",
    "new_training_graph = NeuralGraph.import_from_config(\"my_whole_graph.yml\", reuse_existing_modules=True)\n",
    "\n",
    "# Let's restore only the encoder\n",
    "new_training_graph.restore_from(\"my_whole_graph.chkpt\", module_names=[\"jasperencoder0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:20 neural_graph:1048] Loading modules constituting the 'neuralgraph1' graph from the `my_whole_graph.chkpt` checkpoint :\n",
      "      * Module 'jasperencoder0' (JasperEncoder) params loaded\n",
      "      * Module 'jasperdecoderforctc0' (JasperDecoderForCTC) params loaded\n",
      "      * Module 'greedyctcdecoder0' (GreedyCTCDecoder) params loaded\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Or maybe not...\n",
    "# Let's restore only the encoder\n",
    "new_training_graph.restore_from(\"my_whole_graph.chkpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogically - create a loss callback.\n",
    "loss_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    tensors=[new_training_graph.output_tensors[\"o_loss\"]],\n",
    "    print_func=lambda x: logging.info(f'Train Loss: {str(x[0].item())}'), step_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:51 <ipython-input-23-f4cf4031dfa3>:7] \n",
      "    =================================================================================================================\n",
      "    The `neuralgraph1` Neural Graph [OperationMode.training]:\n",
      "     * Modules (6):\n",
      "        * `audiototextdatalayer0` (AudioToTextDataLayer)\n",
      "        * `audiotomelspectrogrampreprocessor0` (AudioToMelSpectrogramPreprocessor)\n",
      "        * `jasperencoder0` (JasperEncoder) [FROZEN]\n",
      "        * `jasperdecoderforctc0` (JasperDecoderForCTC) [FROZEN]\n",
      "        * `greedyctcdecoder0` (GreedyCTCDecoder) [FROZEN]\n",
      "        * `ctclossnm0` (CTCLossNM)\n",
      "     * Steps (6):\n",
      "        0. audiototextdatalayer0\n",
      "        1. audiotomelspectrogrampreprocessor0\n",
      "        2. jasperencoder0\n",
      "        3. jasperdecoderforctc0\n",
      "        4. greedyctcdecoder0\n",
      "        5. ctclossnm0\n",
      "     * Connections (10):\n",
      "        * 0.audiototextdatalayer0.audio_signal->1.audiotomelspectrogrampreprocessor0.input_signal | axes: (batch, time);  elements_type: AudioSignal\n",
      "        * 0.audiototextdatalayer0.a_sig_length->1.audiotomelspectrogrampreprocessor0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 0.audiototextdatalayer0.transcripts->5.ctclossnm0.targets | axes: (batch, time);  elements_type: LabelsType\n",
      "        * 0.audiototextdatalayer0.transcript_length->5.ctclossnm0.target_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_signal->2.jasperencoder0.audio_signal | axes: (batch, dimension, time);  elements_type: MelSpectrogramType\n",
      "        * 1.audiotomelspectrogrampreprocessor0.processed_length->2.jasperencoder0.length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 2.jasperencoder0.outputs->3.jasperdecoderforctc0.encoder_output | axes: (batch, dimension, time);  elements_type: AcousticEncodedRepresentation\n",
      "        * 2.jasperencoder0.encoded_lengths->5.ctclossnm0.input_length | axes: (batch,);  elements_type: LengthsType\n",
      "        * 3.jasperdecoderforctc0.output->4.greedyctcdecoder0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "        * 3.jasperdecoderforctc0.output->5.ctclossnm0.log_probs | axes: (batch, time, dimension);  elements_type: LogprobsType\n",
      "     * Graph Inputs (0):\n",
      "     * Graph Outputs (1, manual):\n",
      "        * 5.ctclossnm0.loss->o_loss | axes: None;  elements_type: LossType\n",
      "    =================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# And  what will happen if we will freeze our graph?\n",
    "training_graph.freeze() #we can also freeze a subset, using \"module_names=[]\"\"\n",
    "# Let us finetune only the decoder.\n",
    "#training_graph.unfreeze(module_names=[\"jasperdecoderforctc0\"])\n",
    "\n",
    "# Ok, let us see what the graph looks like now.\n",
    "logging.info(training_graph.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-05-15 11:49:53 callbacks:187] Starting .....\n",
      "[NeMo I 2020-05-15 11:49:53 callbacks:199] Starting epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ebb0e117079d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"novograd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moptimization_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"max_steps\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/nemo/nemo/core/neural_factory.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, tensors_to_optimize, training_graph, optimizer, optimization_params, callbacks, lr_policy, batches_per_step, stop_on_nan_loss, steps_per_nan_check, synced_batchnorm, synced_batchnorm_groupsize, gradient_predivide, amp_max_loss_scale, reset)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0msynced_batchnorm_groupsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_batchnorm_groupsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mgradient_predivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_predivide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mamp_max_loss_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp_max_loss_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         )\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/nemo/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, tensors_to_optimize, training_graph, optimizer, optimization_params, callbacks, lr_policy, batches_per_step, stop_on_nan_loss, steps_per_nan_check, synced_batchnorm, synced_batchnorm_groupsize, gradient_predivide, amp_max_loss_scale)\u001b[0m\n\u001b[1;32m   1463\u001b[0m                         \u001b[0;31m# Fix (workaround?) enabling to backpropagate gradiens on CPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                             \u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbps_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m                             \u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbps_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# And continue training...\n",
    "nf.reset_trainer() # I do not understand why do I have to \"reset the trainer\" when calling train() function again :]\n",
    "nf.train(\n",
    "    training_graph=new_training_graph,\n",
    "    optimizer=\"novograd\",\n",
    "    callbacks=[loss_callback],\n",
    "    optimization_params={\"max_steps\": 5, \"lr\": 0.01},\n",
    ")\n",
    "\n",
    "# This will throw an error as all trainable modules are frozen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Graph plans and extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Long-term goal: \"training with graphs\" (since November 2019;])\n",
    "\n",
    "### training with training/evaluation graphs\n",
    " * train(training_graph=graph1, evaluation_graph=graph2 [OPTIONAL], ...)\n",
    "\n",
    "### Expanded: training with callbacks \n",
    " * train(training_graph=graph1, training_callbacks=callbacks1 [OPTIONAL], evaluation_graph=graph2 [OPTIONAL], evaluation_callbacks=callbacks2 [OPTIONAL], ...)\n",
    "\n",
    "### Inference/evaluation\n",
    " * infer(evaluation_graph=graph2, ...)\n",
    "\n",
    "### Expanded: inference with callbacks \n",
    " * infer(evaluation_graph=graph2, evaluation_callbacks=callbacks2 [OPTIONAL], ...)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \"Other main\" graph actions\n",
    "\n",
    " * inputs/outputs binding [DONE]\n",
    " * graph nesting [DONE]\n",
    " * import_from_config()/export_to_config() [DONE]\n",
    " * serialize()/deserialize() [DONE]\n",
    " * save_to()/restore_from() [DONE]\n",
    " \n",
    " \n",
    "## 2. \"Partial\" graph actions\n",
    "### (will be used in the \"main actions\", but also could be called by the user directly)\n",
    "\n",
    " * freeze()/unfreeze() [DONE]\n",
    " * is_valid()\n",
    " * to(device)\n",
    " * graph nesting \"with duplication\" (@duplicate)\n",
    " * get_batch() -> batch\n",
    " * forward(batch) # Evelina's \"infer with user input\" (Complete Dialog Pipeline)\n",
    " * backward() (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo-env",
   "language": "python",
   "name": "nemo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
