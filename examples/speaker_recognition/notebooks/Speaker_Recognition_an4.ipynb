{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speaker_Recognition_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUlQMiPZxfS_",
        "colab_type": "code",
        "outputId": "cee17d53-c44c-4821-ebeb-4fa347c316b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
        "\n",
        "Instructions for setting up Colab are as follows:\n",
        "1. Open a new Python 3 notebook.\n",
        "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
        "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
        "4. Run this cell to set up dependencies.\n",
        "\"\"\"\n",
        "# If you're using Google Colab and not running locally, run this cell.\n",
        "!pip install wget\n",
        "!apt-get install sox\n",
        "!pip install nemo_toolkit[asr]==0.10.0b10\n",
        "!pip install unidecode\n",
        "\n",
        "!mkdir configs\n",
        "!wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/master/examples/speaker_recognition/configs/quartznet_spkr_3x2x512_xvector.yaml\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/NeMo/master/scripts/scp_to_manifest.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=d69c9698696a555da36c83dbfbb4a9892524957bf414d8ffddf644b8df672b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 sox\n",
            "0 upgraded, 8 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 760 kB of archives.\n",
            "After this operation, 6,715 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Fetched 760 kB in 1s (605 kB/s)\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Collecting nemo_toolkit[asr]==0.10.0b10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/88/f6fe3391a12e7f0c0289b6df3ccf34d4933bf342657caaeef83fc4f7d78a/nemo_toolkit-0.10.0b10-py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 36.6MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/39/404df5ee608c548dacde43a17faf0248b183fa6163cf9c06aca6a511d760/onnxruntime-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 49.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (3.2)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/ee/bc7bc88fc8449266add978627e90c363069211584b937fd867b0ccc59f09/onnx-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (2.8.1)\n",
            "Collecting ruamel.yaml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/92/59af3e38227b9cc14520bf1e59516d99ceca53e3b8448094248171e9432b/ruamel.yaml-0.16.10-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 57.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (1.5.0+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (1.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (0.6.0+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (2.2.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (1.12.1)\n",
            "Requirement already satisfied: inflect; extra == \"asr\" in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (2.1.0)\n",
            "Collecting unidecode; extra == \"asr\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 59.5MB/s \n",
            "\u001b[?25hCollecting soundfile; extra == \"asr\"\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting sox; extra == \"asr\"\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a0/5bee540554af8376e0313e462629d95bf2f2bc3c8cb60697aa01254e6cf5/sox-1.3.7-py2.py3-none-any.whl\n",
            "Collecting num2words; extra == \"asr\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa; extra == \"asr\" in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[asr]==0.10.0b10) (0.6.3)\n",
            "Collecting marshmallow; extra == \"asr\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/44/bb46a3a5c4609616c8501776ef77048b6b50345289d53d6b60da5dab3aa6/marshmallow-3.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting kaldi-io; extra == \"asr\"\n",
            "  Downloading https://files.pythonhosted.org/packages/66/25/e77b445aed94e41bac6369f448d3a0b60e166e4918a130af2cea19a2e187/kaldi_io-0.9.4-py3-none-any.whl\n",
            "Collecting frozendict; extra == \"asr\"\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Collecting torch-stft; extra == \"asr\"\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/53/8a0114930b53459bdc6b090515636bbba7e080905284fb83c995a29eb709/torch_stft-0.1.4-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from onnxruntime->nemo_toolkit[asr]==0.10.0b10) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->nemo_toolkit[asr]==0.10.0b10) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->nemo_toolkit[asr]==0.10.0b10) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->nemo_toolkit[asr]==0.10.0b10) (3.6.6)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->nemo_toolkit[asr]==0.10.0b10) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nemo_toolkit[asr]==0.10.0b10) (2018.9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->nemo_toolkit[asr]==0.10.0b10) (7.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (0.34.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (0.9.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.7.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (1.14.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.6.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.14.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (2.1.8)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.48.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->nemo_toolkit[asr]==0.10.0b10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->nemo_toolkit[asr]==0.10.0b10) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->nemo_toolkit[asr]==0.10.0b10) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nemo_toolkit[asr]==0.10.0b10) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo_toolkit[asr]==0.10.0b10) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo_toolkit[asr]==0.10.0b10) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo_toolkit[asr]==0.10.0b10) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (2.20)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa; extra == \"asr\"->nemo_toolkit[asr]==0.10.0b10) (0.31.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nemo_toolkit[asr]==0.10.0b10) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->nemo_toolkit[asr]==0.10.0b10) (0.4.8)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp36-none-any.whl size=3149 sha256=d656deed4aa723cb5a28980b70620b97ec5c6b9de080b1315a72c7c044b547b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "Successfully built frozendict\n",
            "Installing collected packages: onnx, onnxruntime, tensorboardX, ruamel.yaml.clib, ruamel.yaml, unidecode, soundfile, sox, num2words, marshmallow, kaldi-io, frozendict, torch-stft, nemo-toolkit\n",
            "Successfully installed frozendict-1.2 kaldi-io-0.9.4 marshmallow-3.6.0 nemo-toolkit-0.10.0b10 num2words-0.5.10 onnx-1.7.0 onnxruntime-1.2.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 soundfile-0.10.3.post1 sox-1.3.7 tensorboardX-2.0 torch-stft-0.1.4 unidecode-1.1.1\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "--2020-05-11 02:14:48--  https://raw.githubusercontent.com/NVIDIA/NeMo/master/examples/speaker_recognition/configs/quartznet_spkr_3x2x512_xvector.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1789 (1.7K) [text/plain]\n",
            "Saving to: ‘configs/quartznet_spkr_3x2x512_xvector.yaml’\n",
            "\n",
            "quartznet_spkr_3x2x 100%[===================>]   1.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-11 02:14:48 (28.4 MB/s) - ‘configs/quartznet_spkr_3x2x512_xvector.yaml’ saved [1789/1789]\n",
            "\n",
            "--2020-05-11 02:14:48--  https://raw.githubusercontent.com/NVIDIA/NeMo/master/scripts/scp_to_manifest.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1742 (1.7K) [text/plain]\n",
            "Saving to: ‘scp_to_manifest.py’\n",
            "\n",
            "scp_to_manifest.py  100%[===================>]   1.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-11 02:14:48 (42.4 MB/s) - ‘scp_to_manifest.py’ saved [1742/1742]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgTR8CMlxu3p",
        "colab_type": "text"
      },
      "source": [
        "# **SPEAKER RECOGNITION** \n",
        "\n",
        "Speaker Recognition (SR) is an broad research area which solves two major tasks: speaker identification (who is speaking?) and speaker verification (is the speaker who she claims to be?). In this work, we focmus on the far-field, text-independent speaker recognition when the identity of the speaker is based on how speech is spoken, not necessarily in what is being said. Typically such SR systems operate on unconstrained speech utterances, which are converted into vector of fixed length, called speaker embedding. Speaker embedding is also used in automatic speech recognition (ASR) and speech synthesis.\n",
        "\n",
        "As goal of most speaker related systems is to get good speaker level embeddings that could help distinguish from other speakers, we shall first train these embeddings in end-to-end manner optimizing the [QuatzNet](https://arxiv.org/abs/1910.10261) based encoder model on cross-entropy loss. We modify the original quartznet based decoder to get these fixed size embeddings irrespective of length of input audio. We employ mean and variance based statistics pooling method to grab these embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzzOC5rpx9y6",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial we shall first train these embeddings on speaker related datasets and then get speaker embeddings from a pretrained network for a new dataset. Since Google Colab has very slow read-write speeds I'll be demonstarting this tutorial using [an4](http://www.speech.cs.cmu.edu/databases/an4/). \n",
        "\n",
        "Instead if you'd like to try on a bigger dataset like [hi-mia](https://arxiv.org/abs/1912.01231) use the [get_hi-mia-data.py](https://github.com/NVIDIA/NeMo/blob/master/scripts/get_hi-mia_data.py) script to download the necessary files, extract them, also re-sample to 16Khz if any of the sample is not at 16Khz. This will take a while so grap a large coffee. We do also provide scripts to score these embeddings for a speaker-verification task for hi-mia dataset. To do that follow this detailed [tutorial](https://nvidia.github.io/NeMo/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO_hAhMx0rwv",
        "colab_type": "code",
        "outputId": "493bd23a-d07a-46db-e634-d38a09f70ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "data_dir = 'data'\n",
        "!mkdir $data_dir\n",
        "import glob\n",
        "import subprocess\n",
        "import tarfile\n",
        "import wget\n",
        "\n",
        "# Download the dataset. This will take a few moments...\n",
        "print(\"******\")\n",
        "if not os.path.exists(data_dir + '/an4_sphere.tar.gz'):\n",
        "    an4_url = 'http://www.speech.cs.cmu.edu/databases/an4/an4_sphere.tar.gz'\n",
        "    an4_path = wget.download(an4_url, data_dir)\n",
        "    print(f\"Dataset downloaded at: {an4_path}\")\n",
        "else:\n",
        "    print(\"Tarfile already exists.\")\n",
        "    an4_path = data_dir + '/an4_sphere.tar.gz'\n",
        "\n",
        "# Untar and convert .sph to .wav (using sox)\n",
        "tar = tarfile.open(an4_path)\n",
        "tar.extractall(path=data_dir)\n",
        "\n",
        "print(\"Converting .sph to .wav...\")\n",
        "sph_list = glob.glob(data_dir + '/an4/**/*.sph', recursive=True)\n",
        "for sph_path in sph_list:\n",
        "    wav_path = sph_path[:-4] + '.wav'\n",
        "    cmd = [\"sox\", sph_path, wav_path]\n",
        "    subprocess.run(cmd)\n",
        "print(\"Finished conversion.\\n******\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "******\n",
            "Dataset downloaded at: data/an4_sphere.tar.gz\n",
            "Converting .sph to .wav...\n",
            "Finished conversion.\n",
            "******\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEKDkOSimsKr",
        "colab_type": "text"
      },
      "source": [
        "Since an4 is not designed for speaker recognition, this facilitates the oppurtunity to demostrate how you can generate manifest files that are necessary for training. These methods can be applied to any dataset to get similar training manifest files. \n",
        "\n",
        "First get a scp file(s) which has all the wav files with absolute path for each of train,dev and test set. This can be easily done by `find` bash command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6nuOFN8Pfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!find $PWD/data/an4/wav/an4_clstk  -iname \"*.wav\" > data/an4/wav/an4_clstk/train_all.scp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7168Z9eXn4st",
        "colab_type": "text"
      },
      "source": [
        "Let's look at first 3 lines of scp file for train. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQupCVpZIvtL",
        "colab_type": "code",
        "outputId": "e45cf645-42fc-4f4f-bd94-964848e04145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!head -n 3 data/an4/wav/an4_clstk/train_all.scp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/an4/wav/an4_clstk/fsrb/an169-fsrb-b.wav\n",
            "/content/data/an4/wav/an4_clstk/fsrb/an166-fsrb-b.wav\n",
            "/content/data/an4/wav/an4_clstk/fsrb/an170-fsrb-b.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN09z0XFoDjN",
        "colab_type": "text"
      },
      "source": [
        "Since we created scp file for train, we use `scp_to_manifest.py` to convert this scp file to manifest and then optionally split the files to train \\& dev for evaluating the models while training by using `--split` flag. So as you guessed we wouldn't be needing `--split` option for test folder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNXZwNexIkAo",
        "colab_type": "code",
        "outputId": "ca06c4be-c0f6-4ec7-8198-a26347ea4b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!python scp_to_manifest.py --scp data/an4/wav/an4_clstk/train_all.scp --id -2 --out data/an4/wav/an4_clstk/all_manifest.json --split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 948/948 [01:16<00:00, 12.39it/s]\n",
            "853\n",
            "wrote data/an4/wav/an4_clstk/train.json\n",
            "wrote data/an4/wav/an4_clstk/dev.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxUL_g77oned",
        "colab_type": "text"
      },
      "source": [
        "Generating scp for test folder and then converting to manifest type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QShlVwEIO64D",
        "colab_type": "code",
        "outputId": "291d7dce-e202-4062-9eee-e43224084cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!find $PWD/data/an4/wav/an4test_clstk  -iname \"*.wav\" > data/an4/wav/an4test_clstk/test_all.scp\n",
        "!python scp_to_manifest.py --scp data/an4/wav/an4test_clstk/test_all.scp --id -2 --out data/an4/wav/an4test_clstk/test.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 130/130 [00:10<00:00, 12.38it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqYvWJd_TuhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dd8e60b-6cf0-4e20-ae19-374441cfb58c"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/NeMo.git\n",
        "os.chdir('NeMo')\n",
        "!bash reinstall.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NeMo'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 27862 (delta 114), reused 126 (delta 65), pack-reused 27650\u001b[K\n",
            "Receiving objects: 100% (27862/27862), 109.50 MiB | 32.59 MiB/s, done.\n",
            "Resolving deltas: 100% (19493/19493), done.\n",
            "Uninstalling stuff\n",
            "Uninstalling nemo-toolkit-0.10.0b10:\n",
            "  Successfully uninstalled nemo-toolkit-0.10.0b10\n",
            "\u001b[33mWARNING: Skipping nemo-asr as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping nemo-nlp as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping nemo-tts as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping nemo-simple-gan as it is not installed.\u001b[0m\n",
            "Installing stuff\n",
            "Obtaining file:///content/NeMo\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.18.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.7.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.0.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.8.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.6.0+cu101)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.12.1)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.16.10)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.13.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.10.0)\n",
            "Collecting html2text\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.1.0)\n",
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/bb/a3e1a441719ebd75c6dac8170d3ddba884b7ee8a5c0f9aefa7297386627a/ipdb-0.13.2.tar.gz\n",
            "Requirement already satisfied: ipython[all] in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (5.5.0)\n",
            "Collecting jupyterlab\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/30/03638fbb348e55af6375916962ddbfca786bd31cff9899b86162e2fc0cda/jupyterlab-2.1.2-py3-none-any.whl (7.8MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaldi-io in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.9.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.6.3)\n",
            "Requirement already satisfied: marshmallow in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.2.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.2.5)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.5.10)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (7.0.0)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.12.0)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (4.41.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.1.1)\n",
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 49.3MB/s \n",
            "\u001b[?25hCollecting black\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/bb/ad34bbc93d1bea3de086d7c59e528d4a503ac8fe318bd1fa48605584c3d2/black-19.10b0-py36-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 16.0MB/s \n",
            "\u001b[?25hCollecting isort[requirements]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.6.4)\n",
            "Collecting pytest-runner\n",
            "  Using cached https://files.pythonhosted.org/packages/16/45/81b5262c0efc08882bdf183b788e6d28e3d684863990996d8b60967d48da/pytest_runner-5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.8.5)\n",
            "Collecting sphinxcontrib-bibtex\n",
            "  Downloading https://files.pythonhosted.org/packages/60/de/831ec5de791ba30b842a26e27c479ed34259fb1823aa681d8028c551f4d0/sphinxcontrib_bibtex-1.0.0-py3-none-any.whl\n",
            "Collecting braceexpand\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/c7/036c23bddf64033b9978803cb9200291b9d3ac87845ba953067bd29d4aa1/braceexpand-0.1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (20.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.10.3.post1)\n",
            "Requirement already satisfied: torch-stft in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.1.4)\n",
            "Collecting webdataset\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/81/07e072bad8df4b7453136d9b6ab8d2ef3787ea554954e1596c47492259eb/webdataset-0.1.21-py3-none-any.whl\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (0.3.1)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (3.6.4)\n",
            "Collecting pypinyin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/ed/001823a563a23d48749d4d6a1f66e73d112960d03c23962e86e554538ea0/pypinyin-0.37.0-py2.py3-none-any.whl (779kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nemo-toolkit==0.10.2b0) (1.4.1)\n",
            "Collecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->nemo-toolkit==0.10.2b0) (3.6.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx->nemo-toolkit==0.10.2b0) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nemo-toolkit==0.10.2b0) (2018.9)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (1.28.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (1.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (0.34.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->nemo-toolkit==0.10.2b0) (46.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->nemo-toolkit==0.10.2b0) (0.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml->nemo-toolkit==0.10.2b0) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->nemo-toolkit==0.10.2b0) (0.22.2.post1)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo-toolkit==0.10.2b0) (1.16.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo-toolkit==0.10.2b0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo-toolkit==0.10.2b0) (0.9.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (0.8.1)\n",
            "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (4.7.3)\n",
            "Collecting nose>=0.10.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (0.4.4)\n",
            "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (5.6.1)\n",
            "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (4.10.1)\n",
            "Collecting ipyparallel; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/03a9189eb39276396309faf28bf833b4328befe4513bbf375b811a36a076/ipyparallel-6.3.0-py3-none-any.whl (199kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (5.0.6)\n",
            "Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (7.5.1)\n",
            "Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from ipython[all]->nemo-toolkit==0.10.2b0) (5.2.2)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->nemo-toolkit==0.10.2b0) (2.11.2)\n",
            "Collecting jupyterlab-server<2.0,>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/c3/87504f2803277a2b609dcd27a0b4f2fc65f1bad181bc9938916847731f29/jupyterlab_server-1.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->nemo-toolkit==0.10.2b0) (4.5.3)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->nemo-toolkit==0.10.2b0) (0.48.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->nemo-toolkit==0.10.2b0) (2.1.8)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->nemo-toolkit==0.10.2b0) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->nemo-toolkit==0.10.2b0) (0.14.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo-toolkit==0.10.2b0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo-toolkit==0.10.2b0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo-toolkit==0.10.2b0) (0.10.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words->nemo-toolkit==0.10.2b0) (0.6.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->nemo-toolkit==0.10.2b0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->nemo-toolkit==0.10.2b0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->nemo-toolkit==0.10.2b0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->nemo-toolkit==0.10.2b0) (2020.4.5.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->nemo-toolkit==0.10.2b0) (7.1.2)\n",
            "Collecting typed-ast>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from black->nemo-toolkit==0.10.2b0) (19.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from black->nemo-toolkit==0.10.2b0) (2019.12.20)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting toml>=0.9.4\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/d0/887c58853bd4b6ffc7aa9cdba4fc57d7b979b45888a6bd47e4568e1cf868/pathspec-0.8.0-py2.py3-none-any.whl\n",
            "Collecting pipreqs; extra == \"requirements\"\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/83/b1560948400a07ec094a15c2f64587b70e1a5ab5f7b375ba902fcab5b6c3/pipreqs-0.4.10-py2.py3-none-any.whl\n",
            "Collecting pip-api; extra == \"requirements\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/ee/7051b80310b72a42128fb221e52d8290b0d892eafbb38d443399fa3ec665/pip_api-0.0.14-py3-none-any.whl (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->nemo-toolkit==0.10.2b0) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->nemo-toolkit==0.10.2b0) (8.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->nemo-toolkit==0.10.2b0) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->nemo-toolkit==0.10.2b0) (1.4.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (1.2.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (2.0.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (2.8.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx->nemo-toolkit==0.10.2b0) (0.15.2)\n",
            "Collecting pybtex-docutils>=0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/97/066aa09efc1a1f969ffc6ca0e697787a3b8eb9e847a9b5973c0f73119318/pybtex_docutils-0.2.2-py2.py3-none-any.whl\n",
            "Collecting pybtex>=0.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2a/11039970561f1bbc74fbaca89b59c26b398a0a70bba8caad553ac779b4f7/pybtex-0.22.2-py2.py3-none-any.whl (279kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 54.6MB/s \n",
            "\u001b[?25hCollecting oset>=0.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/b1/a49498c699a3fda5d635cc1fa222ffc686ea3b5d04b84a3166c4cab0c57b/oset-0.1.3.tar.gz\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->nemo-toolkit==0.10.2b0) (1.14.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from webdataset->nemo-toolkit==0.10.2b0) (1.0.0)\n",
            "Collecting objectio\n",
            "  Downloading https://files.pythonhosted.org/packages/86/e3/a132a91c4e9fd5e59c947263c7ef4e3415640fa151344f858e2def8c1726/objectio-0.2.29-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from webdataset->nemo-toolkit==0.10.2b0) (3.13)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->nemo-toolkit==0.10.2b0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->nemo-toolkit==0.10.2b0) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo-toolkit==0.10.2b0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo-toolkit==0.10.2b0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nemo-toolkit==0.10.2b0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nemo-toolkit==0.10.2b0) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython[all]->nemo-toolkit==0.10.2b0) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython[all]->nemo-toolkit==0.10.2b0) (0.1.9)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (19.0.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (4.6.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (1.9.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (5.3.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (3.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (2.6.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (3.5.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10->jupyterlab->nemo-toolkit==0.10.2b0) (1.1.1)\n",
            "Collecting json5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/4b/c0b4c7e238a98165a0281d6ad52ee4a8401318580d2fc9d3844dda2ef5f7/json5-0.9.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->nemo-toolkit==0.10.2b0) (0.31.0)\n",
            "Collecting yarg\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/90/89a2ff242ccab6a24fbab18dbbabc67c51a6f0ed01f9a0f41689dc177419/yarg-0.1.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from pip-api; extra == \"requirements\"->isort[requirements]->nemo-toolkit==0.10.2b0) (19.3.1)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/4f/6e7353dce0cfde419995117705035c4a0433a08aa7c49219ee589767766a/latexcodec-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->nemo-toolkit==0.10.2b0) (2.20)\n",
            "Collecting typer\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/01/23ad684b9b54bd84530113695e97fca75b597b22a7254843b9a4a2cc6ac2/typer-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->nemo-toolkit==0.10.2b0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nemo-toolkit==0.10.2b0) (3.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->ipython[all]->nemo-toolkit==0.10.2b0) (0.5.1)\n",
            "Building wheels for collected packages: ipdb, progressbar, oset, simplejson, sacremoses\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.2-cp36-none-any.whl size=10522 sha256=5941c5a77132ed2aa83a56682e3572ceb50fa883c656d9ccec3bf6856e8c4398\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/c2/15/793365e3c9318c46ba914263740d90f1fe67f544b979141ce4\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12074 sha256=9090fbb4f177e2e9429fbcb1436a934ee5d603c975e679fa9aeb7ee32d06ea69\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "  Building wheel for oset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oset: filename=oset-0.1.3-cp36-none-any.whl size=9661 sha256=fc0f20069e23a6e610728a85245228c98318f2808fa4eddf63cdb0e01a2cd5cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/87/c8/3dad2dca279f64fb68af5d9908c380fee2f16488a1b1da3499\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114201 sha256=ecf82816a243aa25da3045f5dbbea529b41982595f8d688b59959bafb4786481\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b675e3aaafe7e2b568a546f2e4e5ca99624d6d3142c6e64c83ae00dfdcb5f08d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built ipdb progressbar oset simplejson sacremoses\n",
            "\u001b[31mERROR: jupyterlab-server 1.1.3 has requirement jsonschema>=3.0.1, but you'll have jsonschema 2.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinxcontrib-bibtex 1.0.0 has requirement Sphinx>=2.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html2text, ipdb, json5, jupyterlab-server, jupyterlab, progressbar, sentencepiece, youtokentome, typed-ast, appdirs, toml, pathspec, black, yarg, pipreqs, pip-api, isort, parameterized, pytest-runner, latexcodec, pybtex, pybtex-docutils, oset, sphinxcontrib-bibtex, braceexpand, typer, simplejson, objectio, webdataset, sacremoses, tokenizers, transformers, pypinyin, attrdict, nemo-toolkit, nose, ipyparallel\n",
            "  Running setup.py develop for nemo-toolkit\n",
            "Successfully installed appdirs-1.4.3 attrdict-2.0.1 black-19.10b0 braceexpand-0.1.5 html2text-2020.1.16 ipdb-0.13.2 ipyparallel-6.3.0 isort-4.3.21 json5-0.9.4 jupyterlab-2.1.2 jupyterlab-server-1.1.3 latexcodec-2.0.0 nemo-toolkit nose-1.3.7 objectio-0.2.29 oset-0.1.3 parameterized-0.7.4 pathspec-0.8.0 pip-api-0.0.14 pipreqs-0.4.10 progressbar-2.5 pybtex-0.22.2 pybtex-docutils-0.2.2 pypinyin-0.37.0 pytest-runner-5.2 sacremoses-0.0.43 sentencepiece-0.1.86 simplejson-3.17.0 sphinxcontrib-bibtex-1.0.0 tokenizers-0.7.0 toml-0.10.0 transformers-2.9.0 typed-ast-1.4.1 typer-0.2.1 webdataset-0.1.21 yarg-0.1.9 youtokentome-1.0.6\n",
            "All done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4rBMntjpPph",
        "colab_type": "text"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSWNvdZPIwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "83455882-4924-4d18-afd3-d2c8ee8ed78d"
      },
      "source": [
        "from ruamel.yaml import YAML\n",
        "\n",
        "import nemo\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import copy\n",
        "from functools import partial"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################################################################################\n",
            "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
            "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
            "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
            "################################################################################\n",
            "\n",
            "/content/NeMo/nemo/collections/asr/audio_preprocessing.py:57: UserWarning: Could not import torchaudio. Some features might not work.\n",
            "  warnings.warn('Could not import torchaudio. Some features might not work.')\n",
            "/content/NeMo/nemo/collections/asr/audio_preprocessing.py:61: UserWarning: Unable to import APEX. Mixed precision and distributed training will not work.\n",
            "  warnings.warn(\"Unable to import APEX. Mixed precision and distributed training will not work.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeKfJQ-YpTOv",
        "colab_type": "text"
      },
      "source": [
        "# Building Training and Evaluation DAGs with NeMo\n",
        "Building a model using NeMo consists of \n",
        "\n",
        "1.  Instantiating the neural modules we need\n",
        "2.  specifying the DAG by linking them together.\n",
        "\n",
        "In NeMo, the training and inference pipelines are managed by a NeuralModuleFactory, which takes care of checkpointing, callbacks, and logs, along with other details in training and inference. We set its log_dir argument to specify where our model logs and outputs will be written, and can set other training and inference settings in its constructor. For instance, if we were resuming training from a checkpoint, we would set the argument checkpoint_dir=`<path_to_checkpoint>`.\n",
        "\n",
        "Along with logs in NeMo, you can optionally view the tensorboard logs with the create_tb_writer=True argument to the NeuralModuleFactory. By default all the tensorboard log files will be stored in {log_dir}/tensorboard, but you can change this with the tensorboard_dir argument. One can load tensorboard logs through tensorboard by running tensorboard --logdir=`<path_to_tensorboard dir>` in the terminal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyn2xrR7R1K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp_name = 'quartznet3x1_an4'\n",
        "work_dir = './myExps/'\n",
        "neural_factory = nemo.core.NeuralModuleFactory(\n",
        "    log_dir=work_dir+\"/as4_logdir/\",\n",
        "    checkpoint_dir=\"./myExps/checkpoints/\" + exp_name,\n",
        "    create_tb_writer=True,\n",
        "    random_seed=42,\n",
        "    tensorboard_dir=work_dir+'/tensorboard/',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-juqc40p8KN",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our neural module factory, we can specify our **neural modules and instantiate them**. Here, we load the parameters for each module from the configuration file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC-KPOy-rpLA",
        "colab_type": "code",
        "outputId": "1d902505-6e35-4eb8-aebf-8401c1bdd39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "logging = nemo.logging\n",
        "yaml = YAML(typ=\"safe\")\n",
        "with open('../configs/quartznet_spkr_3x1x512_xvector.yaml') as f:\n",
        "    spkr_params = yaml.load(f)\n",
        "\n",
        "sample_rate = spkr_params[\"sample_rate\"]\n",
        "time_length = spkr_params.get(\"time_length\", 8)\n",
        "logging.info(\"max time length considered for each file is {} sec\".format(time_length))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:21:15 <ipython-input-20-4537deb08e36>:8] max time length considered for each file is 8 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VgzNS1lrrqS",
        "colab_type": "text"
      },
      "source": [
        "Instantiating train data_layer using config arguments. `labels = None` automatically creates output labels from manifest files, if you would like to pass those speaker names you can use the labels option. So while instatilatin eval data_layer we can use data_layer labels as it should both match to same speaker output labels. This comes handy while training on multiple datasets with more than one manifest file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC9QOenNPoUs",
        "colab_type": "code",
        "outputId": "786aac99-57f6-4066-e9a3-4908dc6e3d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train_dl_params = copy.deepcopy(spkr_params[\"AudioToSpeechLabelDataLayer\"])\n",
        "train_dl_params.update(spkr_params[\"AudioToSpeechLabelDataLayer\"][\"train\"])\n",
        "del train_dl_params[\"train\"]\n",
        "del train_dl_params[\"eval\"]\n",
        "\n",
        "batch_size=64\n",
        "data_layer_train = nemo_asr.AudioToSpeechLabelDataLayer(\n",
        "        manifest_filepath='../data/an4/wav/an4_clstk/train.json',\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        time_length=time_length,\n",
        "        **train_dl_params,\n",
        "    )\n",
        "\n",
        "eval_dl_params = copy.deepcopy(spkr_params[\"AudioToSpeechLabelDataLayer\"])\n",
        "eval_dl_params.update(spkr_params[\"AudioToSpeechLabelDataLayer\"][\"eval\"])\n",
        "del eval_dl_params[\"train\"]\n",
        "del eval_dl_params[\"eval\"]\n",
        "\n",
        "data_layer_eval = nemo_asr.AudioToSpeechLabelDataLayer(\n",
        "    manifest_filepath=\"../data/an4/wav/an4_clstk/dev.json\",\n",
        "    labels=data_layer_train.labels,\n",
        "    batch_size=batch_size,\n",
        "    time_length=time_length,\n",
        "    **eval_dl_params,\n",
        ")\n",
        "\n",
        "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
        "        sample_rate=sample_rate, **spkr_params[\"AudioToMelSpectrogramPreprocessor\"],\n",
        "    )\n",
        "encoder = nemo_asr.JasperEncoder(**spkr_params[\"JasperEncoder\"],)\n",
        "\n",
        "decoder = nemo_asr.JasperDecoderForSpkrClass(\n",
        "        feat_in=spkr_params[\"JasperEncoder\"][\"jasper\"][-1][\"filters\"],\n",
        "        num_classes=data_layer_train.num_classes,\n",
        "        pool_mode=spkr_params[\"JasperDecoderForSpkrClass\"]['pool_mode'],\n",
        "        emb_sizes=spkr_params[\"JasperDecoderForSpkrClass\"][\"emb_sizes\"].split(\",\"),\n",
        "    )\n",
        "\n",
        "xent_loss = nemo_asr.CrossEntropyLossNM(weight=None)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:21:16 collections:234] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2020-05-11 02:21:16 collections:237] # 853 files loaded accounting to # 74 labels\n",
            "[NeMo I 2020-05-11 02:21:16 data_layer:962] # of classes :74\n",
            "[NeMo I 2020-05-11 02:21:17 collections:234] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2020-05-11 02:21:17 collections:237] # 95 files loaded accounting to # 74 labels\n",
            "[NeMo I 2020-05-11 02:21:17 data_layer:962] # of classes :74\n",
            "[NeMo I 2020-05-11 02:21:17 features:144] PADDING: 16\n",
            "[NeMo I 2020-05-11 02:21:17 features:165] STFT using torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bAP70DqsXGY",
        "colab_type": "text"
      },
      "source": [
        "The next step is to assemble our training DAG by specifying the inputs to each neural module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1raBGmd5Vshl",
        "colab_type": "code",
        "outputId": "33a128f4-193f-4913-9c82-fd27610dfb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "audio_signal, audio_signal_len, label, label_len = data_layer_train()\n",
        "processed_signal, processed_signal_len = data_preprocessor(input_signal=audio_signal, length=audio_signal_len)\n",
        "encoded, encoded_len = encoder(audio_signal=processed_signal, length=processed_signal_len)\n",
        "logits, _ = decoder(encoder_output=encoded)\n",
        "loss = xent_loss(logits=logits, labels=label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `audio_signal` produced in step 10 by `audiotospeechlabeldatalayer2` to `10_audiotospeechlabeldatalayer2_audio_signal`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `a_sig_length` produced in step 10 by `audiotospeechlabeldatalayer2` to `10_audiotospeechlabeldatalayer2_a_sig_length`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `label` produced in step 10 by `audiotospeechlabeldatalayer2` to `10_audiotospeechlabeldatalayer2_label`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `label_length` produced in step 10 by `audiotospeechlabeldatalayer2` to `10_audiotospeechlabeldatalayer2_label_length`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `processed_signal` produced in step 11 by `audiotomelspectrogrampreprocessor1` to `11_audiotomelspectrogrampreprocessor1_processed_signal`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `processed_length` produced in step 11 by `audiotomelspectrogrampreprocessor1` to `11_audiotomelspectrogrampreprocessor1_processed_length`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `outputs` produced in step 12 by `jasperencoder1` to `12_jasperencoder1_outputs`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `encoded_lengths` produced in step 12 by `jasperencoder1` to `12_jasperencoder1_encoded_lengths`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `logits` produced in step 13 by `jasperdecoderforspkrclass1` to `13_jasperdecoderforspkrclass1_logits`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `embs` produced in step 13 by `jasperdecoderforspkrclass1` to `13_jasperdecoderforspkrclass1_embs`\n",
            "[NeMo W 2020-05-11 02:21:18 graph_outputs:167] Setting unigue name of the default output port `loss` produced in step 14 by `crossentropylossnm1` to `14_crossentropylossnm1_loss`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwnZT8ycsYMa",
        "colab_type": "text"
      },
      "source": [
        "We would like to be able to evaluate our model on the dev set, as well, so let's set up the evaluation DAG.\n",
        "\n",
        "Our evaluation DAG will reuse most of the parts of the training DAG with the exception of the data layer, since we are loading the evaluation data from a different file but evaluating on the same model. Note that if we were using data augmentation in training, we would also leave that out in the evaluation DAG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPPyiNtLWDyf",
        "colab_type": "code",
        "outputId": "3c37a7dd-b85c-4d29-edfe-cfd0cd16abe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "audio_signal_test, audio_len_test, label_test, _ = data_layer_eval()\n",
        "processed_signal_test, processed_len_test = data_preprocessor(\n",
        "            input_signal=audio_signal_test, length=audio_len_test\n",
        "        )\n",
        "encoded_test, encoded_len_test = encoder(audio_signal=processed_signal_test, length=processed_len_test)\n",
        "logits_test, _ = decoder(encoder_output=encoded_test)\n",
        "loss_test = xent_loss(logits=logits_test, labels=label_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `audio_signal` produced in step 15 by `audiotospeechlabeldatalayer3` to `15_audiotospeechlabeldatalayer3_audio_signal`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `a_sig_length` produced in step 15 by `audiotospeechlabeldatalayer3` to `15_audiotospeechlabeldatalayer3_a_sig_length`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `label` produced in step 15 by `audiotospeechlabeldatalayer3` to `15_audiotospeechlabeldatalayer3_label`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `label_length` produced in step 15 by `audiotospeechlabeldatalayer3` to `15_audiotospeechlabeldatalayer3_label_length`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `processed_signal` produced in step 16 by `audiotomelspectrogrampreprocessor1` to `16_audiotomelspectrogrampreprocessor1_processed_signal`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `processed_length` produced in step 16 by `audiotomelspectrogrampreprocessor1` to `16_audiotomelspectrogrampreprocessor1_processed_length`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `outputs` produced in step 17 by `jasperencoder1` to `17_jasperencoder1_outputs`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `encoded_lengths` produced in step 17 by `jasperencoder1` to `17_jasperencoder1_encoded_lengths`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `logits` produced in step 18 by `jasperdecoderforspkrclass1` to `18_jasperdecoderforspkrclass1_logits`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `embs` produced in step 18 by `jasperdecoderforspkrclass1` to `18_jasperdecoderforspkrclass1_embs`\n",
            "[NeMo W 2020-05-11 02:21:19 graph_outputs:167] Setting unigue name of the default output port `loss` produced in step 19 by `crossentropylossnm1` to `19_crossentropylossnm1_loss`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m7dz1-usp1S",
        "colab_type": "text"
      },
      "source": [
        "# Creating CallBacks\n",
        "\n",
        "We would like to be able to monitor our model while it's training, so we use callbacks. In general, callbacks are functions that are called at specific intervals over the course of training or inference, such as at the start or end of every n iterations, epochs, etc. The callbacks we'll be using for this are the SimpleLossLoggerCallback, which reports the training loss (or another metric of your choosing, such as \\% accuracy for speaker recognition tasks), and the EvaluatorCallback, which regularly evaluates the model on the dev set. Both of these callbacks require you to pass in the tensors to be evaluated--these would be the final outputs of the training and eval DAGs above.\n",
        "\n",
        "Another useful callback is the CheckpointCallback, for saving checkpoints at set intervals. We create one here just to demonstrate how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFlXnbRaWTVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nemo.collections.asr.helpers import (\n",
        "    monitor_classification_training_progress,\n",
        "    process_classification_evaluation_batch,\n",
        "    process_classification_evaluation_epoch,\n",
        ")\n",
        "from nemo.utils.lr_policies import CosineAnnealing\n",
        "\n",
        "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
        "        tensors=[loss, logits, label],\n",
        "        print_func=partial(monitor_classification_training_progress, eval_metric=[1]),\n",
        "        step_freq=40,\n",
        "        get_tb_values=lambda x: [(\"train_loss\", x[0])],\n",
        "        tb_writer=neural_factory.tb_writer,\n",
        "    )\n",
        "\n",
        "callbacks = [train_callback]\n",
        "\n",
        "chpt_callback = nemo.core.CheckpointCallback(\n",
        "            folder=\"./myExps/checkpoints/\" + exp_name,\n",
        "            load_from_folder=\"./myExps/checkpoints/\" + exp_name,\n",
        "            step_freq=100,\n",
        "        )\n",
        "callbacks.append(chpt_callback)\n",
        "\n",
        "tagname = \"an4_dev\"\n",
        "eval_callback = nemo.core.EvaluatorCallback(\n",
        "            eval_tensors=[loss_test, logits_test, label_test],\n",
        "            user_iter_callback=partial(process_classification_evaluation_batch, top_k=1),\n",
        "            user_epochs_done_callback=partial(process_classification_evaluation_epoch, tag=tagname),\n",
        "            eval_step=100,  # How often we evaluate the model on the test set\n",
        "            tb_writer=neural_factory.tb_writer,\n",
        "        )\n",
        "\n",
        "callbacks.append(eval_callback)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8EFjLsWs_jM",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model and callbacks set up, how do we run it?\n",
        "\n",
        "Once we create our neural factory and the callbacks for the information that we want to see, we can start training by simply calling the train function on the tensors we want to optimize and our callbacks! Since this notebook is for you to get started, by an4 as dataset is small it would quickly get higher accuracies. For better models use bigger datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHTEtz7yXVMK",
        "colab_type": "code",
        "outputId": "bd53ae06-cd0d-4291-da66-1af3079cbd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "num_epochs=100\n",
        "N = len(data_layer_train)\n",
        "steps_per_epoch = N // batch_size\n",
        "\n",
        "logging.info(\"Number of steps per epoch {}\".format(steps_per_epoch))\n",
        "\n",
        "neural_factory.train(\n",
        "        tensors_to_optimize=[loss],\n",
        "        callbacks=callbacks,\n",
        "        lr_policy=CosineAnnealing(\n",
        "            num_epochs * steps_per_epoch, warmup_steps=0.1 * num_epochs * steps_per_epoch,\n",
        "        ),\n",
        "        optimizer=\"novograd\",\n",
        "        optimization_params={\n",
        "            \"num_epochs\": num_epochs,\n",
        "            \"lr\": 0.01,\n",
        "            \"betas\": (0.95, 0.5),\n",
        "            \"weight_decay\": 0.001,\n",
        "            \"grad_norm_clip\": None,\n",
        "        }\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:21:22 <ipython-input-25-e501be8813ec>:5] Number of steps per epoch 26\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:187] Starting .....\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:359] Found 2 modules with weights:\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:361] JasperEncoder\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:361] JasperDecoderForSpkrClass\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:362] Total model parameters: 11400194\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:311] Found checkpoint folder ./myExps/checkpoints/quartznet3x1_an4. Will attempt to restore checkpoints from it.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[NeMo W 2020-05-11 02:21:22 callbacks:328] Error(s) in loading state_dict for JasperEncoder:\n",
            "    \tUnexpected key(s) in state_dict: \"encoder.1.mconv.4.conv.weight\", \"encoder.1.mconv.5.weight\", \"encoder.1.mconv.5.bias\", \"encoder.1.mconv.5.running_mean\", \"encoder.1.mconv.5.running_var\", \"encoder.1.mconv.5.num_batches_tracked\", \"encoder.2.mconv.4.conv.weight\", \"encoder.2.mconv.5.weight\", \"encoder.2.mconv.5.bias\", \"encoder.2.mconv.5.running_mean\", \"encoder.2.mconv.5.running_var\", \"encoder.2.mconv.5.num_batches_tracked\", \"encoder.3.mconv.4.conv.weight\", \"encoder.3.mconv.5.weight\", \"encoder.3.mconv.5.bias\", \"encoder.3.mconv.5.running_mean\", \"encoder.3.mconv.5.running_var\", \"encoder.3.mconv.5.num_batches_tracked\". \n",
            "[NeMo W 2020-05-11 02:21:22 callbacks:330] Checkpoint folder ./myExps/checkpoints/quartznet3x1_an4 was present but nothing was restored. Continuing training from random initialization.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:21:22 callbacks:199] Starting epoch 0\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:224] Step: 0\n",
            "[NeMo I 2020-05-11 02:21:22 helpers:104] Loss: 5.108186721801758\n",
            "[NeMo I 2020-05-11 02:21:22 helpers:110] training_batch_top@1:  3.1250\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:239] Step time: 0.32698655128479004 seconds\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:21:22 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 4.314\n",
            "[NeMo I 2020-05-11 02:21:22 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 1.0526\n",
            "[NeMo I 2020-05-11 02:21:22 callbacks:450] Evaluation time: 0.36254286766052246 seconds\n",
            "[NeMo I 2020-05-11 02:21:30 callbacks:207] Finished epoch 0 in 0:00:08.636425\n",
            "[NeMo I 2020-05-11 02:21:30 callbacks:199] Starting epoch 1\n",
            "[NeMo I 2020-05-11 02:21:35 callbacks:224] Step: 40\n",
            "[NeMo I 2020-05-11 02:21:35 helpers:104] Loss: 4.767226696014404\n",
            "[NeMo I 2020-05-11 02:21:35 helpers:110] training_batch_top@1:  0.0000\n",
            "[NeMo I 2020-05-11 02:21:35 callbacks:239] Step time: 0.2993435859680176 seconds\n",
            "[NeMo I 2020-05-11 02:21:39 callbacks:207] Finished epoch 1 in 0:00:08.375817\n",
            "[NeMo I 2020-05-11 02:21:39 callbacks:199] Starting epoch 2\n",
            "[NeMo I 2020-05-11 02:21:47 callbacks:224] Step: 80\n",
            "[NeMo I 2020-05-11 02:21:47 helpers:104] Loss: 3.9721498489379883\n",
            "[NeMo I 2020-05-11 02:21:47 helpers:110] training_batch_top@1:  9.5238\n",
            "[NeMo I 2020-05-11 02:21:47 callbacks:239] Step time: 0.17851567268371582 seconds\n",
            "[NeMo I 2020-05-11 02:21:47 callbacks:207] Finished epoch 2 in 0:00:08.285688\n",
            "[NeMo I 2020-05-11 02:21:47 callbacks:199] Starting epoch 3\n",
            "[NeMo I 2020-05-11 02:21:53 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-100.pt\n",
            "[NeMo I 2020-05-11 02:21:53 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:21:54 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 6.347\n",
            "[NeMo I 2020-05-11 02:21:54 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 2.1053\n",
            "[NeMo I 2020-05-11 02:21:54 callbacks:450] Evaluation time: 0.3545536994934082 seconds\n",
            "[NeMo I 2020-05-11 02:21:56 callbacks:207] Finished epoch 3 in 0:00:08.840915\n",
            "[NeMo I 2020-05-11 02:21:56 callbacks:199] Starting epoch 4\n",
            "[NeMo I 2020-05-11 02:22:00 callbacks:224] Step: 120\n",
            "[NeMo I 2020-05-11 02:22:00 helpers:104] Loss: 3.9769184589385986\n",
            "[NeMo I 2020-05-11 02:22:00 helpers:110] training_batch_top@1:  6.2500\n",
            "[NeMo I 2020-05-11 02:22:00 callbacks:239] Step time: 0.2540261745452881 seconds\n",
            "[NeMo I 2020-05-11 02:22:04 callbacks:207] Finished epoch 4 in 0:00:08.078779\n",
            "[NeMo I 2020-05-11 02:22:04 callbacks:199] Starting epoch 5\n",
            "[NeMo I 2020-05-11 02:22:12 callbacks:224] Step: 160\n",
            "[NeMo I 2020-05-11 02:22:12 helpers:104] Loss: 4.384712219238281\n",
            "[NeMo I 2020-05-11 02:22:12 helpers:110] training_batch_top@1:  0.0000\n",
            "[NeMo I 2020-05-11 02:22:12 callbacks:239] Step time: 0.3350028991699219 seconds\n",
            "[NeMo I 2020-05-11 02:22:12 callbacks:207] Finished epoch 5 in 0:00:08.363582\n",
            "[NeMo I 2020-05-11 02:22:12 callbacks:199] Starting epoch 6\n",
            "[NeMo I 2020-05-11 02:22:20 callbacks:207] Finished epoch 6 in 0:00:08.179709\n",
            "[NeMo I 2020-05-11 02:22:20 callbacks:199] Starting epoch 7\n",
            "[NeMo I 2020-05-11 02:22:24 callbacks:224] Step: 200\n",
            "[NeMo I 2020-05-11 02:22:24 helpers:104] Loss: 3.6177968978881836\n",
            "[NeMo I 2020-05-11 02:22:24 helpers:110] training_batch_top@1:  12.5000\n",
            "[NeMo I 2020-05-11 02:22:24 callbacks:239] Step time: 0.21989011764526367 seconds\n",
            "[NeMo I 2020-05-11 02:22:24 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-200.pt\n",
            "[NeMo I 2020-05-11 02:22:24 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:22:24 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 5.465\n",
            "[NeMo I 2020-05-11 02:22:24 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 4.2105\n",
            "[NeMo I 2020-05-11 02:22:24 callbacks:450] Evaluation time: 0.3451523780822754 seconds\n",
            "[NeMo I 2020-05-11 02:22:29 callbacks:207] Finished epoch 7 in 0:00:08.585562\n",
            "[NeMo I 2020-05-11 02:22:29 callbacks:199] Starting epoch 8\n",
            "[NeMo I 2020-05-11 02:22:37 callbacks:224] Step: 240\n",
            "[NeMo I 2020-05-11 02:22:37 helpers:104] Loss: 3.304609537124634\n",
            "[NeMo I 2020-05-11 02:22:37 helpers:110] training_batch_top@1:  9.3750\n",
            "[NeMo I 2020-05-11 02:22:37 callbacks:239] Step time: 0.25638675689697266 seconds\n",
            "[NeMo I 2020-05-11 02:22:37 callbacks:207] Finished epoch 8 in 0:00:08.130643\n",
            "[NeMo I 2020-05-11 02:22:37 callbacks:199] Starting epoch 9\n",
            "[NeMo I 2020-05-11 02:22:45 callbacks:207] Finished epoch 9 in 0:00:08.391451\n",
            "[NeMo I 2020-05-11 02:22:45 callbacks:199] Starting epoch 10\n",
            "[NeMo I 2020-05-11 02:22:49 callbacks:224] Step: 280\n",
            "[NeMo I 2020-05-11 02:22:49 helpers:104] Loss: 2.940448522567749\n",
            "[NeMo I 2020-05-11 02:22:49 helpers:110] training_batch_top@1:  15.6250\n",
            "[NeMo I 2020-05-11 02:22:49 callbacks:239] Step time: 0.3263366222381592 seconds\n",
            "[NeMo I 2020-05-11 02:22:54 callbacks:207] Finished epoch 10 in 0:00:08.356247\n",
            "[NeMo I 2020-05-11 02:22:54 callbacks:199] Starting epoch 11\n",
            "[NeMo I 2020-05-11 02:22:55 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-300.pt\n",
            "[NeMo I 2020-05-11 02:22:55 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:22:56 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 4.552\n",
            "[NeMo I 2020-05-11 02:22:56 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 8.4211\n",
            "[NeMo I 2020-05-11 02:22:56 callbacks:450] Evaluation time: 0.35518956184387207 seconds\n",
            "[NeMo I 2020-05-11 02:23:02 callbacks:224] Step: 320\n",
            "[NeMo I 2020-05-11 02:23:02 helpers:104] Loss: 2.2025306224823\n",
            "[NeMo I 2020-05-11 02:23:02 helpers:110] training_batch_top@1:  18.7500\n",
            "[NeMo I 2020-05-11 02:23:02 callbacks:239] Step time: 0.25630927085876465 seconds\n",
            "[NeMo I 2020-05-11 02:23:02 callbacks:207] Finished epoch 11 in 0:00:08.607157\n",
            "[NeMo I 2020-05-11 02:23:02 callbacks:199] Starting epoch 12\n",
            "[NeMo I 2020-05-11 02:23:11 callbacks:207] Finished epoch 12 in 0:00:08.308593\n",
            "[NeMo I 2020-05-11 02:23:11 callbacks:199] Starting epoch 13\n",
            "[NeMo I 2020-05-11 02:23:14 callbacks:224] Step: 360\n",
            "[NeMo I 2020-05-11 02:23:14 helpers:104] Loss: 2.1003549098968506\n",
            "[NeMo I 2020-05-11 02:23:14 helpers:110] training_batch_top@1:  37.5000\n",
            "[NeMo I 2020-05-11 02:23:14 callbacks:239] Step time: 0.3284027576446533 seconds\n",
            "[NeMo I 2020-05-11 02:23:19 callbacks:207] Finished epoch 13 in 0:00:08.270800\n",
            "[NeMo I 2020-05-11 02:23:19 callbacks:199] Starting epoch 14\n",
            "[NeMo I 2020-05-11 02:23:26 callbacks:224] Step: 400\n",
            "[NeMo I 2020-05-11 02:23:26 helpers:104] Loss: 1.5436031818389893\n",
            "[NeMo I 2020-05-11 02:23:26 helpers:110] training_batch_top@1:  53.1250\n",
            "[NeMo I 2020-05-11 02:23:26 callbacks:239] Step time: 0.3274867534637451 seconds\n",
            "[NeMo I 2020-05-11 02:23:26 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-400.pt\n",
            "[NeMo I 2020-05-11 02:23:26 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:23:27 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 3.486\n",
            "[NeMo I 2020-05-11 02:23:27 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 18.9474\n",
            "[NeMo I 2020-05-11 02:23:27 callbacks:450] Evaluation time: 0.362715482711792 seconds\n",
            "[NeMo I 2020-05-11 02:23:28 callbacks:207] Finished epoch 14 in 0:00:08.561951\n",
            "[NeMo I 2020-05-11 02:23:28 callbacks:199] Starting epoch 15\n",
            "[NeMo I 2020-05-11 02:23:36 callbacks:207] Finished epoch 15 in 0:00:08.339574\n",
            "[NeMo I 2020-05-11 02:23:36 callbacks:199] Starting epoch 16\n",
            "[NeMo I 2020-05-11 02:23:39 callbacks:224] Step: 440\n",
            "[NeMo I 2020-05-11 02:23:39 helpers:104] Loss: 1.486825942993164\n",
            "[NeMo I 2020-05-11 02:23:39 helpers:110] training_batch_top@1:  65.6250\n",
            "[NeMo I 2020-05-11 02:23:39 callbacks:239] Step time: 0.2553281784057617 seconds\n",
            "[NeMo I 2020-05-11 02:23:44 callbacks:207] Finished epoch 16 in 0:00:08.386867\n",
            "[NeMo I 2020-05-11 02:23:44 callbacks:199] Starting epoch 17\n",
            "[NeMo I 2020-05-11 02:23:51 callbacks:224] Step: 480\n",
            "[NeMo I 2020-05-11 02:23:51 helpers:104] Loss: 1.33021080493927\n",
            "[NeMo I 2020-05-11 02:23:51 helpers:110] training_batch_top@1:  50.0000\n",
            "[NeMo I 2020-05-11 02:23:51 callbacks:239] Step time: 0.323352575302124 seconds\n",
            "[NeMo I 2020-05-11 02:23:53 callbacks:207] Finished epoch 17 in 0:00:08.437114\n",
            "[NeMo I 2020-05-11 02:23:53 callbacks:199] Starting epoch 18\n",
            "[NeMo I 2020-05-11 02:23:57 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-500.pt\n",
            "[NeMo I 2020-05-11 02:23:57 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:23:58 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 3.344\n",
            "[NeMo I 2020-05-11 02:23:58 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 26.3158\n",
            "[NeMo I 2020-05-11 02:23:58 callbacks:450] Evaluation time: 0.3493156433105469 seconds\n",
            "[NeMo I 2020-05-11 02:24:01 callbacks:207] Finished epoch 18 in 0:00:08.669834\n",
            "[NeMo I 2020-05-11 02:24:01 callbacks:199] Starting epoch 19\n",
            "[NeMo I 2020-05-11 02:24:04 callbacks:224] Step: 520\n",
            "[NeMo I 2020-05-11 02:24:04 helpers:104] Loss: 0.7730027437210083\n",
            "[NeMo I 2020-05-11 02:24:04 helpers:110] training_batch_top@1:  71.8750\n",
            "[NeMo I 2020-05-11 02:24:04 callbacks:239] Step time: 0.3435370922088623 seconds\n",
            "[NeMo I 2020-05-11 02:24:10 callbacks:207] Finished epoch 19 in 0:00:08.223290\n",
            "[NeMo I 2020-05-11 02:24:10 callbacks:199] Starting epoch 20\n",
            "[NeMo I 2020-05-11 02:24:16 callbacks:224] Step: 560\n",
            "[NeMo I 2020-05-11 02:24:16 helpers:104] Loss: 1.124522089958191\n",
            "[NeMo I 2020-05-11 02:24:16 helpers:110] training_batch_top@1:  65.6250\n",
            "[NeMo I 2020-05-11 02:24:16 callbacks:239] Step time: 0.33164215087890625 seconds\n",
            "[NeMo I 2020-05-11 02:24:18 callbacks:207] Finished epoch 20 in 0:00:08.409886\n",
            "[NeMo I 2020-05-11 02:24:18 callbacks:199] Starting epoch 21\n",
            "[NeMo I 2020-05-11 02:24:26 callbacks:207] Finished epoch 21 in 0:00:08.292919\n",
            "[NeMo I 2020-05-11 02:24:26 callbacks:199] Starting epoch 22\n",
            "[NeMo I 2020-05-11 02:24:29 callbacks:224] Step: 600\n",
            "[NeMo I 2020-05-11 02:24:29 helpers:104] Loss: 0.5278069972991943\n",
            "[NeMo I 2020-05-11 02:24:29 helpers:110] training_batch_top@1:  84.3750\n",
            "[NeMo I 2020-05-11 02:24:29 callbacks:239] Step time: 0.29141974449157715 seconds\n",
            "[NeMo I 2020-05-11 02:24:29 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-600.pt\n",
            "[NeMo I 2020-05-11 02:24:29 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:24:29 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 2.571\n",
            "[NeMo I 2020-05-11 02:24:29 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 33.6842\n",
            "[NeMo I 2020-05-11 02:24:29 callbacks:450] Evaluation time: 0.3441948890686035 seconds\n",
            "[NeMo I 2020-05-11 02:24:35 callbacks:207] Finished epoch 22 in 0:00:08.855196\n",
            "[NeMo I 2020-05-11 02:24:35 callbacks:199] Starting epoch 23\n",
            "[NeMo I 2020-05-11 02:24:42 callbacks:224] Step: 640\n",
            "[NeMo I 2020-05-11 02:24:42 helpers:104] Loss: 0.7339851260185242\n",
            "[NeMo I 2020-05-11 02:24:42 helpers:110] training_batch_top@1:  71.8750\n",
            "[NeMo I 2020-05-11 02:24:42 callbacks:239] Step time: 0.3383514881134033 seconds\n",
            "[NeMo I 2020-05-11 02:24:43 callbacks:207] Finished epoch 23 in 0:00:08.226636\n",
            "[NeMo I 2020-05-11 02:24:43 callbacks:199] Starting epoch 24\n",
            "[NeMo I 2020-05-11 02:24:52 callbacks:207] Finished epoch 24 in 0:00:08.398368\n",
            "[NeMo I 2020-05-11 02:24:52 callbacks:199] Starting epoch 25\n",
            "[NeMo I 2020-05-11 02:24:54 callbacks:224] Step: 680\n",
            "[NeMo I 2020-05-11 02:24:54 helpers:104] Loss: 0.4135192036628723\n",
            "[NeMo I 2020-05-11 02:24:54 helpers:110] training_batch_top@1:  90.6250\n",
            "[NeMo I 2020-05-11 02:24:54 callbacks:239] Step time: 0.3000311851501465 seconds\n",
            "[NeMo I 2020-05-11 02:25:00 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-700.pt\n",
            "[NeMo I 2020-05-11 02:25:00 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:25:00 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 2.536\n",
            "[NeMo I 2020-05-11 02:25:00 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 41.0526\n",
            "[NeMo I 2020-05-11 02:25:00 callbacks:450] Evaluation time: 0.3478126525878906 seconds\n",
            "[NeMo I 2020-05-11 02:25:01 callbacks:207] Finished epoch 25 in 0:00:08.798661\n",
            "[NeMo I 2020-05-11 02:25:01 callbacks:199] Starting epoch 26\n",
            "[NeMo I 2020-05-11 02:25:07 callbacks:224] Step: 720\n",
            "[NeMo I 2020-05-11 02:25:07 helpers:104] Loss: 0.5520279407501221\n",
            "[NeMo I 2020-05-11 02:25:07 helpers:110] training_batch_top@1:  78.1250\n",
            "[NeMo I 2020-05-11 02:25:07 callbacks:239] Step time: 0.2615697383880615 seconds\n",
            "[NeMo I 2020-05-11 02:25:09 callbacks:207] Finished epoch 26 in 0:00:08.425545\n",
            "[NeMo I 2020-05-11 02:25:09 callbacks:199] Starting epoch 27\n",
            "[NeMo I 2020-05-11 02:25:18 callbacks:207] Finished epoch 27 in 0:00:08.403453\n",
            "[NeMo I 2020-05-11 02:25:18 callbacks:199] Starting epoch 28\n",
            "[NeMo I 2020-05-11 02:25:19 callbacks:224] Step: 760\n",
            "[NeMo I 2020-05-11 02:25:19 helpers:104] Loss: 0.23644520342350006\n",
            "[NeMo I 2020-05-11 02:25:19 helpers:110] training_batch_top@1:  93.7500\n",
            "[NeMo I 2020-05-11 02:25:19 callbacks:239] Step time: 0.31917786598205566 seconds\n",
            "[NeMo I 2020-05-11 02:25:26 callbacks:207] Finished epoch 28 in 0:00:08.154995\n",
            "[NeMo I 2020-05-11 02:25:26 callbacks:199] Starting epoch 29\n",
            "[NeMo I 2020-05-11 02:25:31 callbacks:224] Step: 800\n",
            "[NeMo I 2020-05-11 02:25:31 helpers:104] Loss: 0.3160431981086731\n",
            "[NeMo I 2020-05-11 02:25:31 helpers:110] training_batch_top@1:  93.7500\n",
            "[NeMo I 2020-05-11 02:25:31 callbacks:239] Step time: 0.32634449005126953 seconds\n",
            "[NeMo I 2020-05-11 02:25:32 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-800.pt\n",
            "[NeMo I 2020-05-11 02:25:32 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:25:32 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.815\n",
            "[NeMo I 2020-05-11 02:25:32 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 55.7895\n",
            "[NeMo I 2020-05-11 02:25:32 callbacks:450] Evaluation time: 0.3449685573577881 seconds\n",
            "[NeMo I 2020-05-11 02:25:34 callbacks:207] Finished epoch 29 in 0:00:08.784164\n",
            "[NeMo I 2020-05-11 02:25:34 callbacks:199] Starting epoch 30\n",
            "[NeMo I 2020-05-11 02:25:43 callbacks:207] Finished epoch 30 in 0:00:08.247058\n",
            "[NeMo I 2020-05-11 02:25:43 callbacks:199] Starting epoch 31\n",
            "[NeMo I 2020-05-11 02:25:44 callbacks:224] Step: 840\n",
            "[NeMo I 2020-05-11 02:25:44 helpers:104] Loss: 0.17938025295734406\n",
            "[NeMo I 2020-05-11 02:25:44 helpers:110] training_batch_top@1:  93.7500\n",
            "[NeMo I 2020-05-11 02:25:44 callbacks:239] Step time: 0.3259458541870117 seconds\n",
            "[NeMo I 2020-05-11 02:25:51 callbacks:207] Finished epoch 31 in 0:00:08.366057\n",
            "[NeMo I 2020-05-11 02:25:51 callbacks:199] Starting epoch 32\n",
            "[NeMo I 2020-05-11 02:25:56 callbacks:224] Step: 880\n",
            "[NeMo I 2020-05-11 02:25:56 helpers:104] Loss: 0.2969518005847931\n",
            "[NeMo I 2020-05-11 02:25:56 helpers:110] training_batch_top@1:  90.6250\n",
            "[NeMo I 2020-05-11 02:25:56 callbacks:239] Step time: 0.32151222229003906 seconds\n",
            "[NeMo I 2020-05-11 02:25:59 callbacks:207] Finished epoch 32 in 0:00:08.238424\n",
            "[NeMo I 2020-05-11 02:25:59 callbacks:199] Starting epoch 33\n",
            "[NeMo I 2020-05-11 02:26:03 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-900.pt\n",
            "[NeMo I 2020-05-11 02:26:03 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:26:03 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.948\n",
            "[NeMo I 2020-05-11 02:26:03 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 51.5789\n",
            "[NeMo I 2020-05-11 02:26:03 callbacks:450] Evaluation time: 0.34128642082214355 seconds\n",
            "[NeMo I 2020-05-11 02:26:08 callbacks:207] Finished epoch 33 in 0:00:08.801659\n",
            "[NeMo I 2020-05-11 02:26:08 callbacks:199] Starting epoch 34\n",
            "[NeMo I 2020-05-11 02:26:09 callbacks:224] Step: 920\n",
            "[NeMo I 2020-05-11 02:26:09 helpers:104] Loss: 0.2507334351539612\n",
            "[NeMo I 2020-05-11 02:26:09 helpers:110] training_batch_top@1:  96.8750\n",
            "[NeMo I 2020-05-11 02:26:09 callbacks:239] Step time: 0.25838708877563477 seconds\n",
            "[NeMo I 2020-05-11 02:26:17 callbacks:207] Finished epoch 34 in 0:00:08.438140\n",
            "[NeMo I 2020-05-11 02:26:17 callbacks:199] Starting epoch 35\n",
            "[NeMo I 2020-05-11 02:26:22 callbacks:224] Step: 960\n",
            "[NeMo I 2020-05-11 02:26:22 helpers:104] Loss: 0.1494598090648651\n",
            "[NeMo I 2020-05-11 02:26:22 helpers:110] training_batch_top@1:  93.7500\n",
            "[NeMo I 2020-05-11 02:26:22 callbacks:239] Step time: 0.3257331848144531 seconds\n",
            "[NeMo I 2020-05-11 02:26:25 callbacks:207] Finished epoch 35 in 0:00:08.236576\n",
            "[NeMo I 2020-05-11 02:26:25 callbacks:199] Starting epoch 36\n",
            "[NeMo I 2020-05-11 02:26:33 callbacks:207] Finished epoch 36 in 0:00:08.248934\n",
            "[NeMo I 2020-05-11 02:26:33 callbacks:199] Starting epoch 37\n",
            "[NeMo I 2020-05-11 02:26:34 callbacks:224] Step: 1000\n",
            "[NeMo I 2020-05-11 02:26:34 helpers:104] Loss: 0.09478539228439331\n",
            "[NeMo I 2020-05-11 02:26:34 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:26:34 callbacks:239] Step time: 0.29634737968444824 seconds\n",
            "[NeMo I 2020-05-11 02:26:34 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1000.pt\n",
            "[NeMo I 2020-05-11 02:26:34 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:26:34 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.917\n",
            "[NeMo I 2020-05-11 02:26:34 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 53.6842\n",
            "[NeMo I 2020-05-11 02:26:34 callbacks:450] Evaluation time: 0.34415292739868164 seconds\n",
            "[NeMo I 2020-05-11 02:26:42 callbacks:207] Finished epoch 37 in 0:00:08.911783\n",
            "[NeMo I 2020-05-11 02:26:42 callbacks:199] Starting epoch 38\n",
            "[NeMo I 2020-05-11 02:26:47 callbacks:224] Step: 1040\n",
            "[NeMo I 2020-05-11 02:26:47 helpers:104] Loss: 0.15379740297794342\n",
            "[NeMo I 2020-05-11 02:26:47 helpers:110] training_batch_top@1:  96.8750\n",
            "[NeMo I 2020-05-11 02:26:47 callbacks:239] Step time: 0.3082106113433838 seconds\n",
            "[NeMo I 2020-05-11 02:26:51 callbacks:207] Finished epoch 38 in 0:00:08.574462\n",
            "[NeMo I 2020-05-11 02:26:51 callbacks:199] Starting epoch 39\n",
            "[NeMo I 2020-05-11 02:26:59 callbacks:207] Finished epoch 39 in 0:00:08.329765\n",
            "[NeMo I 2020-05-11 02:26:59 callbacks:199] Starting epoch 40\n",
            "[NeMo I 2020-05-11 02:26:59 callbacks:224] Step: 1080\n",
            "[NeMo I 2020-05-11 02:26:59 helpers:104] Loss: 0.06273411214351654\n",
            "[NeMo I 2020-05-11 02:26:59 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:26:59 callbacks:239] Step time: 0.32518959045410156 seconds\n",
            "[NeMo I 2020-05-11 02:27:06 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1100.pt\n",
            "[NeMo I 2020-05-11 02:27:06 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:27:06 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.793\n",
            "[NeMo I 2020-05-11 02:27:06 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 62.1053\n",
            "[NeMo I 2020-05-11 02:27:06 callbacks:450] Evaluation time: 0.35154247283935547 seconds\n",
            "[NeMo I 2020-05-11 02:27:08 callbacks:207] Finished epoch 40 in 0:00:08.989931\n",
            "[NeMo I 2020-05-11 02:27:08 callbacks:199] Starting epoch 41\n",
            "[NeMo I 2020-05-11 02:27:12 callbacks:224] Step: 1120\n",
            "[NeMo I 2020-05-11 02:27:12 helpers:104] Loss: 0.0812540352344513\n",
            "[NeMo I 2020-05-11 02:27:12 helpers:110] training_batch_top@1:  96.8750\n",
            "[NeMo I 2020-05-11 02:27:12 callbacks:239] Step time: 0.33828067779541016 seconds\n",
            "[NeMo I 2020-05-11 02:27:16 callbacks:207] Finished epoch 41 in 0:00:08.208518\n",
            "[NeMo I 2020-05-11 02:27:16 callbacks:199] Starting epoch 42\n",
            "[NeMo I 2020-05-11 02:27:24 callbacks:224] Step: 1160\n",
            "[NeMo I 2020-05-11 02:27:24 helpers:104] Loss: 0.20495761930942535\n",
            "[NeMo I 2020-05-11 02:27:24 helpers:110] training_batch_top@1:  90.4762\n",
            "[NeMo I 2020-05-11 02:27:24 callbacks:239] Step time: 0.15479636192321777 seconds\n",
            "[NeMo I 2020-05-11 02:27:24 callbacks:207] Finished epoch 42 in 0:00:08.133020\n",
            "[NeMo I 2020-05-11 02:27:24 callbacks:199] Starting epoch 43\n",
            "[NeMo I 2020-05-11 02:27:33 callbacks:207] Finished epoch 43 in 0:00:08.413850\n",
            "[NeMo I 2020-05-11 02:27:33 callbacks:199] Starting epoch 44\n",
            "[NeMo I 2020-05-11 02:27:37 callbacks:224] Step: 1200\n",
            "[NeMo I 2020-05-11 02:27:37 helpers:104] Loss: 0.08607083559036255\n",
            "[NeMo I 2020-05-11 02:27:37 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:27:37 callbacks:239] Step time: 0.3331298828125 seconds\n",
            "[NeMo I 2020-05-11 02:27:37 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1200.pt\n",
            "[NeMo I 2020-05-11 02:27:37 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:27:37 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.501\n",
            "[NeMo I 2020-05-11 02:27:37 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 68.4211\n",
            "[NeMo I 2020-05-11 02:27:37 callbacks:450] Evaluation time: 0.3560357093811035 seconds\n",
            "[NeMo I 2020-05-11 02:27:42 callbacks:207] Finished epoch 44 in 0:00:08.855222\n",
            "[NeMo I 2020-05-11 02:27:42 callbacks:199] Starting epoch 45\n",
            "[NeMo I 2020-05-11 02:27:50 callbacks:224] Step: 1240\n",
            "[NeMo I 2020-05-11 02:27:50 helpers:104] Loss: 0.05887290835380554\n",
            "[NeMo I 2020-05-11 02:27:50 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:27:50 callbacks:239] Step time: 0.2906785011291504 seconds\n",
            "[NeMo I 2020-05-11 02:27:50 callbacks:207] Finished epoch 45 in 0:00:08.496103\n",
            "[NeMo I 2020-05-11 02:27:50 callbacks:199] Starting epoch 46\n",
            "[NeMo I 2020-05-11 02:27:58 callbacks:207] Finished epoch 46 in 0:00:08.288788\n",
            "[NeMo I 2020-05-11 02:27:58 callbacks:199] Starting epoch 47\n",
            "[NeMo I 2020-05-11 02:28:02 callbacks:224] Step: 1280\n",
            "[NeMo I 2020-05-11 02:28:02 helpers:104] Loss: 0.050251781940460205\n",
            "[NeMo I 2020-05-11 02:28:02 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:28:02 callbacks:239] Step time: 0.32466912269592285 seconds\n",
            "[NeMo I 2020-05-11 02:28:07 callbacks:207] Finished epoch 47 in 0:00:08.252868\n",
            "[NeMo I 2020-05-11 02:28:07 callbacks:199] Starting epoch 48\n",
            "[NeMo I 2020-05-11 02:28:08 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1300.pt\n",
            "[NeMo I 2020-05-11 02:28:08 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:28:09 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.886\n",
            "[NeMo I 2020-05-11 02:28:09 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 61.0526\n",
            "[NeMo I 2020-05-11 02:28:09 callbacks:450] Evaluation time: 0.3474085330963135 seconds\n",
            "[NeMo I 2020-05-11 02:28:15 callbacks:224] Step: 1320\n",
            "[NeMo I 2020-05-11 02:28:15 helpers:104] Loss: 0.04002755880355835\n",
            "[NeMo I 2020-05-11 02:28:15 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:28:15 callbacks:239] Step time: 0.3333003520965576 seconds\n",
            "[NeMo I 2020-05-11 02:28:15 callbacks:207] Finished epoch 48 in 0:00:08.826872\n",
            "[NeMo I 2020-05-11 02:28:15 callbacks:199] Starting epoch 49\n",
            "[NeMo I 2020-05-11 02:28:24 callbacks:207] Finished epoch 49 in 0:00:08.451554\n",
            "[NeMo I 2020-05-11 02:28:24 callbacks:199] Starting epoch 50\n",
            "[NeMo I 2020-05-11 02:28:27 callbacks:224] Step: 1360\n",
            "[NeMo I 2020-05-11 02:28:27 helpers:104] Loss: 0.057811081409454346\n",
            "[NeMo I 2020-05-11 02:28:27 helpers:110] training_batch_top@1:  96.8750\n",
            "[NeMo I 2020-05-11 02:28:27 callbacks:239] Step time: 0.30139970779418945 seconds\n",
            "[NeMo I 2020-05-11 02:28:32 callbacks:207] Finished epoch 50 in 0:00:08.491859\n",
            "[NeMo I 2020-05-11 02:28:32 callbacks:199] Starting epoch 51\n",
            "[NeMo I 2020-05-11 02:28:40 callbacks:224] Step: 1400\n",
            "[NeMo I 2020-05-11 02:28:40 helpers:104] Loss: 0.021055638790130615\n",
            "[NeMo I 2020-05-11 02:28:40 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:28:40 callbacks:239] Step time: 0.2870323657989502 seconds\n",
            "[NeMo I 2020-05-11 02:28:40 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1400.pt\n",
            "[NeMo I 2020-05-11 02:28:40 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:28:40 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.934\n",
            "[NeMo I 2020-05-11 02:28:40 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 60.0000\n",
            "[NeMo I 2020-05-11 02:28:40 callbacks:450] Evaluation time: 0.3444681167602539 seconds\n",
            "[NeMo I 2020-05-11 02:28:41 callbacks:207] Finished epoch 51 in 0:00:08.861701\n",
            "[NeMo I 2020-05-11 02:28:41 callbacks:199] Starting epoch 52\n",
            "[NeMo I 2020-05-11 02:28:50 callbacks:207] Finished epoch 52 in 0:00:08.313393\n",
            "[NeMo I 2020-05-11 02:28:50 callbacks:199] Starting epoch 53\n",
            "[NeMo I 2020-05-11 02:28:53 callbacks:224] Step: 1440\n",
            "[NeMo I 2020-05-11 02:28:53 helpers:104] Loss: 0.06866192817687988\n",
            "[NeMo I 2020-05-11 02:28:53 helpers:110] training_batch_top@1:  96.8750\n",
            "[NeMo I 2020-05-11 02:28:53 callbacks:239] Step time: 0.3325502872467041 seconds\n",
            "[NeMo I 2020-05-11 02:28:58 callbacks:207] Finished epoch 53 in 0:00:08.323288\n",
            "[NeMo I 2020-05-11 02:28:58 callbacks:199] Starting epoch 54\n",
            "[NeMo I 2020-05-11 02:29:05 callbacks:224] Step: 1480\n",
            "[NeMo I 2020-05-11 02:29:05 helpers:104] Loss: 0.05327397584915161\n",
            "[NeMo I 2020-05-11 02:29:05 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:29:05 callbacks:239] Step time: 0.24162817001342773 seconds\n",
            "[NeMo I 2020-05-11 02:29:06 callbacks:207] Finished epoch 54 in 0:00:08.366967\n",
            "[NeMo I 2020-05-11 02:29:06 callbacks:199] Starting epoch 55\n",
            "[NeMo I 2020-05-11 02:29:11 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1500.pt\n",
            "[NeMo I 2020-05-11 02:29:11 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:29:12 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.842\n",
            "[NeMo I 2020-05-11 02:29:12 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 63.1579\n",
            "[NeMo I 2020-05-11 02:29:12 callbacks:450] Evaluation time: 0.3591878414154053 seconds\n",
            "[NeMo I 2020-05-11 02:29:15 callbacks:207] Finished epoch 55 in 0:00:08.756653\n",
            "[NeMo I 2020-05-11 02:29:15 callbacks:199] Starting epoch 56\n",
            "[NeMo I 2020-05-11 02:29:18 callbacks:224] Step: 1520\n",
            "[NeMo I 2020-05-11 02:29:18 helpers:104] Loss: 0.01675713062286377\n",
            "[NeMo I 2020-05-11 02:29:18 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:29:18 callbacks:239] Step time: 0.22163105010986328 seconds\n",
            "[NeMo I 2020-05-11 02:29:23 callbacks:207] Finished epoch 56 in 0:00:08.349238\n",
            "[NeMo I 2020-05-11 02:29:23 callbacks:199] Starting epoch 57\n",
            "[NeMo I 2020-05-11 02:29:30 callbacks:224] Step: 1560\n",
            "[NeMo I 2020-05-11 02:29:30 helpers:104] Loss: 0.025200635194778442\n",
            "[NeMo I 2020-05-11 02:29:30 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:29:30 callbacks:239] Step time: 0.2558929920196533 seconds\n",
            "[NeMo I 2020-05-11 02:29:32 callbacks:207] Finished epoch 57 in 0:00:08.360953\n",
            "[NeMo I 2020-05-11 02:29:32 callbacks:199] Starting epoch 58\n",
            "[NeMo I 2020-05-11 02:29:40 callbacks:207] Finished epoch 58 in 0:00:08.197477\n",
            "[NeMo I 2020-05-11 02:29:40 callbacks:199] Starting epoch 59\n",
            "[NeMo I 2020-05-11 02:29:42 callbacks:224] Step: 1600\n",
            "[NeMo I 2020-05-11 02:29:42 helpers:104] Loss: 0.006242603063583374\n",
            "[NeMo I 2020-05-11 02:29:42 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:29:42 callbacks:239] Step time: 0.25508975982666016 seconds\n",
            "[NeMo I 2020-05-11 02:29:42 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1600.pt\n",
            "[NeMo I 2020-05-11 02:29:42 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:29:43 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.612\n",
            "[NeMo I 2020-05-11 02:29:43 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 67.3684\n",
            "[NeMo I 2020-05-11 02:29:43 callbacks:450] Evaluation time: 0.34772443771362305 seconds\n",
            "[NeMo I 2020-05-11 02:29:49 callbacks:207] Finished epoch 59 in 0:00:08.915362\n",
            "[NeMo I 2020-05-11 02:29:49 callbacks:199] Starting epoch 60\n",
            "[NeMo I 2020-05-11 02:29:55 callbacks:224] Step: 1640\n",
            "[NeMo I 2020-05-11 02:29:55 helpers:104] Loss: 0.03432992100715637\n",
            "[NeMo I 2020-05-11 02:29:55 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:29:55 callbacks:239] Step time: 0.3262019157409668 seconds\n",
            "[NeMo I 2020-05-11 02:29:57 callbacks:207] Finished epoch 60 in 0:00:08.253773\n",
            "[NeMo I 2020-05-11 02:29:57 callbacks:199] Starting epoch 61\n",
            "[NeMo I 2020-05-11 02:30:05 callbacks:207] Finished epoch 61 in 0:00:08.381538\n",
            "[NeMo I 2020-05-11 02:30:05 callbacks:199] Starting epoch 62\n",
            "[NeMo I 2020-05-11 02:30:08 callbacks:224] Step: 1680\n",
            "[NeMo I 2020-05-11 02:30:08 helpers:104] Loss: 0.009862840175628662\n",
            "[NeMo I 2020-05-11 02:30:08 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:30:08 callbacks:239] Step time: 0.252669095993042 seconds\n",
            "[NeMo I 2020-05-11 02:30:14 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1700.pt\n",
            "[NeMo I 2020-05-11 02:30:14 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:30:14 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.359\n",
            "[NeMo I 2020-05-11 02:30:14 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 71.5789\n",
            "[NeMo I 2020-05-11 02:30:14 callbacks:450] Evaluation time: 0.34915900230407715 seconds\n",
            "[NeMo I 2020-05-11 02:30:14 callbacks:207] Finished epoch 62 in 0:00:08.997012\n",
            "[NeMo I 2020-05-11 02:30:14 callbacks:199] Starting epoch 63\n",
            "[NeMo I 2020-05-11 02:30:21 callbacks:224] Step: 1720\n",
            "[NeMo I 2020-05-11 02:30:21 helpers:104] Loss: 0.005924046039581299\n",
            "[NeMo I 2020-05-11 02:30:21 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:30:21 callbacks:239] Step time: 0.32567429542541504 seconds\n",
            "[NeMo I 2020-05-11 02:30:23 callbacks:207] Finished epoch 63 in 0:00:08.361445\n",
            "[NeMo I 2020-05-11 02:30:23 callbacks:199] Starting epoch 64\n",
            "[NeMo I 2020-05-11 02:30:31 callbacks:207] Finished epoch 64 in 0:00:08.356698\n",
            "[NeMo I 2020-05-11 02:30:31 callbacks:199] Starting epoch 65\n",
            "[NeMo I 2020-05-11 02:30:33 callbacks:224] Step: 1760\n",
            "[NeMo I 2020-05-11 02:30:33 helpers:104] Loss: 0.011215060949325562\n",
            "[NeMo I 2020-05-11 02:30:33 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:30:33 callbacks:239] Step time: 0.2513871192932129 seconds\n",
            "[NeMo I 2020-05-11 02:30:39 callbacks:207] Finished epoch 65 in 0:00:08.310937\n",
            "[NeMo I 2020-05-11 02:30:39 callbacks:199] Starting epoch 66\n",
            "[NeMo I 2020-05-11 02:30:45 callbacks:224] Step: 1800\n",
            "[NeMo I 2020-05-11 02:30:45 helpers:104] Loss: 0.003354579210281372\n",
            "[NeMo I 2020-05-11 02:30:45 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:30:45 callbacks:239] Step time: 0.3307194709777832 seconds\n",
            "[NeMo I 2020-05-11 02:30:45 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1800.pt\n",
            "[NeMo I 2020-05-11 02:30:45 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:30:46 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.532\n",
            "[NeMo I 2020-05-11 02:30:46 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 71.5789\n",
            "[NeMo I 2020-05-11 02:30:46 callbacks:450] Evaluation time: 0.34970664978027344 seconds\n",
            "[NeMo I 2020-05-11 02:30:48 callbacks:207] Finished epoch 66 in 0:00:08.715346\n",
            "[NeMo I 2020-05-11 02:30:48 callbacks:199] Starting epoch 67\n",
            "[NeMo I 2020-05-11 02:30:57 callbacks:207] Finished epoch 67 in 0:00:08.479212\n",
            "[NeMo I 2020-05-11 02:30:57 callbacks:199] Starting epoch 68\n",
            "[NeMo I 2020-05-11 02:30:58 callbacks:224] Step: 1840\n",
            "[NeMo I 2020-05-11 02:30:58 helpers:104] Loss: 0.001688152551651001\n",
            "[NeMo I 2020-05-11 02:30:58 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:30:58 callbacks:239] Step time: 0.2950136661529541 seconds\n",
            "[NeMo I 2020-05-11 02:31:05 callbacks:207] Finished epoch 68 in 0:00:08.121590\n",
            "[NeMo I 2020-05-11 02:31:05 callbacks:199] Starting epoch 69\n",
            "[NeMo I 2020-05-11 02:31:11 callbacks:224] Step: 1880\n",
            "[NeMo I 2020-05-11 02:31:11 helpers:104] Loss: 0.0024895668029785156\n",
            "[NeMo I 2020-05-11 02:31:11 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:31:11 callbacks:239] Step time: 0.33412766456604004 seconds\n",
            "[NeMo I 2020-05-11 02:31:13 callbacks:207] Finished epoch 69 in 0:00:08.379860\n",
            "[NeMo I 2020-05-11 02:31:13 callbacks:199] Starting epoch 70\n",
            "[NeMo I 2020-05-11 02:31:17 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-1900.pt\n",
            "[NeMo I 2020-05-11 02:31:17 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:31:17 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.420\n",
            "[NeMo I 2020-05-11 02:31:17 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 72.6316\n",
            "[NeMo I 2020-05-11 02:31:17 callbacks:450] Evaluation time: 0.3500385284423828 seconds\n",
            "[NeMo I 2020-05-11 02:31:22 callbacks:207] Finished epoch 70 in 0:00:08.770076\n",
            "[NeMo I 2020-05-11 02:31:22 callbacks:199] Starting epoch 71\n",
            "[NeMo I 2020-05-11 02:31:23 callbacks:224] Step: 1920\n",
            "[NeMo I 2020-05-11 02:31:23 helpers:104] Loss: 0.002674698829650879\n",
            "[NeMo I 2020-05-11 02:31:23 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:31:23 callbacks:239] Step time: 0.24361681938171387 seconds\n",
            "[NeMo I 2020-05-11 02:31:30 callbacks:207] Finished epoch 71 in 0:00:08.324948\n",
            "[NeMo I 2020-05-11 02:31:30 callbacks:199] Starting epoch 72\n",
            "[NeMo I 2020-05-11 02:31:36 callbacks:224] Step: 1960\n",
            "[NeMo I 2020-05-11 02:31:36 helpers:104] Loss: 0.0054544806480407715\n",
            "[NeMo I 2020-05-11 02:31:36 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:31:36 callbacks:239] Step time: 0.24323487281799316 seconds\n",
            "[NeMo I 2020-05-11 02:31:38 callbacks:207] Finished epoch 72 in 0:00:08.166200\n",
            "[NeMo I 2020-05-11 02:31:38 callbacks:199] Starting epoch 73\n",
            "[NeMo I 2020-05-11 02:31:47 callbacks:207] Finished epoch 73 in 0:00:08.439702\n",
            "[NeMo I 2020-05-11 02:31:47 callbacks:199] Starting epoch 74\n",
            "[NeMo I 2020-05-11 02:31:48 callbacks:224] Step: 2000\n",
            "[NeMo I 2020-05-11 02:31:48 helpers:104] Loss: 0.0018942654132843018\n",
            "[NeMo I 2020-05-11 02:31:48 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:31:48 callbacks:239] Step time: 0.3196110725402832 seconds\n",
            "[NeMo I 2020-05-11 02:31:48 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2000.pt\n",
            "[NeMo I 2020-05-11 02:31:48 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:31:48 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.455\n",
            "[NeMo I 2020-05-11 02:31:48 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 71.5789\n",
            "[NeMo I 2020-05-11 02:31:48 callbacks:450] Evaluation time: 0.346468448638916 seconds\n",
            "[NeMo I 2020-05-11 02:31:56 callbacks:207] Finished epoch 74 in 0:00:08.728173\n",
            "[NeMo I 2020-05-11 02:31:56 callbacks:199] Starting epoch 75\n",
            "[NeMo I 2020-05-11 02:32:01 callbacks:224] Step: 2040\n",
            "[NeMo I 2020-05-11 02:32:01 helpers:104] Loss: 0.002985149621963501\n",
            "[NeMo I 2020-05-11 02:32:01 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:32:01 callbacks:239] Step time: 0.30757570266723633 seconds\n",
            "[NeMo I 2020-05-11 02:32:04 callbacks:207] Finished epoch 75 in 0:00:08.313434\n",
            "[NeMo I 2020-05-11 02:32:04 callbacks:199] Starting epoch 76\n",
            "[NeMo I 2020-05-11 02:32:12 callbacks:207] Finished epoch 76 in 0:00:08.323249\n",
            "[NeMo I 2020-05-11 02:32:12 callbacks:199] Starting epoch 77\n",
            "[NeMo I 2020-05-11 02:32:13 callbacks:224] Step: 2080\n",
            "[NeMo I 2020-05-11 02:32:13 helpers:104] Loss: 0.0013275444507598877\n",
            "[NeMo I 2020-05-11 02:32:13 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:32:13 callbacks:239] Step time: 0.3254401683807373 seconds\n",
            "[NeMo I 2020-05-11 02:32:19 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2100.pt\n",
            "[NeMo I 2020-05-11 02:32:19 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:32:20 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.364\n",
            "[NeMo I 2020-05-11 02:32:20 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 74.7368\n",
            "[NeMo I 2020-05-11 02:32:20 callbacks:450] Evaluation time: 0.34360456466674805 seconds\n",
            "[NeMo I 2020-05-11 02:32:21 callbacks:207] Finished epoch 77 in 0:00:08.777151\n",
            "[NeMo I 2020-05-11 02:32:21 callbacks:199] Starting epoch 78\n",
            "[NeMo I 2020-05-11 02:32:25 callbacks:224] Step: 2120\n",
            "[NeMo I 2020-05-11 02:32:25 helpers:104] Loss: 0.0007219314575195312\n",
            "[NeMo I 2020-05-11 02:32:25 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:32:25 callbacks:239] Step time: 0.3226962089538574 seconds\n",
            "[NeMo I 2020-05-11 02:32:29 callbacks:207] Finished epoch 78 in 0:00:08.172290\n",
            "[NeMo I 2020-05-11 02:32:29 callbacks:199] Starting epoch 79\n",
            "[NeMo I 2020-05-11 02:32:38 callbacks:207] Finished epoch 79 in 0:00:08.470198\n",
            "[NeMo I 2020-05-11 02:32:38 callbacks:199] Starting epoch 80\n",
            "[NeMo I 2020-05-11 02:32:38 callbacks:224] Step: 2160\n",
            "[NeMo I 2020-05-11 02:32:38 helpers:104] Loss: 0.0006757378578186035\n",
            "[NeMo I 2020-05-11 02:32:38 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:32:38 callbacks:239] Step time: 0.3327949047088623 seconds\n",
            "[NeMo I 2020-05-11 02:32:46 callbacks:207] Finished epoch 80 in 0:00:08.348893\n",
            "[NeMo I 2020-05-11 02:32:46 callbacks:199] Starting epoch 81\n",
            "[NeMo I 2020-05-11 02:32:51 callbacks:224] Step: 2200\n",
            "[NeMo I 2020-05-11 02:32:51 helpers:104] Loss: 0.0014121532440185547\n",
            "[NeMo I 2020-05-11 02:32:51 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:32:51 callbacks:239] Step time: 0.3154926300048828 seconds\n",
            "[NeMo I 2020-05-11 02:32:51 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2200.pt\n",
            "[NeMo I 2020-05-11 02:32:51 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:32:51 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.338\n",
            "[NeMo I 2020-05-11 02:32:51 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 73.6842\n",
            "[NeMo I 2020-05-11 02:32:51 callbacks:450] Evaluation time: 0.3417849540710449 seconds\n",
            "[NeMo I 2020-05-11 02:32:55 callbacks:207] Finished epoch 81 in 0:00:08.863265\n",
            "[NeMo I 2020-05-11 02:32:55 callbacks:199] Starting epoch 82\n",
            "[NeMo I 2020-05-11 02:33:03 callbacks:224] Step: 2240\n",
            "[NeMo I 2020-05-11 02:33:03 helpers:104] Loss: 0.002039001090452075\n",
            "[NeMo I 2020-05-11 02:33:03 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:33:03 callbacks:239] Step time: 0.1574089527130127 seconds\n",
            "[NeMo I 2020-05-11 02:33:03 callbacks:207] Finished epoch 82 in 0:00:08.193366\n",
            "[NeMo I 2020-05-11 02:33:03 callbacks:199] Starting epoch 83\n",
            "[NeMo I 2020-05-11 02:33:12 callbacks:207] Finished epoch 83 in 0:00:08.518195\n",
            "[NeMo I 2020-05-11 02:33:12 callbacks:199] Starting epoch 84\n",
            "[NeMo I 2020-05-11 02:33:16 callbacks:224] Step: 2280\n",
            "[NeMo I 2020-05-11 02:33:16 helpers:104] Loss: 0.0023241639137268066\n",
            "[NeMo I 2020-05-11 02:33:16 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:33:16 callbacks:239] Step time: 0.3191206455230713 seconds\n",
            "[NeMo I 2020-05-11 02:33:20 callbacks:207] Finished epoch 84 in 0:00:08.378448\n",
            "[NeMo I 2020-05-11 02:33:20 callbacks:199] Starting epoch 85\n",
            "[NeMo I 2020-05-11 02:33:22 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2300.pt\n",
            "[NeMo I 2020-05-11 02:33:22 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:33:22 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.383\n",
            "[NeMo I 2020-05-11 02:33:22 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 75.7895\n",
            "[NeMo I 2020-05-11 02:33:22 callbacks:450] Evaluation time: 0.34298086166381836 seconds\n",
            "[NeMo I 2020-05-11 02:33:29 callbacks:224] Step: 2320\n",
            "[NeMo I 2020-05-11 02:33:29 helpers:104] Loss: 0.0019207894802093506\n",
            "[NeMo I 2020-05-11 02:33:29 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:33:29 callbacks:239] Step time: 0.2907986640930176 seconds\n",
            "[NeMo I 2020-05-11 02:33:29 callbacks:207] Finished epoch 85 in 0:00:08.837236\n",
            "[NeMo I 2020-05-11 02:33:29 callbacks:199] Starting epoch 86\n",
            "[NeMo I 2020-05-11 02:33:37 callbacks:207] Finished epoch 86 in 0:00:08.393493\n",
            "[NeMo I 2020-05-11 02:33:37 callbacks:199] Starting epoch 87\n",
            "[NeMo I 2020-05-11 02:33:41 callbacks:224] Step: 2360\n",
            "[NeMo I 2020-05-11 02:33:41 helpers:104] Loss: 0.0007072687149047852\n",
            "[NeMo I 2020-05-11 02:33:41 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:33:41 callbacks:239] Step time: 0.3078038692474365 seconds\n",
            "[NeMo I 2020-05-11 02:33:46 callbacks:207] Finished epoch 87 in 0:00:08.391233\n",
            "[NeMo I 2020-05-11 02:33:46 callbacks:199] Starting epoch 88\n",
            "[NeMo I 2020-05-11 02:33:54 callbacks:224] Step: 2400\n",
            "[NeMo I 2020-05-11 02:33:54 helpers:104] Loss: 0.0006668269634246826\n",
            "[NeMo I 2020-05-11 02:33:54 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:33:54 callbacks:239] Step time: 0.3242828845977783 seconds\n",
            "[NeMo I 2020-05-11 02:33:54 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2400.pt\n",
            "[NeMo I 2020-05-11 02:33:54 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:33:54 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.362\n",
            "[NeMo I 2020-05-11 02:33:54 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 73.6842\n",
            "[NeMo I 2020-05-11 02:33:54 callbacks:450] Evaluation time: 0.34790897369384766 seconds\n",
            "[NeMo I 2020-05-11 02:33:55 callbacks:207] Finished epoch 88 in 0:00:08.954133\n",
            "[NeMo I 2020-05-11 02:33:55 callbacks:199] Starting epoch 89\n",
            "[NeMo I 2020-05-11 02:34:03 callbacks:207] Finished epoch 89 in 0:00:08.367490\n",
            "[NeMo I 2020-05-11 02:34:03 callbacks:199] Starting epoch 90\n",
            "[NeMo I 2020-05-11 02:34:06 callbacks:224] Step: 2440\n",
            "[NeMo I 2020-05-11 02:34:06 helpers:104] Loss: 0.0005310475826263428\n",
            "[NeMo I 2020-05-11 02:34:06 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:34:06 callbacks:239] Step time: 0.3298463821411133 seconds\n",
            "[NeMo I 2020-05-11 02:34:11 callbacks:207] Finished epoch 90 in 0:00:08.094050\n",
            "[NeMo I 2020-05-11 02:34:11 callbacks:199] Starting epoch 91\n",
            "[NeMo I 2020-05-11 02:34:19 callbacks:224] Step: 2480\n",
            "[NeMo I 2020-05-11 02:34:19 helpers:104] Loss: 0.0005409419536590576\n",
            "[NeMo I 2020-05-11 02:34:19 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:34:19 callbacks:239] Step time: 0.32176804542541504 seconds\n",
            "[NeMo I 2020-05-11 02:34:20 callbacks:207] Finished epoch 91 in 0:00:08.491658\n",
            "[NeMo I 2020-05-11 02:34:20 callbacks:199] Starting epoch 92\n",
            "[NeMo I 2020-05-11 02:34:25 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2500.pt\n",
            "[NeMo I 2020-05-11 02:34:25 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:34:25 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.355\n",
            "[NeMo I 2020-05-11 02:34:25 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 74.7368\n",
            "[NeMo I 2020-05-11 02:34:25 callbacks:450] Evaluation time: 0.34357476234436035 seconds\n",
            "[NeMo I 2020-05-11 02:34:29 callbacks:207] Finished epoch 92 in 0:00:08.946755\n",
            "[NeMo I 2020-05-11 02:34:29 callbacks:199] Starting epoch 93\n",
            "[NeMo I 2020-05-11 02:34:32 callbacks:224] Step: 2520\n",
            "[NeMo I 2020-05-11 02:34:32 helpers:104] Loss: 0.000574260950088501\n",
            "[NeMo I 2020-05-11 02:34:32 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:34:32 callbacks:239] Step time: 0.2919759750366211 seconds\n",
            "[NeMo I 2020-05-11 02:34:37 callbacks:207] Finished epoch 93 in 0:00:08.334876\n",
            "[NeMo I 2020-05-11 02:34:37 callbacks:199] Starting epoch 94\n",
            "[NeMo I 2020-05-11 02:34:44 callbacks:224] Step: 2560\n",
            "[NeMo I 2020-05-11 02:34:44 helpers:104] Loss: 0.0004932284355163574\n",
            "[NeMo I 2020-05-11 02:34:44 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:34:44 callbacks:239] Step time: 0.2569153308868408 seconds\n",
            "[NeMo I 2020-05-11 02:34:45 callbacks:207] Finished epoch 94 in 0:00:08.461214\n",
            "[NeMo I 2020-05-11 02:34:45 callbacks:199] Starting epoch 95\n",
            "[NeMo I 2020-05-11 02:34:53 callbacks:207] Finished epoch 95 in 0:00:08.088197\n",
            "[NeMo I 2020-05-11 02:34:53 callbacks:199] Starting epoch 96\n",
            "[NeMo I 2020-05-11 02:34:56 callbacks:224] Step: 2600\n",
            "[NeMo I 2020-05-11 02:34:56 helpers:104] Loss: 0.00510936975479126\n",
            "[NeMo I 2020-05-11 02:34:56 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:34:56 callbacks:239] Step time: 0.3080604076385498 seconds\n",
            "[NeMo I 2020-05-11 02:34:56 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2600.pt\n",
            "[NeMo I 2020-05-11 02:34:56 callbacks:445] Doing Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:34:57 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.364\n",
            "[NeMo I 2020-05-11 02:34:57 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 73.6842\n",
            "[NeMo I 2020-05-11 02:34:57 callbacks:450] Evaluation time: 0.34247541427612305 seconds\n",
            "[NeMo I 2020-05-11 02:35:02 callbacks:207] Finished epoch 96 in 0:00:08.679435\n",
            "[NeMo I 2020-05-11 02:35:02 callbacks:199] Starting epoch 97\n",
            "[NeMo I 2020-05-11 02:35:09 callbacks:224] Step: 2640\n",
            "[NeMo I 2020-05-11 02:35:09 helpers:104] Loss: 0.0019539296627044678\n",
            "[NeMo I 2020-05-11 02:35:09 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:35:09 callbacks:239] Step time: 0.3111248016357422 seconds\n",
            "[NeMo I 2020-05-11 02:35:10 callbacks:207] Finished epoch 97 in 0:00:08.322436\n",
            "[NeMo I 2020-05-11 02:35:10 callbacks:199] Starting epoch 98\n",
            "[NeMo I 2020-05-11 02:35:19 callbacks:207] Finished epoch 98 in 0:00:08.257718\n",
            "[NeMo I 2020-05-11 02:35:19 callbacks:199] Starting epoch 99\n",
            "[NeMo I 2020-05-11 02:35:21 callbacks:224] Step: 2680\n",
            "[NeMo I 2020-05-11 02:35:21 helpers:104] Loss: 0.0006973743438720703\n",
            "[NeMo I 2020-05-11 02:35:21 helpers:110] training_batch_top@1:  100.0000\n",
            "[NeMo I 2020-05-11 02:35:21 callbacks:239] Step time: 0.24202775955200195 seconds\n",
            "[NeMo I 2020-05-11 02:35:27 callbacks:207] Finished epoch 99 in 0:00:08.261154\n",
            "[NeMo I 2020-05-11 02:35:27 callbacks:195] Done in 0:14:05.425577\n",
            "[NeMo I 2020-05-11 02:35:27 callbacks:303] Saved checkpoint: ./myExps/checkpoints/quartznet3x1_an4/trainer-STEP-2700.pt\n",
            "[NeMo I 2020-05-11 02:35:27 callbacks:468] Final Evaluation ..............................\n",
            "[NeMo I 2020-05-11 02:35:27 helpers:273] ==========>>>>>>Evaluation Loss an4_dev: 1.313\n",
            "[NeMo I 2020-05-11 02:35:27 helpers:275] ==========>>>>>>Evaluation Accuracy Top@1 an4_dev: 76.8421\n",
            "[NeMo I 2020-05-11 02:35:27 callbacks:473] Evaluation time: 0.34503674507141113 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB6s19pmxGfX",
        "colab_type": "text"
      },
      "source": [
        "Now that we trained our embeddings, we shall extract these embeddings from using pretrained checkpoint present at `checkpoint_dir`. As we can see from the neural architecture, we extract the embeddings after `emb1` layer. \n",
        "![Speaker Recognition Layers](./speaker_reco.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSIDu6jkym66",
        "colab_type": "text"
      },
      "source": [
        "Now use test manifest to get the embeddings. As we saw before let's create a new data\\_layer for test. And use previously instiated models and attach the DAGs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JqUVbKDY32a",
        "colab_type": "code",
        "outputId": "dd835e02-8882-4287-9639-c249ac3dfc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "eval_dl_params = copy.deepcopy(spkr_params[\"AudioToSpeechLabelDataLayer\"])\n",
        "eval_dl_params.update(spkr_params[\"AudioToSpeechLabelDataLayer\"][\"eval\"])\n",
        "del eval_dl_params[\"train\"]\n",
        "del eval_dl_params[\"eval\"]\n",
        "eval_dl_params['shuffle'] = False  # To grab  the file names without changing data_layer\n",
        "\n",
        "test_dataset = '../data/an4/wav/an4test_clstk/test.json'\n",
        "data_layer_test = nemo_asr.AudioToSpeechLabelDataLayer(\n",
        "        manifest_filepath=test_dataset,\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        **eval_dl_params,\n",
        "    )\n",
        "\n",
        "audio_signal_test, audio_len_test, label_test, _ = data_layer_test()\n",
        "processed_signal_test, processed_len_test = data_preprocessor(\n",
        "    input_signal=audio_signal_test, length=audio_len_test)\n",
        "encoded_test, _ = encoder(audio_signal=processed_signal_test, length=processed_len_test)\n",
        "_, embeddings = decoder(encoder_output=encoded_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:36:00 collections:234] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2020-05-11 02:36:00 collections:237] # 130 files loaded accounting to # 10 labels\n",
            "[NeMo I 2020-05-11 02:36:00 data_layer:962] # of classes :10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `audio_signal` produced in step 20 by `audiotospeechlabeldatalayer4` to `20_audiotospeechlabeldatalayer4_audio_signal`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `a_sig_length` produced in step 20 by `audiotospeechlabeldatalayer4` to `20_audiotospeechlabeldatalayer4_a_sig_length`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `label` produced in step 20 by `audiotospeechlabeldatalayer4` to `20_audiotospeechlabeldatalayer4_label`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `label_length` produced in step 20 by `audiotospeechlabeldatalayer4` to `20_audiotospeechlabeldatalayer4_label_length`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `processed_signal` produced in step 21 by `audiotomelspectrogrampreprocessor1` to `21_audiotomelspectrogrampreprocessor1_processed_signal`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `processed_length` produced in step 21 by `audiotomelspectrogrampreprocessor1` to `21_audiotomelspectrogrampreprocessor1_processed_length`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `outputs` produced in step 22 by `jasperencoder1` to `22_jasperencoder1_outputs`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `encoded_lengths` produced in step 22 by `jasperencoder1` to `22_jasperencoder1_encoded_lengths`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `logits` produced in step 23 by `jasperdecoderforspkrclass1` to `23_jasperdecoderforspkrclass1_logits`\n",
            "[NeMo W 2020-05-11 02:36:00 graph_outputs:167] Setting unigue name of the default output port `embs` produced in step 23 by `jasperdecoderforspkrclass1` to `23_jasperdecoderforspkrclass1_embs`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwEifkD9zfpl",
        "colab_type": "text"
      },
      "source": [
        "Now get the embeddings using neural_factor infer command, that just does forward pass of all our modules. And save our embeddings in `<work_dir>/embeddings`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGxYiFpJze5h",
        "colab_type": "code",
        "outputId": "dbbc7204-28bc-43e9-b6aa-f3f757f5d4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "eval_tensors = neural_factory.infer(tensors=[embeddings, label_test], checkpoint_dir=\"./myExps/checkpoints/\" + exp_name)\n",
        "    # inf_loss , inf_emb, inf_logits, inf_label = eval_tensors\n",
        "inf_emb, inf_label = eval_tensors\n",
        "whole_embs = []\n",
        "whole_labels = []\n",
        "manifest = open(test_dataset, 'r').readlines()\n",
        "\n",
        "for line in manifest:\n",
        "    line = line.strip()\n",
        "    dic = json.loads(line)\n",
        "    filename = dic['audio_filepath'].split('/')[-1]\n",
        "    whole_labels.append(filename)\n",
        "\n",
        "for idx in range(len(inf_label)):\n",
        "    whole_embs.extend(inf_emb[idx].numpy())\n",
        "\n",
        "embedding_dir = './myExps/embeddings/'\n",
        "if not os.path.exists(embedding_dir):\n",
        "    os.mkdir(embedding_dir)\n",
        "\n",
        "filename = os.path.basename(test_dataset).split('.')[0]\n",
        "name = embedding_dir + filename\n",
        "\n",
        "np.save(name + '.npy', np.asarray(whole_embs))\n",
        "np.save(name + '_labels.npy', np.asarray(whole_labels))\n",
        "logging.info(\"Saved embedding files to {}\".format(embedding_dir))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NeMo I 2020-05-11 02:36:07 actions:1533] Restoring JasperEncoder from ./myExps/checkpoints/quartznet3x1_an4/JasperEncoder-STEP-2700.pt\n",
            "[NeMo I 2020-05-11 02:36:07 actions:1533] Restoring JasperDecoderForSpkrClass from ./myExps/checkpoints/quartznet3x1_an4/JasperDecoderForSpkrClass-STEP-2700.pt\n",
            "[NeMo I 2020-05-11 02:36:07 actions:759] Evaluating batch 0 out of 5\n",
            "[NeMo I 2020-05-11 02:36:07 actions:759] Evaluating batch 1 out of 5\n",
            "[NeMo I 2020-05-11 02:36:07 actions:759] Evaluating batch 2 out of 5\n",
            "[NeMo I 2020-05-11 02:36:08 actions:759] Evaluating batch 3 out of 5\n",
            "[NeMo I 2020-05-11 02:36:08 actions:759] Evaluating batch 4 out of 5\n",
            "[NeMo I 2020-05-11 02:36:08 <ipython-input-27-e3f164d28ce7>:28] Saved embedding files to ./myExps/embeddings/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKKVIb7e6vel",
        "colab_type": "code",
        "outputId": "a3fa3703-da6c-4a07-c20c-c83df11a8f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls myExps/embeddings/"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_labels.npy  test.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_7S4Yja7A8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}