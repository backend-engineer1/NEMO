# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018-2019, NVIDIA
# This file is distributed under the same license as the nemo package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nemo 0.9.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-12-03 17:10+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/zh/asr/datasets.rst:2
msgid "数据集"
msgstr ""

#: ../../source/zh/asr/datasets.rst:7
msgid "LibriSpeech"
msgstr ""

#: ../../source/zh/asr/datasets.rst:9
msgid "运行下面的脚本下载LibriSpeech数据集，并把它转换成 `nemo_asr` 集合需要的格式. 你至少需要110GB的空间。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:19
msgid "之后，你的 `data` 文件夹下应该包含了wav文件和给NeMo语音识别数据层的 `.json` 文件:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:22
msgid ""
"每行是一个训练样本。 `audio_filepath` 包含了wav文件的路径, `duration` 这个音频文件多少秒， `text` "
"是对应的抄本:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:30
msgid "Fisher English Training Speech"
msgstr ""

#: ../../source/zh/asr/datasets.rst:32
msgid "运行这些脚本把Fisher English Training Speech数据集转换成 `nemo_asr` 集合需要的格式."
msgstr ""

#: ../../source/zh/asr/datasets.rst:34
msgid "简言之，下面的脚本会把.sph文件转成.wav，把这些文件切成更小的音频样本，把这些小音频和它们相应的抄本匹配起来，接着把音频样本分成训练集，验证集和测试集。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:37
msgid "你至少需要106GB的空间来转换成.wav，额外的105GB空间做切分和匹配. 你需要安装sph2pipe来运行.wav的转换."
msgstr ""

#: ../../source/zh/asr/datasets.rst:41
msgid "**步骤**"
msgstr ""

#: ../../source/zh/asr/datasets.rst:43
msgid "下面的脚本假设你已经从Linguistic Data Consortium上获得Fisher数据集，并且数据集格式看起来这样的："
msgstr ""

#: ../../source/zh/asr/datasets.rst:61
msgid ""
"抄本位于 `fe_03_p<1,2>_transcripts/data/trans`，音频文件(.sph)位于 `audio` "
"子目录下的剩下目录中."
msgstr ""

#: ../../source/zh/asr/datasets.rst:63
msgid "首先，把音频文件从.sph转换成.wav:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:71
msgid ""
"这个脚本会把未切分的.wav文件放到 `<conversion_target_dir>/LDC200[4,5]S13-Part[1,2"
"]/audio-wav/`。 需要运行几分钟。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:74
msgid "接着，处理抄本和切分音频数据:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:83
msgid ""
"这个脚本会把整个数据集切分成训练集，验证集和测试集，然后把切分好的音频文件放到对应的目标目录下的文件夹中。 "
"每个数据集都有一个清单文件（.json文件），它包括了音频的抄本，时长和路径。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:86
msgid "这里程序大概需要20分钟。 一旦完成后，你可以删掉这些10分钟长的。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:90
msgid "2000 HUB5 English Evaluation Speech"
msgstr ""

#: ../../source/zh/asr/datasets.rst:92
msgid "运行下面的脚本把HUB5数据集转换成 `nemo_asr` 集合需要的文件格式."
msgstr ""

#: ../../source/zh/asr/datasets.rst:94
msgid ""
"类似于Fisher数据集处理脚本，这个脚本把.sph文件转换成.wav文件，切割音频文件和抄本，然后把他们合并成某个最小长度的音频片段(默认是10秒)。"
" 这些音频片段都被写到一个音频目录下，相应的抄本被写到一个Json格式的清单文件中."
msgstr ""

#: ../../source/zh/asr/datasets.rst:98
msgid "你需要5GB的空间来运行这个脚本 你也需要安装sph2pipe"
msgstr ""

#: ../../source/zh/asr/datasets.rst:101
msgid "这个脚本假设你已经从Linguistic Data Consortium获取到了2000 HUB5数据集。"
msgstr ""

#: ../../source/zh/asr/datasets.rst:103
msgid "运行下面的脚本来处理2000 HUB5 English Evaluation Speech数据集样本:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:111
msgid "你可以选择性的加入 `--min_slice_duration=<num_seconds>` 如果你想改变最小音频片段长度."
msgstr ""

#: ../../source/zh/asr/datasets.rst:114
msgid "AISHELL-1"
msgstr ""

#: ../../source/zh/asr/datasets.rst:116
msgid "运行下面的脚本下载AISHELL-1数据集并把它转换到 `nemo_asr` 集合需要的文件格式."
msgstr ""

#: ../../source/zh/asr/datasets.rst:125
msgid ""
"之后，你的 `data` 文件夹应该包含了一个 `data_aishell` "
"文件夹，它下面包含了wav文件夹，transcript文件夹以及相应的 `.json` 清单文件和 `vocab.txt` 文件:"
msgstr ""

#: ../../source/zh/asr/datasets.rst:128
msgid "AISHELL-2"
msgstr ""

#: ../../source/zh/asr/datasets.rst:130
msgid ""
"运行下面的脚本处理AIShell-2数据集，把它处理成 `nemo_asr` 需要的文件格式。通过设置 `--audio_folder` "
"指定数据目录，用 `--dest_folder` 指定处理后的文件目录"
msgstr ""

#: ../../source/zh/asr/datasets.rst:136
msgid "接着在 `dest_folder` 下会生成 `train.json` `dev.json` `test.json` 以及 `vocab.txt`。"
msgstr ""

