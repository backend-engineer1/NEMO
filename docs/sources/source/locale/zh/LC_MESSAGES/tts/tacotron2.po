# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018-2019, NVIDIA
# This file is distributed under the same license as the nemo package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nemo 0.9.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-12-03 17:10+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../source/tts/tacotron2.rst:4
msgid "Tacotron 2"
msgstr ""

#: ../../source/tts/tacotron2.rst:7
msgid "Model"
msgstr ""

#: ../../source/tts/tacotron2.rst:8
msgid ""
"This model is based on the `Tacotron 2 model "
"<https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-"
"speech.html>`_ (see also `paper <https://arxiv.org/abs/1712.05884>`_)."
msgstr ""

#: ../../source/tts/tacotron2.rst:12
msgid ""
"Tacotron 2 follows a simple encoder decoder structure that has seen great"
" success in sequence-to-sequence modeling. NeMo decomposes Tacotron 2 "
"into 4 different Neural Modules:"
msgstr ""

#: ../../source/tts/tacotron2.rst:16
msgid ""
"A TextEmbedding Neural Module is a look-up table that is used to convert "
"the char id into an embedding space"
msgstr ""

#: ../../source/tts/tacotron2.rst:18
msgid "The embedded text is consumed by the Tacotron2Encoder Neural Module."
msgstr ""

#: ../../source/tts/tacotron2.rst:19
msgid ""
"The Tacotron2Decoder Neural Module creates the attention and decoder RNN "
"parts of Tacotron 2."
msgstr ""

#: ../../source/tts/tacotron2.rst:21
msgid ""
"Finally, the Tacotron2Postnet takes the output of the Tacotron2Decoder "
"and corrects the spectrogram generated by the decoder."
msgstr ""

#: ../../source/tts/tacotron2.rst:25
msgid "Tips"
msgstr ""

#: ../../source/tts/tacotron2.rst:26
msgid ""
"A pseudo metric for audio quality is how well attention is learned. "
"Ideally, we want a nice clear diagonal alignment. The current models "
"should learn attention around 20k steps."
msgstr ""

