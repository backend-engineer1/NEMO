

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; nemo 0.8.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial" href="asr-improvement.html" />
    <link rel="prev" title="Tutorial" href="ner.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.8.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">Natural Language Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#neural-machine-translation-nmt">Neural Machine Translation (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer-language-model">Transformer Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#preliminaries">Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#code-structure">Code structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-training">Model training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#improving-speech-recognition-with-bertx2-post-processing-model">Improving speech recognition with BERTx2 post-processing model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">Mandarin Support</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">Natural Language Processing</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/joint_intent_slot_filling.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we are going to implement a joint intent and slot filling system with pretrained BERT model based on <a class="reference external" href="https://arxiv.org/abs/1902.10909">BERT for Joint Intent Classification and Slot Filling</a> <a class="bibtex reference internal" href="#chen2019bert" id="id1">[1]</a>. All code used in this tutorial is based on <code class="docutils literal notranslate"><span class="pre">examples/nlp/joint_intent_slot_with_bert.py</span></code>.</p>
<p>There are four pretrained BERT models that we can select from using the argument <cite>–pretrained_bert_model</cite>. We’re currently using the script for loading pretrained models from <cite>pytorch_transformers</cite>. See the list of available pretrained models <a class="reference external" href="https://huggingface.co/pytorch-transformers/pretrained_models.html">here</a>.</p>
<div class="section" id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h2>
<p><strong>Model details</strong>
This model jointly train the sentence-level classifier for intents and token-level classifier for slots by minimizing the combined loss of the two classifiers:</p>
<blockquote>
<div><p>intent_loss * intent_loss_weight + slot_loss * (1 - intent_loss_weight)</p>
</div></blockquote>
<p>When <cite>intent_loss_weight = 0.5</cite>, this loss jointly maximizes:</p>
<blockquote>
<div><p>p(y | x)P(s1, s2, …, sn | x)</p>
</div></blockquote>
<p>with x being the sequence of n tokens (x1, x2, …, xn), y being the predicted intent for x, and s1, s2, …, sn being the predicted slots corresponding to x1, x2, …, xn.</p>
<p><strong>Datasets.</strong></p>
<dl class="simple">
<dt>This model can work with any dataset that follows the format:</dt><dd><ul class="simple">
<li><p>input file: a <cite>tsv</cite> file with the first line as a header [sentence][tab][label]</p></li>
<li><p>slot file: slot labels for all tokens in the sentence, separated by space. The length of the slot labels should be the same as the length of all tokens in sentence in input file.</p></li>
</ul>
</dd>
</dl>
<p>Currently, the datasets that we provide pre-processing script for include ATIS which can be downloaded from <a class="reference external" href="https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk">Kaggle</a> and the SNIPS spoken language understanding research dataset which can be requested from <a class="reference external" href="https://github.com/snipsco/spoken-language-understanding-research-datasets">here</a>. You can find the pre-processing script in <code class="docutils literal notranslate"><span class="pre">collections/nemo_nlp/nemo_nlp/text_data_utils.py</span></code>.</p>
</div>
<div class="section" id="code-structure">
<h2>Code structure<a class="headerlink" href="#code-structure" title="Permalink to this headline">¶</a></h2>
<p>First, we instantiate Neural Module Factory which defines 1) backend (PyTorch or TensorFlow), 2) mixed precision optimization level, 3) local rank of the GPU, and 4) an experiment manager that creates a timestamped folder to store checkpoints, relevant outputs, log files, and TensorBoard graphs.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nf</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">NeuralModuleFactory</span><span class="p">(</span>
                <span class="n">backend</span><span class="o">=</span><span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">PyTorch</span><span class="p">,</span>
                <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
                <span class="n">optimization_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp_opt_level</span><span class="p">,</span>
                <span class="n">log_dir</span><span class="o">=</span><span class="n">work_dir</span><span class="p">,</span>
                <span class="n">create_tb_writer</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">files_to_copy</span><span class="o">=</span><span class="p">[</span><span class="vm">__file__</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p>We define tokenizer which transforms text into BERT tokens, using a built-in tokenizer by <cite>pytorch_transformers</cite>. This will tokenize text following the mapping of the original BERT model.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_bert_model</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>Next, we define all Neural Modules participating in our joint intent slot filling classification pipeline.</p>
<blockquote>
<div><ul class="simple">
<li><p>Process data: the <cite>JointIntentSlotDataDesc</cite> class in <cite>nemo_nlp/nemo_nlp/text_data_utils.py</cite> is supposed to do the preprocessing of raw data into the format data supported by <cite>BertJointIntentSlotDataset</cite>. Currently, it supports SNIPS and ATIS raw datasets, but you can also write your own preprocessing scripts for any dataset.</p></li>
</ul>
<p>A JointIntentSlotDataDesc object includes information such as <cite>self.train_file</cite>, <cite>self.train_slot_file</cite>, <cite>self.eval_file</cite>, <cite>self.eval_slot_file</cite>,  <cite>self.intent_dict_file</cite>, and <cite>self.slot_dict_file</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_desc</span> <span class="o">=</span> <span class="n">JointIntentSlotDataDesc</span><span class="p">(</span>
    <span class="n">args</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">do_lower_case</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Dataset: convert from the formatted dataset to a dataset that can be fed into DataLayerNM.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">data_desc</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
    <span class="n">nf</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Loading {mode} data...&quot;</span><span class="p">)</span>
    <span class="n">data_file</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data_desc</span><span class="p">,</span> <span class="n">mode</span> <span class="o">+</span> <span class="s1">&#39;_file&#39;</span><span class="p">)</span>
    <span class="n">slot_file</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data_desc</span><span class="p">,</span> <span class="n">mode</span> <span class="o">+</span> <span class="s1">&#39;_slot_file&#39;</span><span class="p">)</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">shuffle_data</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span> <span class="k">else</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">BertJointIntentSlotDataset</span><span class="p">(</span>
        <span class="n">input_file</span><span class="o">=</span><span class="n">data_file</span><span class="p">,</span>
        <span class="n">slot_file</span><span class="o">=</span><span class="n">slot_file</span><span class="p">,</span>
        <span class="n">pad_label</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">pad_label</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>


<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">data_desc</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_train_samples</span><span class="p">)</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">data_desc</span><span class="p">,</span> <span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_eval_samples</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>DataLayer: an extra layer to do the semantic checking for your dataset and convert it into DataLayerNM. You have to define <cite>input_ports</cite> and <cite>output_ports</cite>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_layer</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">BertJointIntentSlotDataLayer</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                        <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">)</span>

<span class="n">ids</span><span class="p">,</span> <span class="n">type_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">,</span> <span class="n">slot_mask</span><span class="p">,</span> <span class="n">intents</span><span class="p">,</span> <span class="n">slots</span> <span class="o">=</span> <span class="n">data_layer</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Load the pretrained model and get the hidden states for the corresponding inputs.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_states</span> <span class="o">=</span> <span class="n">pretrained_bert_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span>
                                      <span class="n">token_type_ids</span><span class="o">=</span><span class="n">type_ids</span><span class="p">,</span>
                                      <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the classifier heads for our task.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">JointIntentSlotClassifier</span><span class="p">(</span>
                                <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
                                <span class="n">num_intents</span><span class="o">=</span><span class="n">num_intents</span><span class="p">,</span>
                                <span class="n">num_slots</span><span class="o">=</span><span class="n">num_slots</span><span class="p">,</span>
                                <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">fc_dropout</span><span class="p">)</span>

<span class="n">intent_logits</span><span class="p">,</span> <span class="n">slot_logits</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="o">=</span><span class="n">hidden_states</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create loss function</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">JointIntentSlotLoss</span><span class="p">(</span><span class="n">num_slots</span><span class="o">=</span><span class="n">num_slots</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">intent_logits</span><span class="o">=</span><span class="n">intent_logits</span><span class="p">,</span>
               <span class="n">slot_logits</span><span class="o">=</span><span class="n">slot_logits</span><span class="p">,</span>
               <span class="n">input_mask</span><span class="o">=</span><span class="n">input_mask</span><span class="p">,</span>
               <span class="n">intents</span><span class="o">=</span><span class="n">intents</span><span class="p">,</span>
               <span class="n">slots</span><span class="o">=</span><span class="n">slots</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create relevant callbacks for saving checkpoints, printing training progresses and evaluating results</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">callback_train</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">SimpleLossLoggerCallback</span><span class="p">(</span>
    <span class="n">tensors</span><span class="o">=</span><span class="n">train_tensors</span><span class="p">,</span>
    <span class="n">print_func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
    <span class="n">get_tb_values</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]],</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">)</span>

<span class="n">callback_eval</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">EvaluatorCallback</span><span class="p">(</span>
    <span class="n">eval_tensors</span><span class="o">=</span><span class="n">eval_tensors</span><span class="p">,</span>
    <span class="n">user_iter_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">eval_iter_callback</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">data_layer</span><span class="p">),</span>
    <span class="n">user_epochs_done_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">eval_epochs_done_callback</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{nf.work_dir}/graphs&#39;</span><span class="p">),</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
    <span class="n">eval_step</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">)</span>

<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">CheckpointCallback</span><span class="p">(</span>
    <span class="n">folder</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">,</span>
    <span class="n">epoch_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_epoch_freq</span><span class="p">,</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_step_freq</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Finally, we define the optimization parameters and run the whole pipeline.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_policy_fn</span> <span class="o">=</span> <span class="n">get_lr_policy</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">,</span>
                             <span class="n">total_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
                             <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_proportion</span><span class="p">)</span>
<span class="n">nf</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">tensors_to_optimize</span><span class="o">=</span><span class="p">[</span><span class="n">train_loss</span><span class="p">],</span>
     <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback_train</span><span class="p">,</span> <span class="n">callback_eval</span><span class="p">,</span> <span class="n">ckpt_callback</span><span class="p">],</span>
     <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy_fn</span><span class="p">,</span>
     <span class="n">optimizer</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">optimizer_kind</span><span class="p">,</span>
     <span class="n">optimization_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
                          <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                          <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">})</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="model-training">
<h2>Model training<a class="headerlink" href="#model-training" title="Permalink to this headline">¶</a></h2>
<p>To train a joint intent slot filling model, run <code class="docutils literal notranslate"><span class="pre">joint_intent_slot_with_bert.py</span></code> located at <code class="docutils literal notranslate"><span class="pre">nemo/examples/nlp</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">launch</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">2</span> <span class="n">joint_intent_slot_with_bert</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">data</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">work_dir</span> <span class="o">&lt;</span><span class="n">where</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="n">log</span> <span class="n">your</span> <span class="n">experiment</span><span class="o">&gt;</span> \
    <span class="o">--</span><span class="n">max_seq_length</span> \
    <span class="o">--</span><span class="n">optimizer_kind</span>
    <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>To do inference, run:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">joint_intent_slot_infer</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">data</span><span class="o">&gt;</span> \
    <span class="o">--</span><span class="n">work_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>
</pre></div>
</div>
</div></blockquote>
<p>To do inference on a single query, run:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">joint_intent_slot_infer</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">work_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">query</span> <span class="o">&lt;</span><span class="n">query</span><span class="o">&gt;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/joint_intent_slot_filling-0"><dl class="citation">
<dt class="bibtex label" id="chen2019bert"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Qian Chen, Zhu Zhuo, and Wen Wang. Bert for joint intent classification and slot filling. <em>arXiv preprint arXiv:1902.10909</em>, 2019.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="asr-improvement.html" class="btn btn-neutral float-right" title="Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ner.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2019, AI Applications team

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>