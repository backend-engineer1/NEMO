{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "01_Pretrained_Language_Models_for_Downstream_Tasks.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "djqHSONJ20X8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "c8c161ce-6a9a-49a8-9b92-b062d9da025f"
   },
   "source": [
    "\"\"\"\n",
    "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "\n",
    "Instructions for setting up Colab are as follows:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "4. Run this cell to set up dependencies.\n",
    "\"\"\"\n",
    "# If you're using Google Colab and not running locally, run this cell\n",
    "\n",
    "# install NeMo\n",
    "!python -m pip install --upgrade git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[nlp]"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting nemo_toolkit[nlp]\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-t5_s8_64/nemo-toolkit\n",
      "  Running command git clone -q https://github.com/NVIDIA/NeMo.git /tmp/pip-install-t5_s8_64/nemo-toolkit\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: onnx>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pytorch-lightning==0.9.0 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.6.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: wget in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (3.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.16.12)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: omegaconf==2.0.1rc12 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (2.0.1rc12)\n",
      "Requirement already satisfied, skipping upgrade: hydra-core==1.0.0rc4 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.0.0rc4)\n",
      "Requirement already satisfied, skipping upgrade: transformers>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.14.48)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.1.91)\n",
      "Requirement already satisfied, skipping upgrade: torchtext in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.3.1)\n",
      "Requirement already satisfied, skipping upgrade: unidecode in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: youtokentome in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.0.6)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: rapidfuzz in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: gdown in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (3.6.4)\n",
      "Requirement already satisfied, skipping upgrade: megatron-lm>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (1.1.4)\n",
      "Requirement already satisfied, skipping upgrade: inflect in /usr/local/lib/python3.6/dist-packages (from nemo_toolkit[nlp]) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->nemo_toolkit[nlp]) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->nemo_toolkit[nlp]) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->nemo_toolkit[nlp]) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard==2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml->nemo_toolkit[nlp]) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nemo_toolkit[nlp]) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nemo_toolkit[nlp]) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from omegaconf==2.0.1rc12->nemo_toolkit[nlp]) (0.7)\n",
      "Requirement already satisfied, skipping upgrade: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.6/dist-packages (from hydra-core==1.0.0rc4->nemo_toolkit[nlp]) (4.8)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core==1.0.0rc4->nemo_toolkit[nlp]) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->nemo_toolkit[nlp]) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->nemo_toolkit[nlp]) (0.8.1rc2)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->nemo_toolkit[nlp]) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->nemo_toolkit[nlp]) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->nemo_toolkit[nlp]) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo_toolkit[nlp]) (1.17.48)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo_toolkit[nlp]) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->nemo_toolkit[nlp]) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo_toolkit[nlp]) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo_toolkit[nlp]) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nemo_toolkit[nlp]) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->nemo_toolkit[nlp]) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pybind11 in /usr/local/lib/python3.6/dist-packages (from megatron-lm>=1.1.4->nemo_toolkit[nlp]) (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx>=1.7.0->nemo_toolkit[nlp]) (49.6.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.31.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core==1.0.0rc4->nemo_toolkit[nlp]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.1.0->nemo_toolkit[nlp]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.1.0->nemo_toolkit[nlp]) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.1.0->nemo_toolkit[nlp]) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.1.0->nemo_toolkit[nlp]) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->nemo_toolkit[nlp]) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0->nemo_toolkit[nlp]) (3.1.0)\n",
      "Building wheels for collected packages: nemo-toolkit\n",
      "  Building wheel for nemo-toolkit (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for nemo-toolkit: filename=nemo_toolkit-1.0.0a0-cp36-none-any.whl size=398162 sha256=0547674ef74d2c94f48cb4b849d2b06750ecf6effbc218ae91f1aeabdddc98e5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-scm6lg2t/wheels/7d/eb/d8/9e9a57ec1209168e720c7eeb7040f76c6417fff3ce490bfb05\n",
      "Successfully built nemo-toolkit\n",
      "Installing collected packages: nemo-toolkit\n",
      "  Found existing installation: nemo-toolkit 1.0.0a0\n",
      "    Uninstalling nemo-toolkit-1.0.0a0:\n",
      "      Successfully uninstalled nemo-toolkit-1.0.0a0\n",
      "Successfully installed nemo-toolkit-1.0.0a0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CmvtH0pxHDQC",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "outputId": "fdaddea0-88fe-4207-ee7e-5a6a8ca360bb"
   },
   "source": [
    "import os\n",
    "import wget\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "from omegaconf import OmegaConf"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-09-09 16:10:53 experimental:28] Module <class 'nemo.collections.nlp.modules.common.huggingface.auto.AutoModelEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-09-09 16:10:53 experimental:28] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-09-09 16:10:53 experimental:28] Module <class 'nemo.collections.nlp.modules.common.sequence_token_classifier.SequenceTokenClassifier'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "WARNING: APEX is not installed, multi_tensor_applier will not be available.\n",
      "WARNING: APEX is not installed, using torch.nn.LayerNorm instead of apex.normalization.FusedLayerNorm!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6AARcXXUEbs",
    "colab_type": "text"
   },
   "source": [
    "# Language models\n",
    "\n",
    "Natural Language Processing (NLP) field experienced a huge leap in recent years due to the concept of transfer learning enabled through pretrained language models.\n",
    "\n",
    "[BERT](https://arxiv.org/abs/1810.04805), [RoBERTa](https://arxiv.org/abs/1907.11692), [Megatron-LM](https://arxiv.org/abs/1909.08053), and many other proposed language models achieve state-of-the-art results on many NLP tasks, such as:\n",
    "* question answering\n",
    "* sentiment analysis\n",
    "* named entity recognition and many others.\n",
    "\n",
    "In NeMo, most of the NLP models represent a pretrained language model followed by a Token Classification layer or a Sequence Classification layer or a combination of both. By changing the language model, you can improve the performance of your final model on the specific downstream task you are solving.\n",
    "\n",
    "With NeMo you can use either pretrain a BERT model from your data or use a pretrained language model from [HuggingFace transformers](https://github.com/huggingface/transformers) or [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) libraries.\n",
    "\n",
    "Let's take a look at the list of available pretrained language models, note the complete list of HuggingFace model could be found at [https://huggingface.co/models](https://huggingface.co/models):\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zp7F45bgX7SU",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "b87752df-8e50-400b-9e1a-12e05bf175d2"
   },
   "source": [
    "nemo_nlp.modules.get_pretrained_lm_models_list(include_external=True)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['megatron-bert-345m-uncased',\n",
       " 'megatron-bert-345m-cased',\n",
       " 'megatron-bert-uncased',\n",
       " 'megatron-bert-cased',\n",
       " 'biomegatron-bert-345m-uncased',\n",
       " 'biomegatron-bert-345m-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-uncased',\n",
       " 'bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-multilingual-uncased',\n",
       " 'bert-base-multilingual-cased',\n",
       " 'bert-base-chinese',\n",
       " 'bert-base-german-cased',\n",
       " 'bert-large-uncased-whole-word-masking',\n",
       " 'bert-large-cased-whole-word-masking',\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad',\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad',\n",
       " 'bert-base-cased-finetuned-mrpc',\n",
       " 'bert-base-german-dbmdz-cased',\n",
       " 'bert-base-german-dbmdz-uncased',\n",
       " 'cl-tohoku/bert-base-japanese',\n",
       " 'cl-tohoku/bert-base-japanese-whole-word-masking',\n",
       " 'cl-tohoku/bert-base-japanese-char',\n",
       " 'cl-tohoku/bert-base-japanese-char-whole-word-masking',\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1',\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1',\n",
       " 'wietsedv/bert-base-dutch-cased',\n",
       " 'facebook/bart-base',\n",
       " 'facebook/bart-large',\n",
       " 'facebook/bart-large-mnli',\n",
       " 'facebook/bart-large-cnn',\n",
       " 'facebook/bart-large-xsum',\n",
       " 'facebook/mbart-large-en-ro',\n",
       " 'yjernite/bart_eli5',\n",
       " 'facebook/mbart-large-cc25',\n",
       " 'openai-gpt',\n",
       " 'transfo-xl-wt103',\n",
       " 'gpt2',\n",
       " 'gpt2-medium',\n",
       " 'gpt2-large',\n",
       " 'gpt2-xl',\n",
       " 'distilgpt2',\n",
       " 'ctrl',\n",
       " 'xlnet-base-cased',\n",
       " 'xlnet-large-cased',\n",
       " 'xlm-mlm-en-2048',\n",
       " 'xlm-mlm-ende-1024',\n",
       " 'xlm-mlm-enfr-1024',\n",
       " 'xlm-mlm-enro-1024',\n",
       " 'xlm-mlm-tlm-xnli15-1024',\n",
       " 'xlm-mlm-xnli15-1024',\n",
       " 'xlm-clm-enfr-1024',\n",
       " 'xlm-clm-ende-1024',\n",
       " 'xlm-mlm-17-1280',\n",
       " 'xlm-mlm-100-1280',\n",
       " 'roberta-base',\n",
       " 'roberta-large',\n",
       " 'roberta-large-mnli',\n",
       " 'distilroberta-base',\n",
       " 'roberta-base-openai-detector',\n",
       " 'roberta-large-openai-detector',\n",
       " 'distilbert-base-uncased',\n",
       " 'distilbert-base-uncased-distilled-squad',\n",
       " 'distilbert-base-cased',\n",
       " 'distilbert-base-cased-distilled-squad',\n",
       " 'distilbert-base-german-cased',\n",
       " 'distilbert-base-multilingual-cased',\n",
       " 'distilbert-base-uncased-finetuned-sst-2-english',\n",
       " 'albert-base-v1',\n",
       " 'albert-large-v1',\n",
       " 'albert-xlarge-v1',\n",
       " 'albert-xxlarge-v1',\n",
       " 'albert-base-v2',\n",
       " 'albert-large-v2',\n",
       " 'albert-xlarge-v2',\n",
       " 'albert-xxlarge-v2',\n",
       " 'camembert-base',\n",
       " 'umberto-commoncrawl-cased-v1',\n",
       " 'umberto-wikipedia-uncased-v1',\n",
       " 't5-small',\n",
       " 't5-base',\n",
       " 't5-large',\n",
       " 't5-3b',\n",
       " 't5-11b',\n",
       " 'xlm-roberta-base',\n",
       " 'xlm-roberta-large',\n",
       " 'xlm-roberta-large-finetuned-conll02-dutch',\n",
       " 'xlm-roberta-large-finetuned-conll02-spanish',\n",
       " 'xlm-roberta-large-finetuned-conll03-english',\n",
       " 'xlm-roberta-large-finetuned-conll03-german',\n",
       " 'flaubert/flaubert_small_cased',\n",
       " 'flaubert/flaubert_base_uncased',\n",
       " 'flaubert/flaubert_base_cased',\n",
       " 'flaubert/flaubert_large_cased',\n",
       " 'google/electra-small-generator',\n",
       " 'google/electra-base-generator',\n",
       " 'google/electra-large-generator',\n",
       " 'google/electra-small-discriminator',\n",
       " 'google/electra-base-discriminator',\n",
       " 'google/electra-large-discriminator',\n",
       " 'allenai/longformer-base-4096',\n",
       " 'allenai/longformer-large-4096',\n",
       " 'allenai/longformer-large-4096-finetuned-triviaqa',\n",
       " 'allenai/longformer-base-4096-extra.pos.embd.only',\n",
       " 'allenai/longformer-large-4096-extra.pos.embd.only',\n",
       " 'retribert-base-uncased']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdpxEiirX8F-",
    "colab_type": "text"
   },
   "source": [
    "NLP models for downstream tasks use `get_lm_model` helper function to easily switch between language models from the list above to another:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5zllsvBojxuJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "1c6e9878-2e82-460a-d890-30073bb11994"
   },
   "source": [
    "# use any pretrained model name from the list above\n",
    "nemo_nlp.modules.get_lm_model(pretrained_model_name='distilbert-base-uncased')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DistilBertEncoder(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEgEo0aPj3Ws",
    "colab_type": "text"
   },
   "source": [
    "All NeMo [NLP models](https://github.com/NVIDIA/NeMo/tree/main/examples/nlp) have an associated config file. As an example, let's examine the config file for the Named Entity Recognition (NER) model (more details about the model and the NER task could be found [here](https://github.com/NVIDIA/NeMo/blob/main/tutorials/nlp/Token_Classification_Named_Entity_Recognition.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T1gA8PsJ13MJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "326a3673-a814-422a-bde3-e61ba4f20fc4"
   },
   "source": [
    "MODEL_CONFIG = \"token_classification_config.yaml\"\n",
    "\n",
    "# download the model's configuration file \n",
    "if not os.path.exists(MODEL_CONFIG):\n",
    "    print('Downloading config file...')\n",
    "    wget.download('https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/nlp/token_classification/conf/' + MODEL_CONFIG)\n",
    "else:\n",
    "    print ('Config file already exists')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Config file already exists\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mX3KmWMvSUQw",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "bf9b174f-f3b1-4387-9c66-29170dec48cf"
   },
   "source": [
    "# this line will print the entire config of the model\n",
    "config = OmegaConf.load(MODEL_CONFIG)\n",
    "print(OmegaConf.to_yaml(config))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "trainer:\n",
      "  gpus: 1\n",
      "  num_nodes: 1\n",
      "  max_epochs: 5\n",
      "  max_steps: null\n",
      "  accumulate_grad_batches: 1\n",
      "  gradient_clip_val: 0.0\n",
      "  amp_level: O0\n",
      "  precision: 16\n",
      "  distributed_backend: ddp\n",
      "  checkpoint_callback: false\n",
      "  logger: false\n",
      "  row_log_interval: 1\n",
      "  val_check_interval: 1.0\n",
      "  resume_from_checkpoint: null\n",
      "exp_manager:\n",
      "  exp_dir: null\n",
      "  name: token_classification_model\n",
      "  create_tensorboard_logger: true\n",
      "  create_checkpoint_callback: true\n",
      "model:\n",
      "  nemo_path: null\n",
      "  label_ids: null\n",
      "  dataset:\n",
      "    data_dir: ???\n",
      "    class_balancing: null\n",
      "    max_seq_length: 128\n",
      "    pad_label: O\n",
      "    ignore_extra_tokens: false\n",
      "    ignore_start_end: false\n",
      "    use_cache: true\n",
      "    num_workers: 2\n",
      "    pin_memory: false\n",
      "    drop_last: false\n",
      "  train_ds:\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    batch_size: 64\n",
      "  validation_ds:\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 64\n",
      "  tokenizer:\n",
      "    tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "    vocab_file: null\n",
      "    tokenizer_model: null\n",
      "    special_tokens: null\n",
      "  language_model:\n",
      "    pretrained_model_name: bert-base-uncased\n",
      "    lm_checkpoint: null\n",
      "    config_file: null\n",
      "    config: null\n",
      "  head:\n",
      "    num_fc_layers: 2\n",
      "    fc_dropout: 0.5\n",
      "    activation: relu\n",
      "    log_softmax: true\n",
      "    use_transformer_init: true\n",
      "  optim:\n",
      "    name: adam\n",
      "    lr: 5.0e-05\n",
      "    weight_decay: 0.0\n",
      "    sched:\n",
      "      name: WarmupAnnealing\n",
      "      warmup_steps: null\n",
      "      warmup_ratio: 0.1\n",
      "      last_epoch: -1\n",
      "      monitor: val_loss\n",
      "      reduce_on_plateau: false\n",
      "hydra:\n",
      "  run:\n",
      "    dir: .\n",
      "  job_logging:\n",
      "    root:\n",
      "      handlers: null\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKFbFDwzKUZB",
    "colab_type": "text"
   },
   "source": [
    "For this tutorial, we are interested in the language_model part of the Named Entity Recognition Model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v6hlcCYyKFiY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "outputId": "0fc8a4e4-978b-406f-e9ef-981f527ccedd"
   },
   "source": [
    "print(OmegaConf.to_yaml(config.model.language_model))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "pretrained_model_name: bert-base-uncased\n",
      "lm_checkpoint: null\n",
      "config_file: null\n",
      "config: null\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xldsDiH9ZY2h",
    "colab_type": "text"
   },
   "source": [
    "There are might be slight differences from one model to another, but most of them have the following important parameters associated with the language model:\n",
    "* `pretrained_model_name` - a name of the pretrained model from either HuggingFace or Megatron-LM libraries, for example, bert-base-uncased or megatron-bert-345m-uncased.\n",
    "* `lm_checkpoint` - a path to the pretrained model checkpoint if, for example, you trained a BERT model with your data\n",
    "* `config_file` -  path to the model configuration file\n",
    "* `config` or `config_dict` - path to the model configuration dictionary\n",
    "\n",
    "To modify the default language model, specify the desired language model name with the `model.language_model.pretrained_model_name` argument, like this:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5r_1gIXwashY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "config.model.language_model.pretrained_model_name = 'roberta-base'"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVp4zvxPatga",
    "colab_type": "text"
   },
   "source": [
    "and then start the training as usual (please see [tutorials/nlp](https://github.com/NVIDIA/NeMo/tree/main/tutorials/nlp) for more details about training a particular model). \n",
    "\n",
    "You can also provide a pretrained language model checkpoint and a configuration file if available.\n",
    "\n",
    "Note, that `pretrained_model_name` is used to set up both Language Model and Tokenizer.\n",
    "\n",
    "All the above holds for both HuggingFace and Megatron-LM pretrained language models. Let's separately examine some specifics of finetuning with Megatron-LM and a HuggingFace model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_LBdSA4U6Q",
    "colab_type": "text"
   },
   "source": [
    "# Downstream tasks with Megatron and BioMegatron LM\n",
    "\n",
    "[Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) is a large, powerful transformer developed by the Applied Deep Learning Research team at NVIDIA. More details could be found at [Megatron-LM github repo](https://github.com/NVIDIA/Megatron-LM).\n",
    "\n",
    "To see the list of available Megatron-LM models in NeMo, run:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0o-XPMrIQBmm",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "outputId": "7a7e0419-e9a1-48b3-b6bf-4d2863f69f46"
   },
   "source": [
    "nemo_nlp.modules.get_megatron_lm_models_list()"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['megatron-bert-345m-uncased',\n",
       " 'megatron-bert-345m-cased',\n",
       " 'megatron-bert-uncased',\n",
       " 'megatron-bert-cased',\n",
       " 'biomegatron-bert-345m-uncased',\n",
       " 'biomegatron-bert-345m-cased']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM_ei7OSLn1X",
    "colab_type": "text"
   },
   "source": [
    "If you want to use one of the available Megatron-LM models, specify its name with `model.language_model.pretrained_model_name` argument, for example:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RmcQLoouME8k",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "config.model.language_model.pretrained_model_name = 'megatron-bert-345m-uncased'"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mla-BZexMM2u",
    "colab_type": "text"
   },
   "source": [
    "If you have a different checkpoint or a model configuration file, use these general Megatron-LM model names:\n",
    "* `megatron-bert-uncased` or \n",
    "* `megatron-bert-cased` \n",
    "\n",
    "and provide associated bert_config and bert_checkpoint files, as follows:\n",
    "\n",
    "`model.language_model.pretrained_model_name=megatron-bert-uncased \\\n",
    "model.language_model.lm_checkpoint=<PATH_TO_CHECKPOINT> \\\n",
    "model.language_model.config_file=<PAHT_TO_CONFIG>`\n",
    " \n",
    " or \n",
    " \n",
    "`model.language_model.pretrained_model_name=megatron-bert-cased \\\n",
    "model.language_model.lm_checkpoint=<PATH_TO_CHECKPOINT> \\\n",
    "model.language_model.config_file=<PAHT_TO_CONFIG>`\n",
    "\n",
    "The general Megatron-LM model names are used to download the correct vocabulary file needed to setup the model correctly. Note, the data preprocessing and model training is done in NeMo. Megatron-LM has its own set of training arguments (including tokenizer) that are ignored during finetuning in NeMo. Please see downstream task [config files and training scripts](https://github.com/NVIDIA/NeMo/tree/main/examples/nlp) for all NeMo supported arguments.\n",
    "\n",
    "## Download pretrained model\n",
    "\n",
    "With NeMo, the original and domain-specific Megatron-LM BERT models and model configuration files will be downloaded automatically, but they also could be downloaded with the links below:\n",
    "\n",
    "[Megatron-LM BERT Uncased 345M (~345M parameters): https://ngc.nvidia.com/catalog/models/nvidia:megatron_bert_345m](https://ngc.nvidia.com/catalog/models/nvidia:megatron_bert_345m/files?version=v0.1_uncased)\n",
    "\n",
    "[Megatron-LM BERT Cased 345M (~345M parameters): https://ngc.nvidia.com/catalog/models/nvidia:megatron_bert_345m](https://ngc.nvidia.com/catalog/models/nvidia:megatron_bert_345m/files?version=v0.1_cased)\n",
    "\n",
    "[BioMegatron-LM BERT Cased 345M (~345M parameters): https://ngc.nvidia.com/catalog/models/nvidia:biomegatron345mcased](https://ngc.nvidia.com/catalog/models/nvidia:biomegatron345mcased)\n",
    "\n",
    "[BioMegatron-LM BERT Uncased 345M (~345M parameters)](https://ngc.nvidia.com/catalog/models/nvidia:biomegatron345muncased): https://ngc.nvidia.com/catalog/models/nvidia:biomegatron345muncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caafJmVLmEVD",
    "colab_type": "text"
   },
   "source": [
    "# Using any HuggingFace Pretrained Model\n",
    "\n",
    "Currently, there are 4 HuggingFace language models that have the most extensive support in [NeMo](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/nlp/modules/common/huggingface): \n",
    "\n",
    "* BERT\n",
    "* RoBERTa\n",
    "* ALBERT\n",
    "* DistilBERT\n",
    "\n",
    "As was mentioned before, just set `model.language_model.pretrained_model_name` to the desired model name in your config and get_lm_model() will take care of the rest.\n",
    "\n",
    "If you want to use another language model from [https://huggingface.co/models](https://huggingface.co/models), NeMo will use AutoModelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKTTCZHFi3Tt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "bb67a2fb-0bc9-48fa-9187-d78a4228a5d9"
   },
   "source": [
    "new_model_name = 't5-small'\n",
    "# change your config like this:\n",
    "# model.language_model.pretrained_model_name = new_model_name\n",
    "nemo_nlp.modules.get_lm_model(pretrained_model_name=new_model_name)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-09-09 16:10:57 lm_utils:69] t5-small is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n",
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-09-09 16:11:00 huggingface_utils:102] Using HuggingFace AutoModel\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AutoModelEncoder(\n",
       "  (lm_model): T5Model(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2Joti9XrJEp",
    "colab_type": "text"
   },
   "source": [
    "Then continue training your PyTorch Lightning Model, as usual, more details on model training could be found at [tutorials](https://github.com/NVIDIA/NeMo/tree/main/tutorials)."
   ]
  }
 ]
}